Автокорреляция порядка p — это
более богатая модель для
структуры зависимости между ε,
а именно: предполагается,
что ε_t — это φ_1 ε_{t‒1} + φ_2 ε_{t‒2} + ...
+ φ_p ε_{t‒p} + новая случайная
составляющая u_t, которая
удовлетворяет тем же предпосылкам:
u_t независимы между собой, независимы
от регрессоров, одинаково распределены,
нулевое математическое ожидание,
постоянная дисперсия σ² u.
В отличие от автокорреляции
первого порядка,
автокорреляция порядка p
допускает более сложную структуру
корреляций между ε_t и ε_{t‒k}, между ε_i и ε_j.
Если раньше корреляция между ε_t и
ε_{t‒k} — это просто было ρ в степени k,
то есть она убывала по модулю,
то сейчас корреляция не обязана сразу
начинать убывать, она может принимать
довольно произвольные значения,
хотя общий факт сохраняется:
предел Corr(ε_t, ε_{t‒k})
при k, стремящемся к бесконечности, 
равен 0.
То есть это означает, что если
расстояние по времени между наблюдениями
очень велико, то сила зависимости
между ними будет маленькой,
то есть зависимость между ε_t и ε_{t‒k}
убывает с ростом расстояния по времени,
предел равен 0.
Посмотрим, как взаимодействует предпосылка
об автокорреляции с другими предпосылками.
Во-первых, автоматом оказывается
нарушена предпосылка о
независимости отдельных наблюдений.
То есть раньше мы говорили,
что вектор из всех объясняющих переменных
и зависимые переменные, относящиеся
к наблюдению i, и такой же вектор,
относящийся к наблюдению j,
были независимы и одинаково распределены.
Теперь они зависимы, хотя по-прежнему
и будут одинаково распределены.
И, во-вторых,
очень часто во временных рядах нарушена
предпосылка о строгой экзогенности: о том,
что E(ε_t|X) = 0.
Как правило, эта предпосылка нарушена.
Могут быть отдельные редкие исключения,
в которых она не нарушена,
а мы для простоты будем предполагать
ситуацию, что эта предпосылка не нарушена.
Хотя, например, даже включение предыдущей
зависимой переменной в регрессоры,
например, наличие y_{t‒1} 
среди регрессоров,
автоматически означает нарушение
предпосылки о строгой экзогенности.
Для возможности включения прошлого
значения зависимой переменной
в регрессоры есть два подхода.
Первый подход — это ослабить предпосылки,
и второй подход — это использовать
принципиально другой метод,
метод максимального правдоподобия,
и работать с ним,
а не с методом наименьших
квадратов и не с его свойствами.
В основном,
большая часть временных рядов построена
на методе максимального правдоподобия,
поэтому мы не будем разбирать варианты с
ослаблением предпосылок, которые подходит
для того, чтобы принять метод наименьших
квадратов для временных рядов.
Итак, посмотрим, что произойдёт, если мы
будем использовать прежние формулы для
оценок коэффициентов,
для стандартных ошибок, а в ε_t будет
автокорреляция порядка p.
Итак, для оценок мы используем
классическую формулу β с крышкой равно
(X'X)^(-1)X'y.
И для оценки ковариационной матрицы —
снова RSS, сумма квадратов остатков,
делить на n ‒ k,
помножить на (X'X)^(-1).
В частности, это означает
использование для оценки дисперсии,
оценки j-того коэффициента,
σ² с крышкой, деленное на RSS_j,
где RSS_j — это RSS в регрессии j-того
регрессора на остальные регрессоры.
Напомним, что у нас было
три группы свойств,
которые возникали при использовании
этих формул и выполненных
стандартных предпосылках,
а именно: у нас были свойства,
связанные с конечной выборкой без
предположения о нормальности ε, свойства
для конечных выборок с предположением
о нормальности ε и асимптотические
свойства для больших выборок,
то есть когда n стремится к бесконечности.
Рассмотрим, что происходит
с каждой группой свойств.
Для конечной выборки без предположения
о нормальности ε сохраняется
свойство линейности по y,
сохраняется условная несмещённость,
то есть математическое ожидание от β с
крышкой при фиксированных X равно β.
Это хорошее свойство, это говорит о том,
что наши оценки, которые мы получаем,
β с крышкой, могут оказаться выше,
чем неизвестные β, могут оказаться ниже,
чем неизвестные β, но в среднем мы
попадаем в неизвестные интересующие нас β.
Оценки как и в случае
гетероскедастичности неэффективны: здесь
автокорреляция очень похожа по своим
последствиям на гетероскедастичность.
Что касается конечной выборки с
предположением о нормальности ε,
здесь мы теряем все свойства,
которые были при
выполнении всех предпосылок
классической линейной модели регрессии.
То есть распределение t-статистики
уже не является t-распределением,
распределение RSS делить на σ²
не является хи-квадрат распределением в
точности, и, соответственно,
распределение F-статистики,
проверявшей гипотезу о совпадении
ограниченной и неограниченной моделей,
также не является в
точности F-распределением.
Асимптотические свойства
отчасти сохраняются.
В частности, при наличии
авторегрессионной схемы порядка p,
фиксированного порядка p в ошибках,
β с крышкой по-прежнему
являются состоятельными оценками для β,
то есть с ростом количества наблюдений,
если у вас достаточно много наблюдений,
то оценки, которые вы получаете,
β с крышкой,
будут очень похожи на настоящие β.
Но, к сожалению, проверять гипотезы
по стандартным формулам не
получается даже при большом
количестве наблюдений.
Даже если n стремится к бесконечности,
t-статистика не становится
нормально распределённой.
Вкратце подвести итог последствиям
можно следующим образом.
Сами β с крышкой,
сами оценки коэффициентов, в условии
автокорреляции можно интерпретировать
как и раньше и использовать.
Однако стандартные ошибки,
считаемые по стандартным формулам,
несостоятельны, и пооэтому мы не можем,
используя обычные формулы,
строить доверительные интервалы
для неизвестных коэффициентов и
проверять гипотезы.

