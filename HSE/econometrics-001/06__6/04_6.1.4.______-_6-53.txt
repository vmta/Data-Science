Что можно сделать, чтобы устранить
негативные последствия автокорреляции?
Одна из стандартных мер,
которая не требует больших усилий от
практика — это исправить
стандартные ошибки.
То есть использовать другую формулу,
а именно формулу для оценки
ковариационной матрицы оценок β с крышкой
состоятельной в условиях
автокорреляции и гетероскедастичности.
HAC расшифровывается как
heteroscedasticity and
autocorrelation consistent.
Следовательно, у нас получатся
другие стандартные ошибки,
и если мы с помощью них будем проверять
гипотезы, то уже асимптотическое
распределение статистики,
t-статистики будет нормальным 0,1,
и мы можем проверять гипотезы и
строить доверительные интервалы.
Робастная (устойчивая) к условной
автокорреляции оценка ковариационной
матрицы была предложена
Нью-Вестом в 1987-м году,
она имеет довольно громоздкую формулу, но,
тем не менее, приятен сам факт,
что она существует,
и мы с помощью компьютера можем ее легко
автоматически посчитать и использовать.
К чему приводит использование формулы
для оценки ковариационной матрицы,
предложенной Нью-Вестом?
С точки зрения практика
все довольно просто.
Мы меняем одни стандартные ошибки на
рассчитываемые по другим формулам,
и использование оценки ковариационной
матрицы Нью-Веста решает проблему
тестирования гипотез об отдельном
коэффициенте и построении доверительных
интервалов для отдельного коэффициента.
То есть t-статистика равная β_j с крышкой
минус β_j, деленное на стандартную ошибку,
устойчивую к автокорреляции теперь
эта t-статистика, с ростом количества
наблюдений, становится все более и более
похожей на нормальное распределение.
И мы получаем возможность строить
доверительные интервалы и
проверять гипотезы.
Какие проблемы использование
этой корректировки не решает?
Во-первых, оценки β с крышкой
остаются неэффективными, и, конечно,
не решаются проблемы с
распределением статистик в конечных
выборках даже с предположением
о нормальности ε.
С практической точки зрения
в R все будет просто.
Мы оцениваем модель как и раньше
методом наименьших квадратов,
то есть с помощью функции lm, и теперь,
чтобы посчитать ковариационную матрицу
оценок коэффициентов, мы используем
команду vcovHAC для данной модели.
И использование правильных
стандартных ошибок решает
проблему с стандартными ошибками
для отдельно взятых коэффициентов.
Когда на практике следует
использовать эту формулу?
Как только вы подразумеваете
наличие зависимости
между близкими наблюдениями
в ваших данных и не хотите
заниматься специально моделированием
этой структуры зависимости.
То есть, если ваши данные представляют
собой временные ряды или ваши данные —
это данные, где имеет место географическая
близость между отдельно взятыми
наблюдениями, во всех этих случаях
имеет смысл использовать ошибки,
стандартные ошибки Нью-Веста, то есть
состоятельные в условиях автокорреляции.
Как можно обнаружить
автокорреляцию в имеющихся данных?
Как и в случае гетероскедастичности,
автокорреляцию можно обнаружить
графически и с помощью формальных тестов.
Для графического обнаружения
автокорреляции оценивают
исходную модель с помощью метода
наименьших квадратов, получают
остатки в исходной модели, то есть ε_1
с крышкой, ε_2 с крышкой и так далее.
А дальше на графике по одной оси,
по горизонтальной оси откладывают
предыдущий остаток ε_{t–1} с крышкой,
а по вертикали откладывают
следующий остаток ε_t с крышкой.
Соответственно, если зависимости
между остатками нет,
то облако получающихся точек
будет примерно похоже на круг.
А ежели зависимость между остатками есть,
если ε_t с крышечкой,
сегодняшний остаток зависит от вчерашнего,
от ε_{t–1} с крышечкой,
то тогда мы увидим облако,
вытянутое из первой четверти
в третью четверть графика.
Если же зависимость между ε_t с крышечкой
и ε_{t-1} с крышечкой  отрицательная,
то мы, соответственно, увидим облако
точек, вытянутое в другом направлении.
Теперь перейдем к формальным
тестам на автокорреляцию.
Два, пожалуй, самых известных теста — это
тест Дарбина-Уотсона и тест Бройша-Годфри.
Несмотря на большую применимость
теста Бройша-Годфри,
тест Дарбина-Уотсона
достаточно популярный,
поэтому я начну свое изложение с него,
хотя, конечно, он уступает
тесту Бройша-Годфри по своим возможностям,
то есть по предпосылкам использования.
Тест Дарбина-Уотсона гораздо более
ограничительный и требует выполнения
гораздо большего числа необходимых
предпосылок, чем тест Бройша-Годфри.
Итак, тест Дарбина-Уотсона.
Во-первых, тест Дарбина-Уотсона
предназначен только для тестирования
автокорреляций первого порядка,
то есть для тестирования гипотезы в рамках
предположения ε_t = ρ ε_{t–1} + u_t мы в
рамках этого предположения тестируем
гипотезу о том, что ρ = 0.
При этом предполагается
нормальность ошибок ε,
предполагается сильная
экзогенность ошибок,
то есть математическое ожидание от ε_t
при фиксированном X должно равняться 0.
И мы проверяем с помощью него нулевую
гипотезу об отсутствии автокорреляции,
то есть о том, что ρ = 0.
Процедура теста Дарбина-Уотсона следующая.
Шаг 1 — оценить исходную
модель с помощью МНК и
получить из исходной модели
остатки ε с крышечкой.
И второй шаг — посчитать статистику
Дарбина-Уотсона по формуле: дробь,
в числителе сумма квадратов
разностей ε_i – ε_{i–1} с крышечками,
и в знаменателе просто
сумма квадратов остатков.
К сожалению,
распределение статистики Дарбина-Уотсона,
даже при выполнении
гипотезы H0 об отсутствии автокорреляции
является довольно неприятным.
Оно сложным образом
нетривиальным зависит от X.
К счастью, можно сделать некоторые простые
качественные выводы, основываясь на том,
что статистика Дарбина-Уотсона примерно
равна 2 *(1 – оценку корреляций ρ).
Поэтому, качественные выводы получаются
следующие: если статистика Дарбина-Уотсона
около нуля, это означает корреляцию ρ
с крышечкой, оцененную около единички.
То есть статистика Дарбина-Уотсона около
нуля означает сильную зависимость между
сегодняшним ε и предыдущим,
сильную положительную зависимость.
Статистика Дарбина-Уотсона около 2
означает отсутствие автокорреляции.
И статистика Дарбина-Уотсона около 4
означает сильную отрицательную корреляцию,
примерно равную –1 между
сегодняшним ε и вчерашним.
Несмотря на сложный закон распределения
статистики Дарбина-Уотсона,
на практике все довольно просто.
Статистические пакеты, такие как R,
автоматически рассчитывают P-значение
для теста Дарбина-Уотсона, поэтому мы
просто можем сравнить посчитанное в
R P-значение с уровнем значимости.
Если оно оказывается меньше
5 % посчитанное P-значение,
то мы отвергаем гипотезу об
отсутствии автокорреляции и таким
образом признаем наличие автокорреляции,
а если P-значение велико,
больше 5 %, то мы не отвергаем
гипотезу об отсутствии автокорреляции.
Ну и существуют таблицы,
в которых указаны границы для
критического значения статистики
Дарбина-Уотсона, но эти таблицы,
скорее, представляют исторический интерес.
А сейчас мы рассмотрим второй тест,
менее требовательный по предпосылкам,
чем тест Дарбина-Уотсона,
поэтому более распространенный, а именно
тест Бройша-Годфри.

