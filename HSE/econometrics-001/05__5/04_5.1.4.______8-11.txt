
﻿1
00:00:13,270 --> 00:00:17,523
Давайте попытаемся ответить
на вопрос: когда в
реальности может возникать
гетероскедастичность?
Я напомню, что мы работаем в парадигме,
где мы предполагаем, что наши регрессоры
являются случайными, и наши наблюдения
являются случайной выборкой из какой-то
большой генеральной совокупности,
то есть отдельно взятые наблюдения x_i,
y_i не зависят от наблюдений x_j,
y_j и имеют одинаковое с ним распределение.
Откуда же может взяться разная условная
дисперсия случайной ошибки ε_i?
Ответ на этот вопрос довольно прост.
Ну давайте, например,
возьмём выборку предприятий.
Скажем, исследователь моделирует
зависимость прибыли от каких-то
характеристик предприятия.
Естественно ожидать, что на крупном
предприятии колебания прибыли от месяца
к месяцу гораздо более значительные,
чем на маленьком предприятии.
На крупном предприятии колебания в
прибыли в сто тысяч рублей в месяц
могут быть совершенным пустяком, в то
время как сумма такая для индивидуального
предпринимателя может быть максимумом,
который он может заработать за месяц.
То есть когда мы в реальности видим,
что к нам в выборку могут попасть объекты
разного размера, — при этом размером может
быть что угодно: на предприятии это может
быть, скажем, численность персонала; если
мы исследуем какую-нибудь зависимость,
скажем, расходов домохозяйств
от каких-то их характеристик,
то размером объекта будет являться
численность домохозяйства; или, скажем,
если мы пытаемся понять,
от чего зависят расходы человека на отдых,
то тут в каком-то смысле размером
может быть доход: чем больше доход,
тем больше будут колебаться
расходы человека на отдых, тот,
у кого нет возможности поехать
и тратить много на отдых,
у него будут небольшие колебания расходов
на отдых, а тот, кто может в один
сезон поехать куда-то очень далеко,
сделать много поездок за короткое время,
— у него колебания расходов,
скорее всего, будут существенно выше.
То есть как только у нас в выборке могут
попасться объекты разного размера,
что бы этот размер ни значил,
скорее всего, есть основания подозревать
наличие условной гетероскедастичности.
Ну а поскольку тот или иной
размер есть и у домохозяйства,
и у предприятия,
и у отдельно взятого индивида,
то поэтому мы получаем,
что гетероскедастичность условная имеет
место практически в
любой случайной выборке.
Поэтому с гетероскедастичностью мы
сталкиваемся практически постоянно.
Давайте посмотрим,
чем нам грозит столь частое явление.
Во-первых, отметим, что мы изучаем
гетероскедастичность отдельно от
других нарушений,
потенциальных нарушений предпосылок.
То есть сейчас мы предполагаем,
что имеет место строгая экзогенность,
то есть математическое ожидание ошибки
ε_i при фиксированных X равно нулю.
Мы также предполагаем,
что у нас математическое ожидание
произведения двух ε_i,
ε_j при фиксированном X также равно нулю,
то есть нет зависимости между ε_i, ε_j,
относящимся к разным наблюдениям.
Мы также предполагаем, что у нас,
естественно, наблюдений больше,
чем параметров в линейной зависимости,
которую мы хотим оценить.
Мы предполагаем,
что у нас матрица регрессоров имеет
полный ранг с вероятностью 1,
то есть, говоря более простым языком,
с вероятностью 1 среди объясняющих
переменных нет линейно зависимых.
Мы по-прежнему предполагаем
случайную выборку,
то есть отдельные наблюдения являются
независимыми и одинаково распределёнными,
то есть никакие другие предпосылки
стандартной модели у нас не нарушены.
И мы по случайности, по незнанию
или намеренно используем старые формулы,
которые, мы доказали,
что являются очень хорошими оценками
в случае условной гомоскедастичности.
То есть мы используем классические
оценки метода наименьших квадратов для
неизвестных коэффициентов β,
и именно: у нас β с крышкой равняется
X'X в минус 1 помножить
на X транспонированное y.
И мы используем стандартную
формулу для оценок дисперсии,
оценок метода наименьших квадратов,
а именно: сумма квадратов остатков,
делённая на (n – k),
помножить на X'X в минус 1.
То есть мы используем стандартные
формулы как для оценок самих
коэффициентов β с крышкой,
также мы используем стандартные формулы
для оценки дисперсии коэффициентов.
Ну в частности, оценка для
отдельно взятой дисперсии одного
коэффициента — это σ² с крышкой,
RSS,
делённое на (n – k),
делённое на RSS_j, то есть RSS,
которое получается в регрессии j-того
объясняющей переменной на остальные.
И вот мы используем стандартные
формулы и посмотрим,
к каким последствиям это приведёт.
Давайте перечислим сначала все те выводы,
которые были у нас,
когда ни одна предпосылка
не была нарушена.
Итак, у нас свойства делились на
свойства для конечных выборок и
асимптотические свойства.
Сначала рассмотрим свойства
для конечных выборок.
Свойства для конечных выборок, в свою
очередь, у нас делились на два класса:
свойства, в которых предполагалась
нормальность ошибок ε_i-тых,
и свойства, в которых нормальность
ошибок не требовалась.
Какие свойства, не требующие
нормальности ошибок ε_i-тых, у нас были?
Ну, во-первых, это линейность по y.
То есть, что она означает?
Она означает, что при увеличении всех y,
всех объясняющих переменных,
в 10 раз, у нас все оценки β с
крышкой увеличивались в 10 раз.
К счастью, это свойство остаётся.
Поскольку используется старая формула для
β с крышкой, поскольку в ней y входит
линейно, то по-прежнему
линейность оценок у нас осталась.
Второе свойство, которое не
требует нормальности ε и выполнено
для конечных выборок,
это условная несмещённость оценок,
или просто несмещённость,
то есть математическое ожидание оценок β с
крышкой при фиксированных регрессорах X,
равнялось раньше β.
Это свойство по-прежнему выполнено,
то есть, в среднем, получаемые нами
оценки могут попасть то слева,
то справа от неизвестного коэффициента,
но в среднем попадают в неизвестный
коэффициент, и это очень приятная новость.
Это говорит о том, что, да, мы иногда,
когда оцениваем неизвестные параметры,
можем иногда завысить истину или занизить,
но, в среднем, мы не ошибаемся.
Следующая новость, к сожалению, плохая.
Мы говорили, что без требования
нормальности ε для конечных
выборок оценки β с крышкой, получаемых
по методу наименьших квадратов при
выполнении всех предпосылок, — они были
эффективны, то есть они были наилучшими.
То есть нельзя было придумать
альтернативную оценку,
— β с крышкой альтернативная,
— которая была бы несмещённой,
линейной и при этом которая была бы лучше,
у которой была бы меньше дисперсия.
На этот раз это свойство не выполнено,
и, соответственно,
получаемые нами оценки,
хотя они несмещённые, они не самые
лучшие: у них не самая маленькая
дисперсия, которая могла бы быть.

