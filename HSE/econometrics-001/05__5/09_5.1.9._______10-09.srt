1
00:00:13,135 --> 00:00:20,740
Подведём небольшой итог
воздействия гетероскедастичности.

2
00:00:20,740 --> 00:00:24,280
Итак, если нарушена предпосылка
о гомоскедастичности,

3
00:00:24,280 --> 00:00:28,835
то мы теряем, прежде всего,
проверку гипотез по старым формулам.

4
00:00:28,835 --> 00:00:33,390
То есть при использовании старой формулы
для t-статистики невозможно проверять

5
00:00:33,390 --> 00:00:39,916
гипотезы на конечных выборках, и даже
асимптотически при большом n результаты

6
00:00:39,916 --> 00:00:44,870
использования старых t-статистики,
f-статистики будут неверными.

7
00:00:44,870 --> 00:00:50,125
Однако с использованием стандартных
ошибок, устойчивых к гетероскедастичности,

8
00:00:50,125 --> 00:00:54,767
мы можем проверять гипотезы о значимости
коэффициентов и строить доверительные

9
00:00:54,767 --> 00:00:59,590
интервалы при большом n
асимптотически при больших выборках.

10
00:00:59,590 --> 00:01:05,714
К сожалению,
использование стандартных ошибок,

11
00:01:05,714 --> 00:01:10,839
устойчивых к гетероскедастичности,
не спасает нас в очень малых

12
00:01:10,839 --> 00:01:15,907
выборках, и кроме этого оно не
добавляет эффективности оценок,

13
00:01:15,907 --> 00:01:20,230
поскольку оценки мы по-прежнему считали
старым способом и никак их не подправляли.

14
00:01:20,230 --> 00:01:25,280
Возникает вопрос: что же делать
с потерянной эффективностью?

15
00:01:25,280 --> 00:01:29,342
На практике ответ чаще звучит
всего следующим образом: увы,

16
00:01:29,342 --> 00:01:33,503
надо смериться с тем,
что наши оценки стали неэффективными.

17
00:01:33,503 --> 00:01:37,706
Мы можем довольствоваться тем,
что они несмещённые, состоятельные,

18
00:01:37,706 --> 00:01:41,742
и при использовании новых робастных
формул для стандартных ошибок мы

19
00:01:41,742 --> 00:01:45,780
можем проверять гипотезы при
достаточном количестве наблюдений.

20
00:01:45,780 --> 00:01:51,901
Хотя теорема на этот раз утверждает,
что наши оценки

21
00:01:51,901 --> 00:01:57,073
потеряли эффективность, а, значит, где-то
есть более эффективные оценки, на практике

22
00:01:57,073 --> 00:02:02,070
построение этих мифических более
эффективных оценок практически невозможно.

23
00:02:02,070 --> 00:02:09,966
В редких случаях, когда это всё-таки
удаётся, нужно очень хорошо понимать,

24
00:02:09,966 --> 00:02:15,140
как конкретно устроена условная
дисперсия εi при фиксированном X.

25
00:02:15,140 --> 00:02:20,103
То есть вы должны чётко осознавать или
сделать какие-то очень ограничивающие

26
00:02:20,103 --> 00:02:22,630
предположения о структуре дисперсии.

27
00:02:22,630 --> 00:02:27,439
Если вы их сделали, то вы можете
получить более эффективные оценки,

28
00:02:27,439 --> 00:02:30,380
чем оценки метода наименьших квадратов.

29
00:02:30,380 --> 00:02:34,354
Давайте разберём простой пример,
в котором посмотрим,

30
00:02:34,354 --> 00:02:39,755
как конкретно это сделать, если бы мы
знали структуру гетероскедастичности.

31
00:02:39,755 --> 00:02:44,414
То есть мы сделаем ограничивающие
предположения и посмотрим, как в рамках

32
00:02:44,414 --> 00:02:49,031
этих ограничивающих предположений получить
более эффективные оценки, чем оценки

33
00:02:49,031 --> 00:02:53,730
метода наименьших квадратов для исходной
модели с условной гетероскедастичностью.

34
00:02:53,730 --> 00:02:59,234
Сейчас мы на примере разберём,
как в некоторых очень редких ситуациях

35
00:02:59,234 --> 00:03:05,051
можно построить эффективные оценки
в условиях гетероскедастичности.

36
00:03:05,051 --> 00:03:10,200
Итак, предположим,
что мы исследуем результат по математике,

37
00:03:10,200 --> 00:03:15,990
средний результат, скажем,
ЕГЭ в разных классах, в разных школах.

38
00:03:15,990 --> 00:03:20,689
То есть, соответственно, mi — это средний
результат какого-то i-того класса по

39
00:03:20,689 --> 00:03:24,821
математике, и мы предполагаем,
что у нас есть следующие данные.

40
00:03:24,821 --> 00:03:30,797
Нам доступно, скажем: размер
класса ri — размер i-того класса,

41
00:03:30,797 --> 00:03:37,009
плюс мы опросили учащихся класса и
выяснили некое среднее количество времени,

42
00:03:37,009 --> 00:03:42,098
которое учащиеся каждого класса тратили
на домашнее задание по математике,

43
00:03:42,098 --> 00:03:45,713
там, скажем,
тут введём переменную ti, плюс εi.

44
00:03:45,713 --> 00:03:52,120
Такая простая, несложная модель, то есть
средний результат каждого класса — это,

45
00:03:52,120 --> 00:03:57,412
соответственно, размер каждого класса
и это средние затраты времени,

46
00:03:57,412 --> 00:04:00,840
измеренные во времени
на занятие математикой.

47
00:04:00,840 --> 00:04:03,946
И, соответственно, первый вопрос.

48
00:04:03,946 --> 00:04:10,576
Он, скорее, не по математике, а,
скорее, вот по здравому смыслу.

49
00:04:10,576 --> 00:04:17,550
Какую структуру гетероскедастичности
логично ожидать в этой модели?

50
00:04:17,550 --> 00:04:21,460
Логично ожидать.

51
00:04:21,460 --> 00:04:26,641
То есть от каких из имеющихся
переменных мы стали бы ожидать

52
00:04:26,641 --> 00:04:31,400
зависимости дисперсии εi
просто по здравому смыслу?

53
00:04:31,400 --> 00:04:35,033
И второй вопрос уже
относится к математике.

54
00:04:35,033 --> 00:04:41,133
Если получить вот эту осмысленную
структуру гетероскедастичности,

55
00:04:41,133 --> 00:04:46,010
то как получить эффективные

56
00:04:46,010 --> 00:04:52,688
оценки, эффективные оценки β с крышкой?

57
00:04:52,688 --> 00:04:56,850
Потому что мы говорили,
что корректировка стандартных ошибок,

58
00:04:56,850 --> 00:05:00,526
которая используется как одна из мер
по борьбе с гетероскедастичностью,

59
00:05:00,526 --> 00:05:04,800
— она позволяет проверять гипотезы, но не
позволяет получать эффективные оценки.

60
00:05:04,800 --> 00:05:07,059
Но перейдём к первому вопросу.

61
00:05:07,059 --> 00:05:12,175
Какую структуру гетероскедастичности
здесь логично ожидать в этой модели?

62
00:05:12,175 --> 00:05:17,431
Поскольку mi — это средний результат
класса, то что собой представляет mi?

63
00:05:17,431 --> 00:05:23,645
Это складываются результаты каждого
ученика: mi первого ученика плюс mi

64
00:05:23,645 --> 00:05:30,690
второго ученика плюс и так далее плюс mi —
всего у меня в i-том классе ri учеников.

65
00:05:30,690 --> 00:05:35,758
И делится, естественно,
на количество учеников в классе.

66
00:05:35,758 --> 00:05:39,721
Соответственно, если,
скажем, предположить,

67
00:05:39,721 --> 00:05:44,087
что результаты учащихся независимые
и имеют одинаковую дисперсию,

68
00:05:44,087 --> 00:05:50,766
то есть если сделать предположение, что
дисперсия результата каждого ученика mij,

69
00:05:50,766 --> 00:05:56,681
— то есть это результат учащегося,
j-тый номер учащегося в i-том классе,

70
00:05:56,681 --> 00:06:01,641
— если предположить,
что эта дисперсия равна какой-то,

71
00:06:01,641 --> 00:06:06,361
пусть будет σ-квадрат, и mij независимы,

72
00:06:06,361 --> 00:06:11,590
то тогда мы получим результат,
что дисперсия

73
00:06:11,590 --> 00:06:17,455
mi как дисперсия среднего арифметического,
— она, соответственно,

74
00:06:17,455 --> 00:06:24,510
равна σ-квадрат, делённое на
количество наблюдений, то есть на ri.

75
00:06:24,510 --> 00:06:28,486
То есть у нас имеет место условная
гетероскедастичность, но не абы какая,

76
00:06:28,486 --> 00:06:30,360
а вполне определённой структуры.

77
00:06:30,360 --> 00:06:34,412
А если нам структура гетероскедастичности
доподлинно известна, что бывает очень

78
00:06:34,412 --> 00:06:38,880
редко, то есть эта модель с усреднением —
один из немногих примеров такой ситуации,

79
00:06:38,880 --> 00:06:42,391
— то мы можем легко откорректировать
гетероскедастичность.

80
00:06:42,391 --> 00:06:49,577
Как избавиться от данной
гетероскедастичности?

81
00:06:49,577 --> 00:06:52,680
Оказывается, очень легко.

82
00:06:52,680 --> 00:06:56,433
Действительно, если мы предполагаем,

83
00:06:56,433 --> 00:07:01,980
что дисперсия εi при
фиксированных X равна σ-квадрат,

84
00:07:01,980 --> 00:07:07,591
делённое на ri, то что нам нужно сделать,
чтобы дисперсия стала постоянной?

85
00:07:07,591 --> 00:07:11,470
Ответ очень простой: надо внутри
домножить на корень из ri.

86
00:07:11,470 --> 00:07:16,508
Если я возьму дисперсию
корень из ri помножить на εi

87
00:07:16,508 --> 00:07:22,358
при фиксированных X, то корень из
ri будет выноситься с квадратом,

88
00:07:22,358 --> 00:07:27,686
то есть будет получаться ri,
а дисперсия εi — это σ-квадрат на ri.

89
00:07:27,686 --> 00:07:29,741
И получается σ-квадрат.

90
00:07:29,741 --> 00:07:33,865
Получается, что если бы
остатком в модели было не εi,

91
00:07:33,865 --> 00:07:38,426
а корень из ri помножить на εi, тогда
бы модель была с гомоскедастичностью.

92
00:07:38,426 --> 00:07:41,585
Поэтому вопрос,
как получить эффективные оценки,

93
00:07:41,585 --> 00:07:44,705
— да надо просто всё
домножить на корень из ri.

94
00:07:44,705 --> 00:07:49,674
То есть вместо вот этой исходной модели
мы будем оценивать другую модель,

95
00:07:49,674 --> 00:07:55,285
модель с гомоскедастичностью, а именно:
мы будем, все помножим на корень из ri.

96
00:07:55,285 --> 00:08:01,353
У нас получится модель: корень из ri
помножить на mi равняется β1 помножить на

97
00:08:01,353 --> 00:08:06,782
корень из ri плюс β2 помножить
на ri в степени 3/2 плюс

98
00:08:06,782 --> 00:08:12,539
β3 помножить на ti помножить
на корень из ri плюс — здесь,

99
00:08:12,539 --> 00:08:17,670
естественно, окажется корень из ri
умножить на εi, я эту новую случайную

100
00:08:17,670 --> 00:08:23,370
составляющую назову ui, то есть ui
— это корень из ri помножить на εi.

101
00:08:23,370 --> 00:08:28,331
И дальше я с помощью обычного
метода наименьших квадратов...

102
00:08:28,331 --> 00:08:34,360
Вот это модель B, а это модель A.

103
00:08:34,360 --> 00:08:38,375
Дальше я буду оценивать модель B,

104
00:08:38,375 --> 00:08:43,081
с помощью обычного метода наименьших
квадратов оценю модель B.

105
00:08:43,081 --> 00:08:46,770
И оценив модель B,

106
00:08:46,770 --> 00:08:53,190
я получу эффективные оценки β с крышкой
несмещённые и с наименьшей дисперсией.

107
00:08:53,190 --> 00:08:56,335
То есть я получу β1 с крышкой,
β2 с крышкой и β3 с крышкой,

108
00:08:56,335 --> 00:08:58,648
используя метод наименьших квадратов.

109
00:08:58,648 --> 00:09:01,830
Единственно, на что здесь
следует обратить внимание,

110
00:09:01,830 --> 00:09:06,710
что модель B не содержит в себе...

111
00:09:06,710 --> 00:09:12,187
Вот здесь нет единичного столбца, то есть
если я буду записывать матрицу регрессоров

112
00:09:12,187 --> 00:09:17,738
для модели B, то матрица регрессоров — она
не будет содержать единичного столбца.

113
00:09:17,738 --> 00:09:21,630
Здесь будет, первый столбик,
это будет корень из r1.

114
00:09:21,630 --> 00:09:26,080
Второй столбик будет
начинаться r1 в степени 3/2.

115
00:09:26,080 --> 00:09:33,680
И третий столбик будет t1 на корень из
r1 и так далее до n-ного наблюдения,

116
00:09:33,680 --> 00:09:39,791
корень из rn, rn в степени 3/2,
а здесь будет tn на корень из rn.

117
00:09:39,791 --> 00:09:41,618
То есть среди регрессоров,

118
00:09:41,618 --> 00:09:45,190
матрица всех регрессоров единичного
столбца содержать не будет.

119
00:09:45,190 --> 00:09:50,016
Но, тем не менее, вот такой простой трюк,
домножение, построенное таким образом,

120
00:09:50,016 --> 00:09:54,067
чтобы дисперсия новой случайной
составляющей вышла на константу,

121
00:09:54,067 --> 00:09:58,967
— при использовании такого простого трюка
мы можем оценить модель методом наименьших

122
00:09:58,967 --> 00:10:04,040
квадратов и получить эффективные оценки,
то есть оценки с наименьшей дисперсией.

