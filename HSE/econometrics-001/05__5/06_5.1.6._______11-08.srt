1
00:00:12,405 --> 00:00:17,907
Кратко подводя итог сохранившимся

2
00:00:17,907 --> 00:00:22,073
свойствам и потерянным
свойствам при нарушении

3
00:00:22,073 --> 00:00:26,796
предпосылки об условной
гомоскедастичности, то есть в ситуации,

4
00:00:26,796 --> 00:00:31,750
когда дисперсия εi при фиксированных
иксах зависит от иксов,

5
00:00:31,750 --> 00:00:35,060
можно подвести итоги следующим образом.

6
00:00:35,060 --> 00:00:38,734
Во-первых, сами β с крышкой
по-прежнему довольно хороши,

7
00:00:38,734 --> 00:00:43,390
их можно интерпретировать,
их можно использовать при прогнозировании.

8
00:00:43,390 --> 00:00:48,671
Однако основная проблема лежит не в
самих β с крышкой, сами то β с крышкой

9
00:00:48,671 --> 00:00:53,600
и состоятельные и несмещенные, и в
среднем вокруг неизвестного коэффициента

10
00:00:53,600 --> 00:00:57,375
и при большом количестве наблюдений
похожи все более и более на него.

11
00:00:57,375 --> 00:00:59,597
Проблема лежит не в β с крышкой.

12
00:00:59,597 --> 00:01:03,640
Проблема лежит в стандартных
ошибках β с крышкой j-тое.

13
00:01:03,640 --> 00:01:08,108
Эти стандартные ошибки,
к сожалению, несостоятельны.

14
00:01:08,108 --> 00:01:11,038
То есть даже при большом количестве

15
00:01:11,038 --> 00:01:15,920
наблюдений дисперсия оценки
оценивается неправильно.

16
00:01:15,920 --> 00:01:19,105
Это приводит к тому, что несмотря на то,

17
00:01:19,105 --> 00:01:22,764
что мы можем посчитать β
с крышкой j-тое точечно,

18
00:01:22,764 --> 00:01:27,343
можем построить прогноз точечный, но мы
не можем строить доверительные интервалы,

19
00:01:27,343 --> 00:01:32,180
мы не можем сказать, используя
стандартные ошибки, насколько мы уверены,

20
00:01:32,180 --> 00:01:36,430
каков диапазон, разброс для
истинного значения коэффициента.

21
00:01:36,430 --> 00:01:40,150
То есть точечные оценки коэффициентов,
они хорошие,

22
00:01:40,150 --> 00:01:45,912
а вот построить доверительный интервал
для неизвестного βj или построить

23
00:01:45,912 --> 00:01:50,209
доверительный интервал для прогноза, мы,
используя старые стандартные ошибки,

24
00:01:50,209 --> 00:01:56,198
не можем, потому что они несостоятельные
в условиях условной гетероскедастичности.

25
00:01:56,198 --> 00:01:57,340
Что же делать?

26
00:01:57,340 --> 00:02:01,890
Ответ: использовать другие
стандартные ошибки.

27
00:02:01,890 --> 00:02:04,078
Раз старые стандартные ошибки,

28
00:02:04,078 --> 00:02:08,707
которые находились как корни из
диагональных элементов матрицы Var с

29
00:02:08,707 --> 00:02:13,970
крышкой β с крышкой равное RSS
делить на минус k на X'X в минус 1.

30
00:02:13,970 --> 00:02:18,810
Раз они не состоятельны,
и их поэтому не нужно использовать,

31
00:02:18,810 --> 00:02:22,030
значит вместо них надо
использовать что-то другое.

32
00:02:22,030 --> 00:02:25,851
И эти другие ошибки,

33
00:02:25,851 --> 00:02:30,462
которые исправят нам большинство проблем,

34
00:02:30,462 --> 00:02:33,651
они были придуманы еще в прошлом веке.

35
00:02:33,651 --> 00:02:37,620
Это работа Уайта 1980 года,
который предложил

36
00:02:37,620 --> 00:02:43,311
корректировку для стандартных ошибок,

37
00:02:43,311 --> 00:02:48,572
а именно стандартные ошибки β с
крышкой — это та же X'X в минус

38
00:02:48,572 --> 00:02:53,580
1 на X' на оценку матрицы
Ω на X'X в минус 1,

39
00:02:53,580 --> 00:02:58,111
где Ω — это диагональная матрица,
где по диагонали находятся

40
00:02:58,111 --> 00:03:02,717
квадраты остатков из
обычной mnk регрессии.

41
00:03:02,717 --> 00:03:07,425
То есть оценка Уайта,
она очень проста по структуре.

42
00:03:07,425 --> 00:03:11,600
Сначала строится обычная регрессия,
с помощью обычного mnk,

43
00:03:11,600 --> 00:03:13,795
по старой формуле считается β с крышкой.

44
00:03:13,795 --> 00:03:17,990
После этого точно также
считаются ошибки ε с крышкой.

45
00:03:17,990 --> 00:03:23,567
А после этого каждая из ошибок из остатков
ε с крышкой возводится в квадрат.

46
00:03:23,567 --> 00:03:26,215
Получается диагональная матрица,

47
00:03:26,215 --> 00:03:30,162
на диагонали квадраты остатков,
вне диагонали – нули.

48
00:03:30,162 --> 00:03:35,418
Эта матрица подставляется в формулу
для Var с крышкой β с крышкой,

49
00:03:35,418 --> 00:03:40,324
и получаются другие оценки
дисперсии β с крышкой.

50
00:03:40,324 --> 00:03:46,739
Они называются HC, что означает
heteroskedasticity consistent,

51
00:03:46,739 --> 00:03:49,817
то есть состоятельные в
условиях гетероскедастичности.

52
00:03:49,817 --> 00:03:54,411
То есть если мы будем использовать эти
стандартные ошибки, полученные как корни

53
00:03:54,411 --> 00:03:59,280
из диагональных элементов этой матрицы,
то ситуация значительно исправится.

54
00:03:59,280 --> 00:04:04,560
Современный вариант этой формулы чуть-чуть
сложнее, чем был предложен Уайтом.

55
00:04:04,560 --> 00:04:09,120
Он также асимптотически устойчив,
робастен к гетероскедастичности,

56
00:04:09,120 --> 00:04:13,904
но на малых выборках ведет себя
немножко лучше, то есть для

57
00:04:13,904 --> 00:04:18,330
малых выборок получаются более корректные,
более точные доверительные интервалы.

58
00:04:18,330 --> 00:04:23,860
Соответственно, с точки зрения практика,
ситуация очень простая.

59
00:04:23,860 --> 00:04:30,114
Мы вместо старой формулы
для стандартных ошибок β

60
00:04:30,114 --> 00:04:35,379
с крышкой j используем новую формулу
для стандартных ошибок β с крышкой j,

61
00:04:35,379 --> 00:04:39,894
которую мы будем помечать
стандартные ошибки с индексом НС,

62
00:04:39,894 --> 00:04:43,770
то есть состоятельные в
условиях гетероскедастичности.

63
00:04:43,770 --> 00:04:48,265
Если мы используем эту формулу,
то что меняется?

64
00:04:48,265 --> 00:04:54,571
К сожалению, точных распределений в
конечных выборках получить не удается.

65
00:04:54,571 --> 00:04:59,307
Однако ассимптотические
результаты с использованием новых

66
00:04:59,307 --> 00:05:02,853
стандартных ошибок совпадают со старыми.

67
00:05:02,853 --> 00:05:08,639
То есть если мы в формуле t-статистики
вместо обычных стандартных ошибок будем

68
00:05:08,639 --> 00:05:13,590
использовать стандартные ошибки устойчивой
гетероскедастичности, то t-статистики

69
00:05:13,590 --> 00:05:17,750
при большом количестве наблюдений
будут иметь нормальные распределения,

70
00:05:17,750 --> 00:05:22,685
а это как раз нам и нужно для проверки
гипотез о значимости коэффициентов.

71
00:05:22,685 --> 00:05:27,005
Соответственно, с точки зрения практика,
все довольно просто.

72
00:05:27,005 --> 00:05:31,790
Мы, если исследователь использует R,
он запускает R, там есть команда vcovHC

73
00:05:31,790 --> 00:05:36,156
для оценки ковариационной
матрицы оценки коэффициентов, и,

74
00:05:36,156 --> 00:05:39,306
соответственно, эта оценка
является состоятельной,

75
00:05:39,306 --> 00:05:43,385
и ее можно прекрасно использовать для
проверки гипотез, построения доверительных

76
00:05:43,385 --> 00:05:47,661
интервалов для коэффициентов, построения
доверительных интервалов для прогнозов.

77
00:05:47,661 --> 00:05:53,591
Поэтому, с точки зрения практика,
как только у нас есть случайная выборка,

78
00:05:53,591 --> 00:05:58,665
и мы подозреваем,
что у нас в выборке могут быть объекты

79
00:05:58,665 --> 00:06:03,729
с разным разбросом εi,
то есть, проще говоря,

80
00:06:03,729 --> 00:06:08,804
если мы видим, что к нам в выборку
могут попасть объекты разного размера.

81
00:06:08,804 --> 00:06:11,970
Это могут быть предприятия
разной численности,

82
00:06:11,970 --> 00:06:16,275
это могут быть домохозяйства разного
размера, это могут быть страны,

83
00:06:16,275 --> 00:06:18,988
если мы исследуем какие-то
страновые показатели.

84
00:06:18,988 --> 00:06:22,256
Опять же, у всех этих объектов
естествено понятие размера.

85
00:06:22,256 --> 00:06:25,843
Оно может быть разным,
что считать размером страны — площадь ли,

86
00:06:25,843 --> 00:06:31,264
количество ли жителей, это — отдельный
вопрос, но тем не менее даже страны,

87
00:06:31,264 --> 00:06:37,316
домохозяйства, фирмы, индивиды отличаются
по какой-то своей характеристике размера,

88
00:06:37,316 --> 00:06:40,551
и нам логично ожидать условную
гетероскедастичность.

89
00:06:40,551 --> 00:06:44,223
И поэтому, как только мы ожидаем
условную гетероскедастичность,

90
00:06:44,223 --> 00:06:49,490
мы тут же вместо обычных стандартных
ошибок используем стандартные ошибки

91
00:06:49,490 --> 00:06:54,638
Уайта или современную подправку
стандартных ошибок, и, соответственно,

92
00:06:54,638 --> 00:06:59,168
тогда спокойно проверяем гипотезы о
значимости отдельного коэффициента или

93
00:06:59,168 --> 00:07:03,350
строим доверительные интервалы или строим
доверительные интервалы для прогнозов.

94
00:07:03,350 --> 00:07:05,599
Как увидеть гетероскедастичность?

95
00:07:05,599 --> 00:07:09,540
Во-первых, гетероскедастичность
можно увидеть графически.

96
00:07:09,540 --> 00:07:15,627
Если вы оцените на первом шаге
модель методом наименьших квадратов,

97
00:07:15,627 --> 00:07:21,190
а потом по горизонтали отложите тот
регрессор, который, вы подозреваете,

98
00:07:21,190 --> 00:07:26,864
связан с условной дисперсией ε, то,
соответственно, вы можете по вертикали

99
00:07:26,864 --> 00:07:32,315
отложить просто модуль остатка, модуль
ε с крышкой и ε с крышкой в квадрате.

100
00:07:32,315 --> 00:07:37,430
То есть в каком-то смысле
расстояние от ε с крышкой до нуля.

101
00:07:37,430 --> 00:07:42,846
Мы знаем, что ε с крышкой похожа на ε,
а это означает, что,

102
00:07:42,846 --> 00:07:48,431
чтобы проверить — правда ли,
что разборос ε зависит от х,

103
00:07:48,431 --> 00:07:52,854
можно проверять похожую идею
графически — а правда ли,

104
00:07:52,854 --> 00:07:55,263
что разброс ε с крышкой зависит от х?

105
00:07:55,263 --> 00:07:56,910
Перед вами два графика.

106
00:07:56,910 --> 00:08:01,738
На одном из них вы видите,
что размер остатка ε с

107
00:08:01,738 --> 00:08:06,780
крышкой в квадрате растет
с размером регрессора х.

108
00:08:06,780 --> 00:08:10,790
Это говорит о возможной
гетероскедастичности.

109
00:08:10,790 --> 00:08:15,286
На втором графике видно, что размер
остатка, измеряемый с помощью ε с

110
00:08:15,286 --> 00:08:19,620
крышкой в квадрате,
практически стабилен для разных иксов.

111
00:08:19,620 --> 00:08:23,860
Это, скорее, указывает на
гомоскедастичность, то есть на то,

112
00:08:23,860 --> 00:08:28,570
что условная дисперсия ε при
фиксированном х не зависит от х.

113
00:08:28,570 --> 00:08:31,990
Существует ряд формальных тестов,
помимо графики,

114
00:08:31,990 --> 00:08:35,188
ряд формальных тестов на
гетероскедастичность.

115
00:08:35,188 --> 00:08:40,175
Самыми известными и самыми,
по всей видимости, применяемыми и немножко

116
00:08:40,175 --> 00:08:45,100
разными по своим идеям, являются тест
Уайта и тест Голдфельда-Квандта.

117
00:08:45,100 --> 00:08:50,670
Это, конечно, не все тесты на
гетероскедастичность, но их много,

118
00:08:50,670 --> 00:08:56,790
и по сути они приближаются либо к
тесту Уайта, либо Голдфельда-Квандта.

119
00:08:56,790 --> 00:08:59,904
Разберем сначала тест Уайта.

120
00:08:59,904 --> 00:09:03,496
Тест Уайта, он ассимптотический,
то есть он применим,

121
00:09:03,496 --> 00:09:05,660
когда у вас достаточно много наблюдений.

122
00:09:05,660 --> 00:09:09,930
В тесте Уайта не требуется
нормальность εi-тых.

123
00:09:09,930 --> 00:09:12,325
Тест Уайта устроен следующим образом.

124
00:09:12,325 --> 00:09:16,770
Он делается с помощью одной
дополнительной вспомогательной регрессии.

125
00:09:16,770 --> 00:09:21,266
Сначала оценивается исходная модель.

126
00:09:21,266 --> 00:09:26,030
И оценив исходную модель,
вы получаете остатки ε с крышкой.

127
00:09:26,030 --> 00:09:30,392
И дальше вы оцениваете вспомогательную
регрессию, то есть вы берете квадраты

128
00:09:30,392 --> 00:09:35,966
полученных в первой регрессии остатков
ε с крышкой i-тая в квадрате.

129
00:09:35,966 --> 00:09:40,950
И строите регрессии на те переменные, от
которых, по вашему мнению, может зависеть

130
00:09:40,950 --> 00:09:45,930
условная гетероскедастичность,
условная дисперсия ε.

131
00:09:45,930 --> 00:09:50,794
Если вы не знаете, от каких факторов
может зависеть условная дисперсия ε,

132
00:09:50,794 --> 00:09:56,120
тогда в качестве факторов
берут исходные регрессоры,

133
00:09:56,120 --> 00:10:02,110
их квадраты и попарные произведения
исходных регрессоров в основной модели.

134
00:10:02,110 --> 00:10:06,992
После этого вы в вспомогательной регрессии
вы считаете R-квадрат вспомогательной и

135
00:10:06,992 --> 00:10:11,210
умножаете его на n,
получаете значения статистики Уайта.

136
00:10:11,210 --> 00:10:16,032
И Уайт в своей работе доказал,
что при верной Н0,

137
00:10:16,032 --> 00:10:20,570
то есть при гипотезе об
условной гомоскедастичности,

138
00:10:20,570 --> 00:10:26,360
то есть при условии о том, что дисперсия
εi-тых при фиксированном x постоянна,

139
00:10:26,360 --> 00:10:30,620
эта статистика имеет χ квадрат
распределение с n в минус 1 степенью

140
00:10:30,620 --> 00:10:34,021
свободы, где n — это число параметров
во вспомогательной регрессии, а,

141
00:10:34,021 --> 00:10:40,748
соответственно, n минус 1 — это
количество осмысленных объясняющих

142
00:10:40,748 --> 00:10:44,880
переменных во вспомогательной регрессии,
то есть кроме единичного столбца.

143
00:10:44,880 --> 00:10:50,840
Соответственно, если значение статистики
Уайта оказывается слишком большим,

144
00:10:50,840 --> 00:10:53,657
то гипотеза Н0 отвергается.

145
00:10:53,657 --> 00:10:59,490
А если значение статистика Уайта
небольшое, то есть до критического порога,

146
00:10:59,490 --> 00:11:04,340
соответственно, Н0 о
гомоскедастичности не отвергается.

