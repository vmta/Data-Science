1
00:00:13,010 --> 00:00:18,484
Второй тест,
который принципиально по своей структуре

2
00:00:18,484 --> 00:00:23,336
не похож на тест Уайта — это
тест Голдфельда-Квандта.

3
00:00:23,336 --> 00:00:28,965
При проведении теста Голдфельда-Квандта
на условную гетероскедастичность,

4
00:00:28,965 --> 00:00:31,594
предполагается, что есть
некоторая переменная,

5
00:00:31,594 --> 00:00:34,530
от которой зависит эта самая
условная дисперсия ошибок.

6
00:00:34,530 --> 00:00:39,810
Для проведения этого теста требуется
предположение о нормальности ошибок,

7
00:00:39,810 --> 00:00:42,050
зато, в отличие от теста Уайта,

8
00:00:42,050 --> 00:00:46,730
тест Голдфельда-Квандта применим
для выборок небольшого размера.

9
00:00:46,730 --> 00:00:51,528
Процедура теста Голдфельда-Квандта
следующая: на первом шаге

10
00:00:51,528 --> 00:00:56,017
мы сортируем наблюдения по предполагаемому
убыванию условной дисперсии.

11
00:00:56,017 --> 00:00:59,030
То есть, если вы предполагаете, например,

12
00:00:59,030 --> 00:01:04,079
что у вас разброс прибыли предприятия
зависит от численности персонала, то,

13
00:01:04,079 --> 00:01:08,090
соответственно, вы должны отсортировать
ваши наблюдения по численности персонала.

14
00:01:08,090 --> 00:01:13,124
Если вы предполагаете, что расходы
домохозяйства на продукты питания

15
00:01:13,124 --> 00:01:17,652
зависят от количества людей в этой семье,
то,

16
00:01:17,652 --> 00:01:22,734
соответственно, вы должны
упорядочить домохозяйства, семьи,

17
00:01:22,734 --> 00:01:27,300
которые попались в вашу выборку от самых
многочисленных до самых малочисленных.

18
00:01:27,300 --> 00:01:30,657
То есть вы сортируете
наблюдения по тому фактору,

19
00:01:30,657 --> 00:01:34,880
который по вашему мнению влияет
на условную дисперсию ошибки.

20
00:01:34,880 --> 00:01:40,525
После этого вы выкидываете небольшое
количество наблюдений посередине,

21
00:01:40,525 --> 00:01:45,692
ну, на практике иногда берут 20 %,
но с точки зрения сухой математической

22
00:01:45,692 --> 00:01:51,075
теории можно выкинуть любое
количество наблюдений.

23
00:01:51,075 --> 00:01:56,976
Делается это для того, чтобы подчеркнуть
разницу между дисперсией верхней половины,

24
00:01:56,976 --> 00:01:59,318
верхней части выборки и
нижней части выборки.

25
00:01:59,318 --> 00:02:04,540
Соответственно, вы предполагаете, что в
верхней части выборки у вас находятся

26
00:02:04,540 --> 00:02:09,060
объекты с более высоким разбросом,
чем в нижней части выборки.

27
00:02:09,060 --> 00:02:12,296
После этого вы оцениваете вашу модель,

28
00:02:12,296 --> 00:02:18,033
которую вы хотели отдельно по первой
части выборки с предположительно

29
00:02:18,033 --> 00:02:23,015
высокой дисперсией ε условной,
и оцениваете эту же модель,

30
00:02:23,015 --> 00:02:28,537
которую вы хотите по нижней части выборки,
то есть по той части выборки,

31
00:02:28,537 --> 00:02:32,820
где вы предполагаете небольшую
условную дисперсию ε_i-того.

32
00:02:32,820 --> 00:02:36,141
То есть вы оцениваете две
вспомогательные регрессии.

33
00:02:36,141 --> 00:02:38,615
Оценив две вспомогательные регрессии,

34
00:02:38,615 --> 00:02:44,652
вы в каждой из них считаете RSS — сумму
квадратов остатков: RSS_1 в первой,

35
00:02:44,652 --> 00:02:50,843
где предположительно дисперсия
ε_i-того условно велика и RSS_2,

36
00:02:50,843 --> 00:02:55,646
где предположительно дисперсия
ε_i-того условно мала.

37
00:02:55,646 --> 00:03:00,807
После этого вы считаете F-статистику
по формуле RSS_1 деленное

38
00:03:00,807 --> 00:03:05,975
на его степени свободы,
на (n_1 – k) делить на в знаменателе

39
00:03:05,975 --> 00:03:10,838
RSS_2 деленное на его степени свободы,
на (n_2 – k), где n_1 — это,

40
00:03:10,838 --> 00:03:14,746
соответственно, количество наблюдений
в первой вспомогательной регрессии,

41
00:03:14,746 --> 00:03:17,710
n_2 — количество наблюдений во
второй вспомогательной регрессии,

42
00:03:17,710 --> 00:03:20,256
а k — это количество
объясняющих переменных,

43
00:03:20,256 --> 00:03:24,790
включая единичку в вашей регрессии,
то есть количество параметров оцениваемых.

44
00:03:24,790 --> 00:03:29,500
И при верной H0 в тесте
Голдфельда-Квандта,

45
00:03:29,500 --> 00:03:31,381
так же, как и в тесте Уайта,

46
00:03:31,381 --> 00:03:36,848
нулевой гипотезой проверяемой является
гипотеза о гомоскедастичности условной,

47
00:03:36,848 --> 00:03:41,370
а альтернативной гипотезой является
гипотеза о гетероскедастичности.

48
00:03:41,370 --> 00:03:46,670
Так вот при верной H0,
при гомоскедастичных ε_i-тых,

49
00:03:46,670 --> 00:03:53,960
эта дробь имеет F-распределение с n_1– k,
n_2 – k степенями свободы.

50
00:03:53,960 --> 00:03:58,961
Соответственно, это позволяет
проверять гипотезу H0.

51
00:03:58,961 --> 00:04:00,268
Как ее тестировать?

52
00:04:00,268 --> 00:04:02,181
Вы считаете значение в статистике.

53
00:04:02,181 --> 00:04:06,532
Если оно оказывается больше,
чем F-критическое, то, соответственно,

54
00:04:06,532 --> 00:04:11,139
H0 — гипотеза об условной
гомоскедастичности отвергается.

55
00:04:11,139 --> 00:04:16,200
Если значение F-статистики
оказывается небольшим,

56
00:04:16,200 --> 00:04:22,030
то ничего противоречащего
H0 мы не наблюдаем,

57
00:04:22,030 --> 00:04:27,800
и, соответственно, гипотеза H0 о
гомоскедастичности не отвергается.

58
00:04:27,800 --> 00:04:33,530
Давайте проведем тест
Голдфельда-Квандта для нашего примера.

59
00:04:33,530 --> 00:04:37,469
Вернемся к нашему примеру
с спросом на мороженое и

60
00:04:37,469 --> 00:04:41,667
на примере покажем как проводить
тест Голдфельда-Квандта.

61
00:04:41,667 --> 00:04:46,027
Соответственно, исследователь оценил
количество покупаемого мороженого по

62
00:04:46,027 --> 00:04:49,662
разным киоскам и предположил, что это
зависит от средней цены мороженого в

63
00:04:49,662 --> 00:04:54,403
данном киоске, от количества от величины
ассортимента, то есть сколько разных видов

64
00:04:54,403 --> 00:04:58,536
мороженого продается и от расстояния
до ближайшей остановки от киоска.

65
00:04:58,536 --> 00:05:03,122
И, соответственно, исследователь хочет
провести тест Голдфельда-Квандта на

66
00:05:03,122 --> 00:05:08,388
гетероскедастичность, то есть проверяемая
нулевая гипотеза о гомоскедастичности,

67
00:05:08,388 --> 00:05:12,790
о том что дисперсия ε_i-тых при
фиксированных регрессорах постоянна.

68
00:05:12,790 --> 00:05:17,816
И альтернативная гипотеза об условной
гетероскедастичности, то есть о том,

69
00:05:17,816 --> 00:05:22,790
что условная дисперсия ε_i-тых при
фиксированных регрессорах непостоянна.

70
00:05:22,790 --> 00:05:28,411
Будем проверять по прежнему на уровне
значимости 5 % и проведем тест

71
00:05:28,411 --> 00:05:34,840
Голдфельда-Квандта.

72
00:05:34,840 --> 00:05:39,794
Для проведения теста нам
нужна следующая информация:

73
00:05:39,794 --> 00:05:44,892
количество наблюдений 200,
и в тесте Голдфельда-Квандта,

74
00:05:44,892 --> 00:05:49,974
в отличие от теста Уайта,
нам надо предположить по какой

75
00:05:49,974 --> 00:05:54,748
переменной имеет место зависимость
от гетероскедастичности.

76
00:05:54,748 --> 00:05:59,139
То есть нам нужно поделить наблюдения
на две группы: группу наблюдений с

77
00:05:59,139 --> 00:06:02,809
предположительно высокой условной
дисперсией и группу наблюдений с

78
00:06:02,809 --> 00:06:05,430
предположительно низкой
условной дисперсией.

79
00:06:05,430 --> 00:06:09,921
И, к примеру, исследователь предположил,

80
00:06:09,921 --> 00:06:15,846
что величина дисперсии условной
ε_i-того при фиксированных

81
00:06:15,846 --> 00:06:20,960
регрессорах что она зависит
монотонно от расстояния до метро.

82
00:06:20,960 --> 00:06:25,360
Ну если киоск рядом с метро или рядом
с какой-то остановкой общественного

83
00:06:25,360 --> 00:06:28,429
транспорта другой, то,
соответственно, можно ожидать,

84
00:06:28,429 --> 00:06:32,199
что там бывают какие-то пики,
когда приезжает много пассажиров,

85
00:06:32,199 --> 00:06:36,567
когда там рабочие дни там больше,
а если киоск удален от остановки, то,

86
00:06:36,567 --> 00:06:41,809
соответственно, там, скорей всего,
можно ожидать меньше разброс ε_i-тых.

87
00:06:41,809 --> 00:06:45,112
Соответственно, исследователь предположил,

88
00:06:45,112 --> 00:06:50,033
что условная дисперсия зависит от d_i-тых,
и зависит отрицательно.

89
00:06:50,033 --> 00:06:52,215
То есть с ростом d_i-того,

90
00:06:52,215 --> 00:06:56,480
с ростом расстояния до остановки
дисперсия условная ε_i-того падает.

91
00:06:56,480 --> 00:07:01,252
Поэтому, исследователь поделил
всю выборку из 200 наблюдений на

92
00:07:01,252 --> 00:07:05,605
80 наблюдений, где d_i-тое мало,

93
00:07:05,605 --> 00:07:11,248
на 80 наблюдений,
где d_i-тое велико, и оставшиеся,

94
00:07:11,248 --> 00:07:16,063
соответственно, 40 наблюдений
посередке он просто не учитывал.

95
00:07:16,063 --> 00:07:19,400
И оценил модель по
первой части наблюдений,

96
00:07:19,400 --> 00:07:24,040
получил в ней RSS_1 = 210.

97
00:07:24,040 --> 00:07:28,206
По вот этим 40 наблюдениям
никакую модель не оценивал.

98
00:07:28,206 --> 00:07:33,100
По 80 наблюдениям,
где были самые большие d_i-тое он оценил

99
00:07:33,100 --> 00:07:37,815
ту же самую модель и получил RSS_2 = 120.

100
00:07:37,815 --> 00:07:42,637
И, соответственно,
на основании этих данных нам нужно

101
00:07:42,637 --> 00:07:47,311
проверить гипотезу об
условной гомоскедастичности

102
00:07:47,311 --> 00:07:51,871
против H альтернативной об
условной гетероскедастичности.

103
00:07:51,871 --> 00:07:54,720
Как нам провести тест Голдфельда-Квандта?

104
00:07:54,720 --> 00:07:59,171
Тест Голдфельда-Квандта устроен просто.

105
00:07:59,171 --> 00:08:05,140
Нам надо взять RSS_1,
поделить на количество наблюдений

106
00:08:05,140 --> 00:08:10,630
в первой регрессии минус количество
переменных, оцениваемых –k,

107
00:08:10,630 --> 00:08:16,497
поделить на RSS_2,
деленное на количество наблюдений

108
00:08:16,497 --> 00:08:21,340
во второй построенной оцененной регрессии,

109
00:08:21,340 --> 00:08:25,499
минус количество параметров в модели.

110
00:08:25,499 --> 00:08:30,026
В нашем случае мы получаем 210

111
00:08:30,026 --> 00:08:34,891
/ 80- 4 и тут 120 / 80- 4.

112
00:08:34,891 --> 00:08:39,297
И вот ради того, чтобы это сокращалось
как раз специально и берут

113
00:08:39,297 --> 00:08:43,747
одинаковое количество наблюдений
в двух частях выборки.

114
00:08:43,747 --> 00:08:49,228
И у нас, соответственно,
получается 210 / 120 = 1,75.

115
00:08:49,228 --> 00:08:53,771
Это наблюдаемое значение
статистики Голдфельда-Квандта.

116
00:08:53,771 --> 00:08:59,042
Ну, соответственно, теорема у нас
есть за кадром, которая говорит,

117
00:08:59,042 --> 00:09:05,660
что при верной H0, при верной гипотезе
о гомоскедастичности условной,

118
00:09:05,660 --> 00:09:10,850
статистика Голдфельда-Квандта имеет

119
00:09:10,850 --> 00:09:17,014
F-распределение с n_1 – k,n_2
– k степенями свободы.

120
00:09:17,014 --> 00:09:22,808
То есть в данном случае, это F
распределение со степенями свободы 76,76.

121
00:09:22,808 --> 00:09:27,133
У F-распределения два
параметра степеней свободы.

122
00:09:27,133 --> 00:09:32,250
График функции плотности F-распределения
имеет примерно такой вид.

123
00:09:32,250 --> 00:09:34,948
Нам нужно найти здесь F-критическое.

124
00:09:34,948 --> 00:09:39,503
F-критическое мы можем найти либо
по таблицам, либо дав команду в R.

125
00:09:39,503 --> 00:09:44,650
Нам нужен квантиль,
нужна квантиль F-распределения порядка

126
00:09:44,650 --> 00:09:50,526
0,95 со степенями свободы: первая степень

127
00:09:50,526 --> 00:09:56,383
свободы равна 76,
вторая степень свободы равна 76.

128
00:09:56,383 --> 00:10:02,307
Если мы дадим такую команду в R,
то мы получим вот это самое F-критическое,

129
00:10:02,307 --> 00:10:06,360
и у нас F-критическое оно
оказывается равным 1,46.

130
00:10:06,360 --> 00:10:08,473
F-критическое 1,46.

131
00:10:08,473 --> 00:10:12,788
А наблюдаемое значение
статистики Голдфельда-Квандта

132
00:10:12,788 --> 00:10:16,038
оказалось равно 1,75,
то есть где-то здесь.

133
00:10:16,038 --> 00:10:21,010
F-критическое делит область возможных
значений статистики Голдфельда-Квандта на

134
00:10:21,010 --> 00:10:26,101
две части: часть, где H0 не отвергается и,

135
00:10:26,101 --> 00:10:30,970
то есть там, где разница между

136
00:10:30,970 --> 00:10:35,968
RSS в предположительной части выборки,

137
00:10:35,968 --> 00:10:40,660
где дисперсии велики и RSS той
части выборки, где предположительно

138
00:10:40,660 --> 00:10:44,920
дисперсии малы, если они не очень сильно
отличаются, то статистика будет около 1.

139
00:10:44,920 --> 00:10:49,380
Ну вот у нас 1,75, и это оказывается
существенно дальше, чем 1.

140
00:10:49,380 --> 00:10:54,300
И здесь мы получаем, что H0 отвергается.

141
00:10:54,300 --> 00:10:59,209
Значит, в нашем случае тест
Голдфельда-Квандта приводит

142
00:10:59,209 --> 00:11:02,231
нас к тем же результатам,
что и тест Уайта.

143
00:11:02,231 --> 00:11:06,850
Вывод: H0 отвергается.

144
00:11:06,850 --> 00:11:12,890
То есть в наших данных
имеет место условная

145
00:11:12,890 --> 00:11:18,390
гетероскедастичность.

