Кратко подводя итог сохранившимся
свойствам и потерянным
свойствам при нарушении
предпосылки об условной
гомоскедастичности, то есть в ситуации,
когда дисперсия εi при фиксированных
иксах зависит от иксов,
можно подвести итоги следующим образом.
Во-первых, сами β с крышкой
по-прежнему довольно хороши,
их можно интерпретировать,
их можно использовать при прогнозировании.
Однако основная проблема лежит не в
самих β с крышкой, сами то β с крышкой
и состоятельные и несмещенные, и в
среднем вокруг неизвестного коэффициента
и при большом количестве наблюдений
похожи все более и более на него.
Проблема лежит не в β с крышкой.
Проблема лежит в стандартных
ошибках β с крышкой j-тое.
Эти стандартные ошибки,
к сожалению, несостоятельны.
То есть даже при большом количестве
наблюдений дисперсия оценки
оценивается неправильно.
Это приводит к тому, что несмотря на то,
что мы можем посчитать β
с крышкой j-тое точечно,
можем построить прогноз точечный, но мы
не можем строить доверительные интервалы,
мы не можем сказать, используя
стандартные ошибки, насколько мы уверены,
каков диапазон, разброс для
истинного значения коэффициента.
То есть точечные оценки коэффициентов,
они хорошие,
а вот построить доверительный интервал
для неизвестного βj или построить
доверительный интервал для прогноза, мы,
используя старые стандартные ошибки,
не можем, потому что они несостоятельные
в условиях условной гетероскедастичности.
Что же делать?
Ответ: использовать другие
стандартные ошибки.
Раз старые стандартные ошибки,
которые находились как корни из
диагональных элементов матрицы Var с
крышкой β с крышкой равное RSS
делить на минус k на X'X в минус 1.
Раз они не состоятельны,
и их поэтому не нужно использовать,
значит вместо них надо
использовать что-то другое.
И эти другие ошибки,
которые исправят нам большинство проблем,
они были придуманы еще в прошлом веке.
Это работа Уайта 1980 года,
который предложил
корректировку для стандартных ошибок,
а именно стандартные ошибки β с
крышкой — это та же X'X в минус
1 на X' на оценку матрицы
Ω на X'X в минус 1,
где Ω — это диагональная матрица,
где по диагонали находятся
квадраты остатков из
обычной mnk регрессии.
То есть оценка Уайта,
она очень проста по структуре.
Сначала строится обычная регрессия,
с помощью обычного mnk,
по старой формуле считается β с крышкой.
После этого точно также
считаются ошибки ε с крышкой.
А после этого каждая из ошибок из остатков
ε с крышкой возводится в квадрат.
Получается диагональная матрица,
на диагонали квадраты остатков,
вне диагонали – нули.
Эта матрица подставляется в формулу
для Var с крышкой β с крышкой,
и получаются другие оценки
дисперсии β с крышкой.
Они называются HC, что означает
heteroskedasticity consistent,
то есть состоятельные в
условиях гетероскедастичности.
То есть если мы будем использовать эти
стандартные ошибки, полученные как корни
из диагональных элементов этой матрицы,
то ситуация значительно исправится.
Современный вариант этой формулы чуть-чуть
сложнее, чем был предложен Уайтом.
Он также асимптотически устойчив,
робастен к гетероскедастичности,
но на малых выборках ведет себя
немножко лучше, то есть для
малых выборок получаются более корректные,
более точные доверительные интервалы.
Соответственно, с точки зрения практика,
ситуация очень простая.
Мы вместо старой формулы
для стандартных ошибок β
с крышкой j используем новую формулу
для стандартных ошибок β с крышкой j,
которую мы будем помечать
стандартные ошибки с индексом НС,
то есть состоятельные в
условиях гетероскедастичности.
Если мы используем эту формулу,
то что меняется?
К сожалению, точных распределений в
конечных выборках получить не удается.
Однако ассимптотические
результаты с использованием новых
стандартных ошибок совпадают со старыми.
То есть если мы в формуле t-статистики
вместо обычных стандартных ошибок будем
использовать стандартные ошибки устойчивой
гетероскедастичности, то t-статистики
при большом количестве наблюдений
будут иметь нормальные распределения,
а это как раз нам и нужно для проверки
гипотез о значимости коэффициентов.
Соответственно, с точки зрения практика,
все довольно просто.
Мы, если исследователь использует R,
он запускает R, там есть команда vcovHC
для оценки ковариационной
матрицы оценки коэффициентов, и,
соответственно, эта оценка
является состоятельной,
и ее можно прекрасно использовать для
проверки гипотез, построения доверительных
интервалов для коэффициентов, построения
доверительных интервалов для прогнозов.
Поэтому, с точки зрения практика,
как только у нас есть случайная выборка,
и мы подозреваем,
что у нас в выборке могут быть объекты
с разным разбросом εi,
то есть, проще говоря,
если мы видим, что к нам в выборку
могут попасть объекты разного размера.
Это могут быть предприятия
разной численности,
это могут быть домохозяйства разного
размера, это могут быть страны,
если мы исследуем какие-то
страновые показатели.
Опять же, у всех этих объектов
естествено понятие размера.
Оно может быть разным,
что считать размером страны — площадь ли,
количество ли жителей, это — отдельный
вопрос, но тем не менее даже страны,
домохозяйства, фирмы, индивиды отличаются
по какой-то своей характеристике размера,
и нам логично ожидать условную
гетероскедастичность.
И поэтому, как только мы ожидаем
условную гетероскедастичность,
мы тут же вместо обычных стандартных
ошибок используем стандартные ошибки
Уайта или современную подправку
стандартных ошибок, и, соответственно,
тогда спокойно проверяем гипотезы о
значимости отдельного коэффициента или
строим доверительные интервалы или строим
доверительные интервалы для прогнозов.
Как увидеть гетероскедастичность?
Во-первых, гетероскедастичность
можно увидеть графически.
Если вы оцените на первом шаге
модель методом наименьших квадратов,
а потом по горизонтали отложите тот
регрессор, который, вы подозреваете,
связан с условной дисперсией ε, то,
соответственно, вы можете по вертикали
отложить просто модуль остатка, модуль
ε с крышкой и ε с крышкой в квадрате.
То есть в каком-то смысле
расстояние от ε с крышкой до нуля.
Мы знаем, что ε с крышкой похожа на ε,
а это означает, что,
чтобы проверить — правда ли,
что разборос ε зависит от х,
можно проверять похожую идею
графически — а правда ли,
что разброс ε с крышкой зависит от х?
Перед вами два графика.
На одном из них вы видите,
что размер остатка ε с
крышкой в квадрате растет
с размером регрессора х.
Это говорит о возможной
гетероскедастичности.
На втором графике видно, что размер
остатка, измеряемый с помощью ε с
крышкой в квадрате,
практически стабилен для разных иксов.
Это, скорее, указывает на
гомоскедастичность, то есть на то,
что условная дисперсия ε при
фиксированном х не зависит от х.
Существует ряд формальных тестов,
помимо графики,
ряд формальных тестов на
гетероскедастичность.
Самыми известными и самыми,
по всей видимости, применяемыми и немножко
разными по своим идеям, являются тест
Уайта и тест Голдфельда-Квандта.
Это, конечно, не все тесты на
гетероскедастичность, но их много,
и по сути они приближаются либо к
тесту Уайта, либо Голдфельда-Квандта.
Разберем сначала тест Уайта.
Тест Уайта, он ассимптотический,
то есть он применим,
когда у вас достаточно много наблюдений.
В тесте Уайта не требуется
нормальность εi-тых.
Тест Уайта устроен следующим образом.
Он делается с помощью одной
дополнительной вспомогательной регрессии.
Сначала оценивается исходная модель.
И оценив исходную модель,
вы получаете остатки ε с крышкой.
И дальше вы оцениваете вспомогательную
регрессию, то есть вы берете квадраты
полученных в первой регрессии остатков
ε с крышкой i-тая в квадрате.
И строите регрессии на те переменные, от
которых, по вашему мнению, может зависеть
условная гетероскедастичность,
условная дисперсия ε.
Если вы не знаете, от каких факторов
может зависеть условная дисперсия ε,
тогда в качестве факторов
берут исходные регрессоры,
их квадраты и попарные произведения
исходных регрессоров в основной модели.
После этого вы в вспомогательной регрессии
вы считаете R-квадрат вспомогательной и
умножаете его на n,
получаете значения статистики Уайта.
И Уайт в своей работе доказал,
что при верной Н0,
то есть при гипотезе об
условной гомоскедастичности,
то есть при условии о том, что дисперсия
εi-тых при фиксированном x постоянна,
эта статистика имеет χ квадрат
распределение с n в минус 1 степенью
свободы, где n — это число параметров
во вспомогательной регрессии, а,
соответственно, n минус 1 — это
количество осмысленных объясняющих
переменных во вспомогательной регрессии,
то есть кроме единичного столбца.
Соответственно, если значение статистики
Уайта оказывается слишком большим,
то гипотеза Н0 отвергается.
А если значение статистика Уайта
небольшое, то есть до критического порога,
соответственно, Н0 о
гомоскедастичности не отвергается.

