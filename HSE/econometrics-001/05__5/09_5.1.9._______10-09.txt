Подведём небольшой итог
воздействия гетероскедастичности.
Итак, если нарушена предпосылка
о гомоскедастичности,
то мы теряем, прежде всего,
проверку гипотез по старым формулам.
То есть при использовании старой формулы
для t-статистики невозможно проверять
гипотезы на конечных выборках, и даже
асимптотически при большом n результаты
использования старых t-статистики,
f-статистики будут неверными.
Однако с использованием стандартных
ошибок, устойчивых к гетероскедастичности,
мы можем проверять гипотезы о значимости
коэффициентов и строить доверительные
интервалы при большом n
асимптотически при больших выборках.
К сожалению,
использование стандартных ошибок,
устойчивых к гетероскедастичности,
не спасает нас в очень малых
выборках, и кроме этого оно не
добавляет эффективности оценок,
поскольку оценки мы по-прежнему считали
старым способом и никак их не подправляли.
Возникает вопрос: что же делать
с потерянной эффективностью?
На практике ответ чаще звучит
всего следующим образом: увы,
надо смериться с тем,
что наши оценки стали неэффективными.
Мы можем довольствоваться тем,
что они несмещённые, состоятельные,
и при использовании новых робастных
формул для стандартных ошибок мы
можем проверять гипотезы при
достаточном количестве наблюдений.
Хотя теорема на этот раз утверждает,
что наши оценки
потеряли эффективность, а, значит, где-то
есть более эффективные оценки, на практике
построение этих мифических более
эффективных оценок практически невозможно.
В редких случаях, когда это всё-таки
удаётся, нужно очень хорошо понимать,
как конкретно устроена условная
дисперсия εi при фиксированном X.
То есть вы должны чётко осознавать или
сделать какие-то очень ограничивающие
предположения о структуре дисперсии.
Если вы их сделали, то вы можете
получить более эффективные оценки,
чем оценки метода наименьших квадратов.
Давайте разберём простой пример,
в котором посмотрим,
как конкретно это сделать, если бы мы
знали структуру гетероскедастичности.
То есть мы сделаем ограничивающие
предположения и посмотрим, как в рамках
этих ограничивающих предположений получить
более эффективные оценки, чем оценки
метода наименьших квадратов для исходной
модели с условной гетероскедастичностью.
Сейчас мы на примере разберём,
как в некоторых очень редких ситуациях
можно построить эффективные оценки
в условиях гетероскедастичности.
Итак, предположим,
что мы исследуем результат по математике,
средний результат, скажем,
ЕГЭ в разных классах, в разных школах.
То есть, соответственно, mi — это средний
результат какого-то i-того класса по
математике, и мы предполагаем,
что у нас есть следующие данные.
Нам доступно, скажем: размер
класса ri — размер i-того класса,
плюс мы опросили учащихся класса и
выяснили некое среднее количество времени,
которое учащиеся каждого класса тратили
на домашнее задание по математике,
там, скажем,
тут введём переменную ti, плюс εi.
Такая простая, несложная модель, то есть
средний результат каждого класса — это,
соответственно, размер каждого класса
и это средние затраты времени,
измеренные во времени
на занятие математикой.
И, соответственно, первый вопрос.
Он, скорее, не по математике, а,
скорее, вот по здравому смыслу.
Какую структуру гетероскедастичности
логично ожидать в этой модели?
Логично ожидать.
То есть от каких из имеющихся
переменных мы стали бы ожидать
зависимости дисперсии εi
просто по здравому смыслу?
И второй вопрос уже
относится к математике.
Если получить вот эту осмысленную
структуру гетероскедастичности,
то как получить эффективные
оценки, эффективные оценки β с крышкой?
Потому что мы говорили,
что корректировка стандартных ошибок,
которая используется как одна из мер
по борьбе с гетероскедастичностью,
— она позволяет проверять гипотезы, но не
позволяет получать эффективные оценки.
Но перейдём к первому вопросу.
Какую структуру гетероскедастичности
здесь логично ожидать в этой модели?
Поскольку mi — это средний результат
класса, то что собой представляет mi?
Это складываются результаты каждого
ученика: mi первого ученика плюс mi
второго ученика плюс и так далее плюс mi —
всего у меня в i-том классе ri учеников.
И делится, естественно,
на количество учеников в классе.
Соответственно, если,
скажем, предположить,
что результаты учащихся независимые
и имеют одинаковую дисперсию,
то есть если сделать предположение, что
дисперсия результата каждого ученика mij,
— то есть это результат учащегося,
j-тый номер учащегося в i-том классе,
— если предположить,
что эта дисперсия равна какой-то,
пусть будет σ-квадрат, и mij независимы,
то тогда мы получим результат,
что дисперсия
mi как дисперсия среднего арифметического,
— она, соответственно,
равна σ-квадрат, делённое на
количество наблюдений, то есть на ri.
То есть у нас имеет место условная
гетероскедастичность, но не абы какая,
а вполне определённой структуры.
А если нам структура гетероскедастичности
доподлинно известна, что бывает очень
редко, то есть эта модель с усреднением —
один из немногих примеров такой ситуации,
— то мы можем легко откорректировать
гетероскедастичность.
Как избавиться от данной
гетероскедастичности?
Оказывается, очень легко.
Действительно, если мы предполагаем,
что дисперсия εi при
фиксированных X равна σ-квадрат,
делённое на ri, то что нам нужно сделать,
чтобы дисперсия стала постоянной?
Ответ очень простой: надо внутри
домножить на корень из ri.
Если я возьму дисперсию
корень из ri помножить на εi
при фиксированных X, то корень из
ri будет выноситься с квадратом,
то есть будет получаться ri,
а дисперсия εi — это σ-квадрат на ri.
И получается σ-квадрат.
Получается, что если бы
остатком в модели было не εi,
а корень из ri помножить на εi, тогда
бы модель была с гомоскедастичностью.
Поэтому вопрос,
как получить эффективные оценки,
— да надо просто всё
домножить на корень из ri.
То есть вместо вот этой исходной модели
мы будем оценивать другую модель,
модель с гомоскедастичностью, а именно:
мы будем, все помножим на корень из ri.
У нас получится модель: корень из ri
помножить на mi равняется β1 помножить на
корень из ri плюс β2 помножить
на ri в степени 3/2 плюс
β3 помножить на ti помножить
на корень из ri плюс — здесь,
естественно, окажется корень из ri
умножить на εi, я эту новую случайную
составляющую назову ui, то есть ui
— это корень из ri помножить на εi.
И дальше я с помощью обычного
метода наименьших квадратов...
Вот это модель B, а это модель A.
Дальше я буду оценивать модель B,
с помощью обычного метода наименьших
квадратов оценю модель B.
И оценив модель B,
я получу эффективные оценки β с крышкой
несмещённые и с наименьшей дисперсией.
То есть я получу β1 с крышкой,
β2 с крышкой и β3 с крышкой,
используя метод наименьших квадратов.
Единственно, на что здесь
следует обратить внимание,
что модель B не содержит в себе...
Вот здесь нет единичного столбца, то есть
если я буду записывать матрицу регрессоров
для модели B, то матрица регрессоров — она
не будет содержать единичного столбца.
Здесь будет, первый столбик,
это будет корень из r1.
Второй столбик будет
начинаться r1 в степени 3/2.
И третий столбик будет t1 на корень из
r1 и так далее до n-ного наблюдения,
корень из rn, rn в степени 3/2,
а здесь будет tn на корень из rn.
То есть среди регрессоров,
матрица всех регрессоров единичного
столбца содержать не будет.
Но, тем не менее, вот такой простой трюк,
домножение, построенное таким образом,
чтобы дисперсия новой случайной
составляющей вышла на константу,
— при использовании такого простого трюка
мы можем оценить модель методом наименьших
квадратов и получить эффективные оценки,
то есть оценки с наименьшей дисперсией.

