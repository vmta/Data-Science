1
00:00:13,270 --> 00:00:20,025
Приступим к

2
00:00:20,025 --> 00:00:23,320
компьютерной части нашей
сегодняшней лекции.

3
00:00:23,320 --> 00:00:30,480
Открываем файл-заготовку с загрузкой
пакетов: Open file, lab_10_beforeR.

4
00:00:30,480 --> 00:00:34,088
Здесь у нас все необходимые пакеты
подгружаются, ну, их, конечно,

5
00:00:34,088 --> 00:00:37,410
надо установить предварительно,
если они еще не установлены.

6
00:00:37,410 --> 00:00:41,240
Быстренько их пробегаем,
Ctrl+Enter, Ctrl+Enter, Ctrl+Enter.

7
00:00:41,240 --> 00:00:46,260
И, соответственно, загрузим данные
по стоимости квартир в Москве:

8
00:00:46,260 --> 00:00:51,791
f равняется read.table.

9
00:00:51,791 --> 00:00:56,085
Естественно, при этом нам
нужно встать в нужную папку.

10
00:00:56,085 --> 00:01:00,443
Встать в нужную папку можно Session,
Set Working Directory и выбрать ту папку,

11
00:01:00,443 --> 00:01:01,540
где хранится файл.

12
00:01:01,540 --> 00:01:06,992
Файл у нас называется flats_moscow.txt.

13
00:01:06,992 --> 00:01:11,167
Я напомню, что в этом файле есть
заголовок – название переменных,

14
00:01:11,167 --> 00:01:13,220
то есть мы пишем header=TRUE.

15
00:01:13,220 --> 00:01:18,760
Разделителем наблюдений является
табуляция, и разделителем десятичных,

16
00:01:18,760 --> 00:01:22,570
десятичных знаков является точка.

17
00:01:22,570 --> 00:01:23,677
Загрузили данные.

18
00:01:23,677 --> 00:01:27,200
После загрузки всегда надо проверить,
а всё ли хорошо прошло.

19
00:01:27,200 --> 00:01:30,770
Ну, вот в нашем случае всё прошло хорошо,
все данные загрузились,

20
00:01:30,770 --> 00:01:36,310
и теперь мы можем оценить не обычную
регрессию, а квантильную регрессию.

21
00:01:36,310 --> 00:01:42,140
Давайте оценим model квантильную,
для квантиля порядка 01.

22
00:01:42,140 --> 00:01:48,793
Модель квантильной регрессии
оценивается с помощью функций из

23
00:01:48,793 --> 00:01:53,795
пакета quantreg, quantile regression,
и функция называется rq, наверное,

24
00:01:53,795 --> 00:01:58,796
от противоположного порядка слов
regression quantile, rq(data),

25
00:01:58,796 --> 00:02:04,080
мы берем данные из набора данных f,
формулу мы указываем точно так же,

26
00:02:04,080 --> 00:02:08,630
то есть мы говорим price
зависит от общей площади,

27
00:02:08,630 --> 00:02:12,143
и тут нам надо указать квантиль.

28
00:02:12,143 --> 00:02:16,905
Можно сразу tau, можно сразу оценить
модели для нескольких квантилей,

29
00:02:16,905 --> 00:02:20,534
то есть tau,
пусть это будет вектор 0.1, 0.5 и 0.9,

30
00:02:20,534 --> 00:02:26,004
то есть мы сразу оценим три разных модели:
модель для условно дешевых квартир,

31
00:02:26,004 --> 00:02:30,500
квантиль порядка 10 %, медианную
регрессию, квантиль порядка 50 %,

32
00:02:30,500 --> 00:02:35,380
и модель для дорогих квартир,
квантиль порядка 90 %.

33
00:02:35,380 --> 00:02:39,163
Нажимаем Ctrl+Enter,
вот у нас замечательно оценилась модель.

34
00:02:39,163 --> 00:02:45,732
Можем посмотреть summary по модели,
я ее назвал q01,

35
00:02:45,732 --> 00:02:49,560
хотя на самом деле она,
конечно, по всем сразу.

36
00:02:49,560 --> 00:02:56,897
И вот мы видим,
что здесь перечисляются три модели.

37
00:02:56,897 --> 00:03:02,965
Для квантиля порядка 0.1, tau равно 0.1,
коэффициенты 3.93 и 1.31,

38
00:03:02,965 --> 00:03:07,974
и, опять же, перед нами стандартная
совершенно табличка для проверки гипотез.

39
00:03:07,974 --> 00:03:11,186
То есть мы здесь, за кадром не видим,
конечно, что формулы для рассчета

40
00:03:11,186 --> 00:03:13,842
оценок коэффициентов и
стандартных ошибок были другие,

41
00:03:13,842 --> 00:03:15,910
а вот t-статистика считается точно так же.

42
00:03:15,910 --> 00:03:19,047
Автоматом проверяется гипотеза о том,
что коэффициент равен нулю,

43
00:03:19,047 --> 00:03:23,562
то есть t-статистика считается как 3.93
минус 0, делить на стандартную ошибку.

44
00:03:23,562 --> 00:03:27,568
Вот мы видим, что здесь у нас
коэффициент для дешевых квартир,

45
00:03:27,568 --> 00:03:30,590
зависимость стоимости от метража, значим.

46
00:03:30,590 --> 00:03:35,566
Аналогичная зависимость
для медианной регрессии,

47
00:03:35,566 --> 00:03:40,470
то есть для средних квартир,
и для дорогого жилья.

48
00:03:40,470 --> 00:03:45,990
И, соответственно,
мы можем нашу модель визуализировать.

49
00:03:45,990 --> 00:03:48,761
Давайте построим базовый график.

50
00:03:48,761 --> 00:03:51,858
Базовый график – это будет график...

51
00:03:51,858 --> 00:03:57,155
Данные мы берем из набора данных f,
по горизонтали откладываем общую площадь,

52
00:03:57,155 --> 00:03:59,780
по вертикали откладываем цену квартиры.

53
00:03:59,780 --> 00:04:04,520
Соответственно, давайте покажем
на картинке базовый график.

54
00:04:04,520 --> 00:04:10,343
А, я опечатался, не totps,
а totsp, общая площадь.

55
00:04:10,343 --> 00:04:14,203
Теперь мы этот базовый график,
диаграмму рассеивания,

56
00:04:14,203 --> 00:04:17,234
где при горизонтали
отложена площадь квартиры,

57
00:04:17,234 --> 00:04:21,140
а по вертикали – цена, можем дополнить
линиями квантильной регрессии.

58
00:04:21,140 --> 00:04:27,240
То есть мы добавим к базовому
графику сглаживание stat_smooth,

59
00:04:27,240 --> 00:04:34,890
method – это квантильная регрессия,
tau равняется 0.1,

60
00:04:34,890 --> 00:04:40,460
и стандартные ошибки здесь у нас нам не
нужны, мы просто построим саму линию.

61
00:04:40,460 --> 00:04:46,190
Вот, соответственно,
мы провели линию для квантиля 0.1,

62
00:04:46,190 --> 00:04:49,020
и точно так же можем, скопировав этот код,

63
00:04:49,020 --> 00:04:54,230
построить две линии.

64
00:04:54,230 --> 00:04:59,220
Еще одну для квантиля 0.9.

65
00:04:59,220 --> 00:05:05,652
Вот, соответственно, мы получили
две линии квантильной регрессии.

66
00:05:05,652 --> 00:05:11,285
Можем результат обозвать "базовый
график с квантилями base_q" и,

67
00:05:11,285 --> 00:05:17,220
скажем, еще добавить автоматом разделение
на кирпичные и некирпичные дома.

68
00:05:17,220 --> 00:05:23,160
Скажем, мы к базовому графику
с квантилями добавим эстетику,

69
00:05:23,160 --> 00:05:29,159
то, что цвет точек colour будет
определяться переменной brick,

70
00:05:29,159 --> 00:05:32,160
которая отвечала за кирпичность дома.

71
00:05:32,160 --> 00:05:39,307
И, соответственно, здесь у нас brick она
посчитала за непрерывную переменную,

72
00:05:39,307 --> 00:05:44,157
давайте укажем,
что она факторная, factor(brick).

73
00:05:44,157 --> 00:05:47,839
И у нас получится,
теперь компьютер будет знать,

74
00:05:47,839 --> 00:05:51,270
что у переменной brick – два значения,
1 и 0, кирпичные дома и некирпичные.

75
00:05:51,270 --> 00:05:58,765
И вот на этом графике, если его увеличить,
мы уже видим несколько интересных фактов.

76
00:05:58,765 --> 00:06:05,011
Ну, во-первых, мы видим, что естественно
ожидать, что и для дорогого жилья,

77
00:06:05,011 --> 00:06:10,990
и для дешевого жилья с ростом площади
растет цена, при этом наклон,

78
00:06:10,990 --> 00:06:16,020
наклон линии для дорогого жилья,
для 90%-ного квантиля больше,

79
00:06:16,020 --> 00:06:20,560
чем для 10%-ного квантиля, то есть
стоимость дорогого жилья растет быстрее.

80
00:06:20,560 --> 00:06:24,580
И видно, что у кирпичных
домов соответствующие линии

81
00:06:24,580 --> 00:06:28,600
квантильной регрессии еще выше,
чем у некирпичных.

82
00:06:34,615 --> 00:06:40,630
Теперь перейдем к
построению случайного леса,

83
00:06:40,630 --> 00:06:44,310
то есть компьютер автоматом построит
много-много-много-много деревьев.

84
00:06:44,310 --> 00:06:49,520
Значит, соответствующие функции,
они находятся в пакете randomForest.

85
00:06:49,520 --> 00:06:50,647
Ну, к сожалению,

86
00:06:50,647 --> 00:06:55,205
никаких красивых графиков для алгоритма
случайного леса у нас не получится.

87
00:06:55,205 --> 00:06:59,250
Всё, для чего нужен алгоритм случайного
леса –это для прогнозирования.

88
00:06:59,250 --> 00:07:04,885
Соответственно, мы построим
две модели: модель метода

89
00:07:04,885 --> 00:07:10,382
наименьших квадратов
model_lm и модель с помощью

90
00:07:10,382 --> 00:07:15,780
алгоритма случайного леса,
и посмотрим, как они прогнозируют.

91
00:07:15,780 --> 00:07:18,030
Ну, чтобы прогнозирование было честным,

92
00:07:18,030 --> 00:07:20,600
мы предварительно поделим
выборку на две части.

93
00:07:20,600 --> 00:07:24,400
Значит, сначала мы
определим те наблюдения,

94
00:07:24,400 --> 00:07:30,170
которые попадут в тестовую выборку,
и какие попадут в обучающую.

95
00:07:30,170 --> 00:07:36,110
createDataPartition, мы возьмем из
набора данных f переменную price,

96
00:07:36,110 --> 00:07:40,810
количество наблюдений в обучающей
части выборки пусть будет 75 %,

97
00:07:40,810 --> 00:07:43,380
ну и поставим тут опцию list=FALSE.

98
00:07:43,380 --> 00:07:48,050
Соответственно, in_sample,
можно посмотреть, что это такое.

99
00:07:48,050 --> 00:07:51,030
head(in_sample) – это номера наблюдений,

100
00:07:51,030 --> 00:07:56,050
которые у нас войдут в обучающую выборку,
по которой мы будем оценивать модели.

101
00:07:56,050 --> 00:08:02,170
Соответственно, обучающая выборка
f_train – это будет кусок выборки f,

102
00:08:02,170 --> 00:08:06,820
ну, соответственно, те номера,
которые выпали при случайном отборе.

103
00:08:06,820 --> 00:08:12,510
И тестовая часть выборки
f_test – это будет те номера,

104
00:08:12,510 --> 00:08:15,590
которые не выпали при отборе.

105
00:08:15,590 --> 00:08:21,540
И, соответственно, как мы и собирались,
оценим модель линейной регрессии.

106
00:08:21,540 --> 00:08:26,154
Это будет линейная модель,
данные мы возьмем из обучающей

107
00:08:26,154 --> 00:08:31,153
выборки f_train,
а модель может быть сколь угодно сложной.

108
00:08:31,153 --> 00:08:35,828
Пусть будет price равняется общая площадь

109
00:08:35,828 --> 00:08:40,287
плюс площадь кухни плюс жилая

110
00:08:40,287 --> 00:08:45,160
площадь плюс кирпичность дома,
ну, ограничимся такими.

111
00:08:45,160 --> 00:08:51,380
И оценим ту же самую модель с
помощью алгоритма случайного леса.

112
00:08:51,380 --> 00:08:54,491
model_rf равняется,

113
00:08:54,491 --> 00:08:59,241
и здесь функция называется randomForest,

114
00:08:59,241 --> 00:09:03,010
синтаксис точно такой же,
ничего изменять не надо.

115
00:09:03,010 --> 00:09:06,516
Ну, единственное, конечно,
это ни в коем случае не линейная модель,

116
00:09:06,516 --> 00:09:10,312
просто для удобства авторами сохранен
синтаксис функции, но ни в коем случае

117
00:09:10,312 --> 00:09:14,275
здесь никаких коэффициентов β с крышкой
нет, будет построено 500 деревьев,

118
00:09:14,275 --> 00:09:19,000
совершенно не похожих друг на друга,
и прогнозы будут совершенно нелинейные.

119
00:09:19,000 --> 00:09:23,775
Ну, это занимает некоторое время на
компьютере, то есть можно увидеть

120
00:09:23,775 --> 00:09:28,260
задержку, модель оценивается дольше,
чем модель линейной регрессии, и всё,

121
00:09:28,260 --> 00:09:33,588
для чего нам нужна модель случайного
леса – это прогнозировать.

122
00:09:33,588 --> 00:09:39,345
Давайте мы возьмем y из тестовой выборки,
то есть это f_test,

123
00:09:39,345 --> 00:09:45,010
переменная price, и, соответственно,
это настоящие y в тестовой части,

124
00:09:45,010 --> 00:09:49,211
и мы спрогнозируем y с
крышкой по модели lm.

125
00:09:49,211 --> 00:09:54,960
Это будет predict,
мы предсказываем по модели lm.

126
00:09:54,960 --> 00:10:01,576
И новые данные – это f_test,

127
00:10:01,576 --> 00:10:06,280
то есть для тестовой части выборки
мы предсказываем по одной модели,

128
00:10:13,880 --> 00:10:19,264
соответственно, точно так же по
тестовой части выборки предсказываем

129
00:10:19,264 --> 00:10:24,346
для модели случайного леса, и теперь

130
00:10:24,346 --> 00:10:28,862
мы можем сравнить качество прогнозов,

131
00:10:28,862 --> 00:10:31,973
то есть можем посчитать сумму
квадратов ошибок прогнозов.

132
00:10:31,973 --> 00:10:37,271
То есть мы возьмем y минус y
прогнозное по одной модели

133
00:10:37,271 --> 00:10:42,298
в квадрате,
сумму квадратов ошибок по одной модели,

134
00:10:42,298 --> 00:10:50,615
и возьмем сумму квадратов
ошибок по другой модели.

135
00:10:50,615 --> 00:10:56,210
И мы видим в нашем случае, не смотря даже
на то, что мы не включили кучу переменных,

136
00:10:56,210 --> 00:11:00,252
что модель случайного леса
дает ошибки прогноза,

137
00:11:00,252 --> 00:11:05,430
сумму квадратов ошибок прогноза меньше,
чем модель линейной регрессии, ну,

138
00:11:05,430 --> 00:11:11,014
соответственно, если бы мы добавили
объясняющих переменных, этот эффект стал

139
00:11:11,014 --> 00:11:16,070
бы еще сильнее.

