
﻿1
00:00:13,250 --> 00:00:19,678
Второй сюжет, о котором мы поговорим
— это алгоритм случайного леса.
Алгоритм случайного леса он замечательно
прогнозирует, он один из лучших
алгоритмов по прогнозной силе, но при
этом он совершенно ничего не объясняет.
То есть это такой черный ящик,
который выдает хорошие прогнозы,
но абсолютно не рассказывает о том,
как устроена на самом деле зависимость.
Соответственно, существует много
версий алгоритмов случайного леса,
но две пожалуй самых важных — это алгоритм
для количественной объясняемой переменной,
для количественной y,
и алгоритм для качественной y,
которая принимает значение 0 или 1,
да или нет.
Мы рассмотрим версию алгоритм случайного
леса для количественной переменной,
то есть которая принимает
какой-то диапазон значений.
Ну, например, рассмотрим какой-то
абстрактный набор данных,
где y_i-тое — это переменная,
которая равна 1, 1, 2,
10 и 20 и есть две переменных x и z,
с помощью которых мы пытаемся
объяснить и предсказать,
получить прогнозы переменной y.
И алгоритм случайного леса,
как следует из его названия,
лес состоит из нескольких деревьев,
и для начала нужно понять как
устроено одно отдельно взятое дерево,
а потом насажать их целый лес.
Итак, одно дерево для данной
задачи может выглядеть следующим образом.
Изначально у нас есть 5 наблюдений: 1,
1, 2, 10 и 20.
В качестве прогноза в одном
отдельно взятом дереве
для набора данных используется простейший
прогноз, а именно среднее арифметическое.
Если я возьму сложу 1 + 1 + 2 + 10 +
20 и поделю на 5 у меня получится 6,8.
А дальше, соответственно вот
этот набор из пяти чисел,
каждый из которых я прогнозирую простым
прогнозом 6,8, я поделю на два набора.
И делить я буду я помощью
объясняющих переменных.
Ну, например, первая дележка может
происходить по критерию z < 6.
Если z < 6, то у меня остается в одной
стороне, там где z < 6 три наблюдения: 1,
1 и 2, а в другой стороне
остается два наблюдения: 10 и 20.
Соответственно, для того узла,
куда попали числа 1,
1 и 2 прогноз — это среднее
арифметическое, это 1,3, а для того узла,
куда попали числа 10 и 20 прогноз —
это среднее арифметическое, это 15.
И, соответственно, тот узел, где остались
10 и 20 я еще могу поделить на 2 узла.
Скажем, если я поделю по критерию x < 0,5,
то там где x < 0,5,
туда попадет только число 10, а там где
x > 0,5, туда попадет только число 20.
Соответственно, в других узлах
прогнозы будут равны 10 и 20.
И, соответственно, на этом дереве
в квадратиках я вижу точечный
прогноз для каждого узла,
и для терминальных узлов я
вижу процент наблюдений, которые попали
в соответствующий терминальный узел.
Ну, соответственно, в узел,
где z < 6 у меня попало три наблюдения,
то есть 60 % наблюдений,
в узел, где у меня z > 6,
а x < 0,5 туда у меня
попало 20 % наблюдений,
и, соответственно, в оставшийся узел
у меня попало тоже 20 % наблюдений.
Соответственно, когда у
вас есть такое дерево,
вопрос как его создать по набору данных
— это отдельный сюжет, но тем не менее,
когда у вас есть такое дерево,
то задача прогнозирования очень простая.
Допустим, я хочу спрогнозировать
чему равен y для z = 10 и x = 5.
Ну раз z = 10, значит z > 6,
соответственно,
я иду по дереву вправо
и x у меня тоже > 0,5,
я иду по дереву вправо, соответственно,
я получаю прогноз, что y = 20.
Как посадить дерево?
Дерево сажается по следующему алгоритму.
Ну, это одна из версий и на самом деле это
отдельный свой сюжет и существует огромная
своя теория как строить деревья
по имеющимся наборам данных.
Ну алгоритм, который мы будем использовать
по умолчанию в R он устроен следующим
образом: у нас есть k
объясняющих переменных,
мы случайным образом отберем примерно
треть объясняющих переменных,
и из отобранных трети случайных
переменных выберем ту,
которая дает наилучшее деление
ветви дерева на две подветви.
И, соответственно, мы будем повторять
операцию деления ветви на две
подветви до тех пор, пока в каждом
терминальном узле не окажется меньше,
пока в каждом терминальном узле
остается больше пяти наблюдений.
Ну, соответственно, возникает вопрос:
что означает наилучшее деление?
Ну у нас есть такой показатель как RSS
— сумма квадратов ошибок прогнозов.
Если у меня множество было 1, 1, 2,
10 и 20 и я прогнозирую его,
прогноз тривиальный y среднее,
которое равно 6,8, у меня сумма
квадратов ошибок прогнозов 274.
А если я разобью на две части: на часть 1,
1, 2 и на часть 10,
20, в одном случае у
меня будет прогноз 1,3 и
сумма квадратов ошибок
прогнозов будет 0,67.
Во втором случае у меня будет прогноз 15,
сумма квадратов ошибок прогнозов будет 50,
итоговая сумма квадратов
ошибок прогнозов будет 50,67.
То есть при делении множества 1, 1, 2, 10,
20 на два поднабора у меня сумма квадратов
ошибок прогнозов упала с 274 до 50.
И, соответственно, на каждом шаге
выбирается такой критерий разбиения,
при котором сумма квадратов ошибок
прогнозов падает сильнее всего.
Стоит отметить, что наш алгоритм
случайный, потому что мы на каждом шаге
предварительно выбираем треть объясняющих
переменных, их которых выбираем наилучшую,
и поэтому повторное применение алгоритма
к тому же набору данных в реальности
может дать слегка другие оценки,
построится слегка другое дерево.
Ну и соответственно,
алгоритм случайного леса состоит в
построении большого количества деревьев.
Как устроено построение случайного леса?
Для каждого дерева,
ну скажем мы будем строить 500 деревьев,
для каждого дерева случайным
образом из имеющихся n наблюдений
выбирается с повторами n наблюдений.
Ну то есть это означает, что одно и то
же наблюдение может попасться дважды,
а какое-то наблюдение не
попасться ни одного раза.
Соответственно, по этим репликам
этого исходного набора данных,
по каждому из них строится дерево,
согласно предыдущему алгоритму.
И когда мы получили 500 деревьев,
мы можем легко прогнозировать с помощью
этого леса из случайных деревьев.
Каждое дерево нам даст свой прогноз для y,
соответственно,
у нас получится 500 прогнозов по 500-м
деревьев для объясняемой переменной и мы
возьмем просто среднее арифметическое
из полученных прогнозов.
Это и будет прогнозом случайного леса.
Оказывается такой алгоритм
очень классно прогнозирует.
Ну и для того, чтобы лучше понять,
как строится дерево,
сейчас мы посадим дерево по
простому набору переменных.
У нас, правда, будет всего одна
объясняющая переменная и строить дерево мы
будем до тех пор, пока на нем не
останется три терминальных узла.

