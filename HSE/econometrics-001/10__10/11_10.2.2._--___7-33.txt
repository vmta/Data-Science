
﻿1
00:00:12,630 --> 00:00:19,990
Перейдем к иллюстрациям
байесовского подхода.
Bayesian apрroach.
Сначала проиллюстрируем метод Монте-Карло
по схеме марковской цепи в ситуации,
где обычная логит-модель приводит
к отсутствию оценок β (с крышкой).
Давайте создадим
искусственный набор данных.
Назовем его bad,
bad — это будет плохой набор данных.
data.frame Y будет равняться (0,0,1),
а X будет равняться (1,2,3).
То есть bad — это плохой набор данных.
Здесь действительно видно,
что возможно, в кавычках,
так называемое совершенное
прогнозирование,
а именно — легко понять в нашем наборе
данных, что если X > 2,5, то Y = 1.
Очень все просто и понятно.
Это будет означать, что оценки метода
максимального правдоподобия не существует.
Ну, то есть если я попробую
оценить model_logit,
то есть glm по набору данных bad,
попробую оценить модель
зависимости Y от X и укажу,
что речь идет о логит-модели,
link="logit", то, соответственно,
я получу вот такое вот предупреждение
от R, что возникли подогнанные
вероятности 0 или 1, по английски —
fitted probabilities 0 or 1 occured.
И если я посмотрю на описание модели,
summary (model _logit),
то, соответственно,
я получу здесь вероятности,
близкие к одному, хотя на самом деле
коэффициенты, в общем-то, значимы.
Да?
Проблема связана с тем,
что оценки — очень большие по модулю,
стандартные ошибки у них еще больше,
и получается, что p value близко к 1,
хотя на самом деле коэффициенты там
довольно значимые, зависимость есть.
И, соответственно,
что предлагает байесовский подход?
Байесовский подход предлагает сделать
какое-то априорное предположение о том,
какие значения принимают
коэффициенты β_1 и β_2.
Ну, даже если вы не знаете,
какие они могут быть,
у вас все равно могут быть какие-то
соображения здравого смысла, ну,
что при моих единицах измерения
β вряд ли будет больше 100.
Это означает, что вы считаете,
что с вероятностью 95 % β лежит
в диапазоне от (- 100) до 100.
Это означает, что вы предполагаете,
что стандартное отклонение
β априорное равно 50.
И вы можете моделировать β нормальным
распределением с матожиданием 0 и
дисперсией 50^2.
Ну, например, мы так и поступим.
То есть если я предполагаю
априорное распределение,
что β у меня нормально с
математическим ожиданием 0 и
дисперсией 50^2,
то как мне это реализовать в R?
Соответственно, я воспользуюсь уже
написанной функцией для реализации модели
логит в байесовском подходе,
функция mcmclogit.
И здесь точно так же указывается набор
данных, точно так же указывается формула.
Ну, дальше мне надо указать то,
во что я верю априорно.
Если я считаю, что у меня β
неизвестная от (- 100) до 100,
то это означает,
что стандартное отклонение равно
50 и дисперсия равна 50^2.
И я указываю, b0,
вектор средних – это 0 и B0 – это 1 делить
на дисперсию, это, соответственно, 1/50^2.
Соответственно, сделав
такие предположения,
я могу оценить логит-модель.
Здесь уже не надо пугаться
этих fitted probabilities,
потому что в алгоритме mcmc только
на первом шаге используется
стартовая точка,
для алгоритма mcmc используется старая,
но тем не менее сейчас это
предупреждение стало неопасным,
и если мы посмотрим на
отчет по данной модели,
то мы получим уже вполне
себе замечательные коэффициенты с средним,
стандартной ошибкой.
И можно строить доверительные интервалы,
можно проверять гипотезы,
но уже немножко по-другому: то есть можно,
например, посчитать вероятность того,
что коэффициент больше 0.
Вот я вижу,
что если строить байесовский интервал,
то 90-процентный интервал, то есть...
Не, давайте лучше возьмем
95-процентный интервал,
который можно по умолчанию строить, не
вызывая дополнительных подсчетов, от 4,23
до 47 — это у нас получится 95-процентный
интервал для коэффициента при X.
И таким образом можно получить
некий байесовский аналог того,
что коэффициент на самом деле значим.
0,95 %-ным интервалом не пересекается.
И точно так же, конечно, надо подчеркнуть,
что в байесовском подходе выводы зависят
от того, во что вы верили изначально.
Некоторые считают это недостатком
байесовского подхода,
но на самом деле это просто такая...
факт математической
честности с самим собой.
Результаты зависят от
изначальных предположений.
Соответственно, если я предположу,
скажем, изначально, что я считал,
что у меня коэффициенты от там
(-20) до 20, то есть можно считать,
что стандартная ошибка 10, то,
соответственно, дисперсия 10^2,
коэффициент точности B(большое)0 =1/10^2.
И при переоценке той же самой модели
я уже получу другие коэффициенты.
Вот коэффициент, давайте сравним,
вот здесь был 4,53,
а раньше был коэффициент 21,
апостериорное среднее было.
То есть если я изначально верил,
что коэффициент ближе к нулю,
я получил соответствующие выводы.
И здесь у меня по-прежнему 95-процентный
байесовский интервал от 0,04 до 10,28.
Тоже он 0 не содержит,
поэтому это является аналогом классической
проверки гипотез, и мы делаем вывод о том,
что коэффициент значим.
Ну и, действительно,
здесь все-таки ясно видно,
что с ростом X меняется, в такой простой
выборке меняется вероятность того,
что Y = 0, а в классическом подходе
оценки просто не существовали.

