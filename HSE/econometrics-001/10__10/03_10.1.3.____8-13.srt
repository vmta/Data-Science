1
00:00:13,250 --> 00:00:19,678
Второй сюжет, о котором мы поговорим
— это алгоритм случайного леса.

2
00:00:19,678 --> 00:00:25,459
Алгоритм случайного леса он замечательно
прогнозирует, он один из лучших

3
00:00:25,459 --> 00:00:30,771
алгоритмов по прогнозной силе, но при
этом он совершенно ничего не объясняет.

4
00:00:30,771 --> 00:00:34,367
То есть это такой черный ящик,
который выдает хорошие прогнозы,

5
00:00:34,367 --> 00:00:39,030
но абсолютно не рассказывает о том,
как устроена на самом деле зависимость.

6
00:00:39,030 --> 00:00:43,849
Соответственно, существует много
версий алгоритмов случайного леса,

7
00:00:43,849 --> 00:00:49,019
но две пожалуй самых важных — это алгоритм
для количественной объясняемой переменной,

8
00:00:49,019 --> 00:00:52,138
для количественной y,
и алгоритм для качественной y,

9
00:00:52,138 --> 00:00:55,327
которая принимает значение 0 или 1,
да или нет.

10
00:00:55,327 --> 00:01:00,499
Мы рассмотрим версию алгоритм случайного
леса для количественной переменной,

11
00:01:00,499 --> 00:01:03,650
то есть которая принимает
какой-то диапазон значений.

12
00:01:03,650 --> 00:01:07,255
Ну, например, рассмотрим какой-то
абстрактный набор данных,

13
00:01:07,255 --> 00:01:11,250
где y_i-тое — это переменная,
которая равна 1, 1, 2,

14
00:01:11,250 --> 00:01:16,890
10 и 20 и есть две переменных x и z,
с помощью которых мы пытаемся

15
00:01:16,890 --> 00:01:21,960
объяснить и предсказать,
получить прогнозы переменной y.

16
00:01:21,960 --> 00:01:25,948
И алгоритм случайного леса,
как следует из его названия,

17
00:01:25,948 --> 00:01:30,462
лес состоит из нескольких деревьев,
и для начала нужно понять как

18
00:01:30,462 --> 00:01:35,350
устроено одно отдельно взятое дерево,
а потом насажать их целый лес.

19
00:01:35,350 --> 00:01:40,037
Итак, одно дерево для данной

20
00:01:40,037 --> 00:01:44,320
задачи может выглядеть следующим образом.

21
00:01:44,320 --> 00:01:48,850
Изначально у нас есть 5 наблюдений: 1,
1, 2, 10 и 20.

22
00:01:48,850 --> 00:01:53,920
В качестве прогноза в одном
отдельно взятом дереве

23
00:01:53,920 --> 00:01:58,990
для набора данных используется простейший
прогноз, а именно среднее арифметическое.

24
00:01:58,990 --> 00:02:05,300
Если я возьму сложу 1 + 1 + 2 + 10 +
20 и поделю на 5 у меня получится 6,8.

25
00:02:05,300 --> 00:02:09,801
А дальше, соответственно вот
этот набор из пяти чисел,

26
00:02:09,801 --> 00:02:16,602
каждый из которых я прогнозирую простым
прогнозом 6,8, я поделю на два набора.

27
00:02:16,602 --> 00:02:20,923
И делить я буду я помощью
объясняющих переменных.

28
00:02:20,923 --> 00:02:25,570
Ну, например, первая дележка может
происходить по критерию z < 6.

29
00:02:25,570 --> 00:02:34,061
Если z < 6, то у меня остается в одной
стороне, там где z < 6 три наблюдения: 1,

30
00:02:34,061 --> 00:02:38,992
1 и 2, а в другой стороне
остается два наблюдения: 10 и 20.

31
00:02:38,992 --> 00:02:42,831
Соответственно, для того узла,
куда попали числа 1,

32
00:02:42,831 --> 00:02:47,665
1 и 2 прогноз — это среднее
арифметическое, это 1,3, а для того узла,

33
00:02:47,665 --> 00:02:52,610
куда попали числа 10 и 20 прогноз —
это среднее арифметическое, это 15.

34
00:02:52,610 --> 00:02:58,570
И, соответственно, тот узел, где остались
10 и 20 я еще могу поделить на 2 узла.

35
00:02:58,570 --> 00:03:04,258
Скажем, если я поделю по критерию x < 0,5,
то там где x < 0,5,

36
00:03:04,258 --> 00:03:10,613
туда попадет только число 10, а там где
x > 0,5, туда попадет только число 20.

37
00:03:10,613 --> 00:03:16,570
Соответственно, в других узлах
прогнозы будут равны 10 и 20.

38
00:03:16,570 --> 00:03:21,594
И, соответственно, на этом дереве
в квадратиках я вижу точечный

39
00:03:21,594 --> 00:03:26,497
прогноз для каждого узла,
и для терминальных узлов я

40
00:03:26,497 --> 00:03:31,260
вижу процент наблюдений, которые попали
в соответствующий терминальный узел.

41
00:03:31,260 --> 00:03:36,224
Ну, соответственно, в узел,
где z < 6 у меня попало три наблюдения,

42
00:03:36,224 --> 00:03:40,881
то есть 60 % наблюдений,
в узел, где у меня z > 6,

43
00:03:40,881 --> 00:03:46,840
а x < 0,5 туда у меня
попало 20 % наблюдений,

44
00:03:46,840 --> 00:03:52,055
и, соответственно, в оставшийся узел
у меня попало тоже 20 % наблюдений.

45
00:03:52,055 --> 00:03:54,331
Соответственно, когда у
вас есть такое дерево,

46
00:03:54,331 --> 00:03:57,978
вопрос как его создать по набору данных
— это отдельный сюжет, но тем не менее,

47
00:03:57,978 --> 00:04:01,168
когда у вас есть такое дерево,
то задача прогнозирования очень простая.

48
00:04:01,168 --> 00:04:06,200
Допустим, я хочу спрогнозировать
чему равен y для z = 10 и x = 5.

49
00:04:06,200 --> 00:04:11,843
Ну раз z = 10, значит z > 6,
соответственно,

50
00:04:11,843 --> 00:04:17,189
я иду по дереву вправо
и x у меня тоже > 0,5,

51
00:04:17,189 --> 00:04:22,070
я иду по дереву вправо, соответственно,
я получаю прогноз, что y = 20.

52
00:04:22,070 --> 00:04:25,623
Как посадить дерево?

53
00:04:25,623 --> 00:04:29,961
Дерево сажается по следующему алгоритму.

54
00:04:29,961 --> 00:04:34,509
Ну, это одна из версий и на самом деле это
отдельный свой сюжет и существует огромная

55
00:04:34,509 --> 00:04:39,085
своя теория как строить деревья
по имеющимся наборам данных.

56
00:04:39,085 --> 00:04:43,111
Ну алгоритм, который мы будем использовать
по умолчанию в R он устроен следующим

57
00:04:43,111 --> 00:04:46,426
образом: у нас есть k
объясняющих переменных,

58
00:04:46,426 --> 00:04:52,350
мы случайным образом отберем примерно
треть объясняющих переменных,

59
00:04:52,350 --> 00:04:56,700
и из отобранных трети случайных
переменных выберем ту,

60
00:04:56,700 --> 00:05:03,050
которая дает наилучшее деление
ветви дерева на две подветви.

61
00:05:03,050 --> 00:05:07,570
И, соответственно, мы будем повторять
операцию деления ветви на две

62
00:05:07,570 --> 00:05:12,696
подветви до тех пор, пока в каждом
терминальном узле не окажется меньше,

63
00:05:12,696 --> 00:05:17,020
пока в каждом терминальном узле
остается больше пяти наблюдений.

64
00:05:17,020 --> 00:05:21,440
Ну, соответственно, возникает вопрос:
что означает наилучшее деление?

65
00:05:21,440 --> 00:05:25,860
Ну у нас есть такой показатель как RSS
— сумма квадратов ошибок прогнозов.

66
00:05:25,860 --> 00:05:28,907
Если у меня множество было 1, 1, 2,

67
00:05:28,907 --> 00:05:33,850
10 и 20 и я прогнозирую его,
прогноз тривиальный y среднее,

68
00:05:33,850 --> 00:05:38,660
которое равно 6,8, у меня сумма
квадратов ошибок прогнозов 274.

69
00:05:38,660 --> 00:05:44,055
А если я разобью на две части: на часть 1,
1, 2 и на часть 10,

70
00:05:44,055 --> 00:05:48,439
20, в одном случае у
меня будет прогноз 1,3 и

71
00:05:48,439 --> 00:05:53,123
сумма квадратов ошибок
прогнозов будет 0,67.

72
00:05:53,123 --> 00:05:58,583
Во втором случае у меня будет прогноз 15,
сумма квадратов ошибок прогнозов будет 50,

73
00:05:58,583 --> 00:06:02,836
итоговая сумма квадратов
ошибок прогнозов будет 50,67.

74
00:06:02,836 --> 00:06:06,943
То есть при делении множества 1, 1, 2, 10,

75
00:06:06,943 --> 00:06:14,800
20 на два поднабора у меня сумма квадратов
ошибок прогнозов упала с 274 до 50.

76
00:06:14,800 --> 00:06:19,095
И, соответственно, на каждом шаге
выбирается такой критерий разбиения,

77
00:06:19,095 --> 00:06:23,889
при котором сумма квадратов ошибок
прогнозов падает сильнее всего.

78
00:06:23,889 --> 00:06:29,866
Стоит отметить, что наш алгоритм
случайный, потому что мы на каждом шаге

79
00:06:29,866 --> 00:06:35,160
предварительно выбираем треть объясняющих
переменных, их которых выбираем наилучшую,

80
00:06:35,160 --> 00:06:39,926
и поэтому повторное применение алгоритма
к тому же набору данных в реальности

81
00:06:39,926 --> 00:06:43,990
может дать слегка другие оценки,
построится слегка другое дерево.

82
00:06:43,990 --> 00:06:48,355
Ну и соответственно,

83
00:06:48,355 --> 00:06:52,720
алгоритм случайного леса состоит в
построении большого количества деревьев.

84
00:06:52,720 --> 00:06:56,800
Как устроено построение случайного леса?

85
00:06:56,800 --> 00:07:01,156
Для каждого дерева,
ну скажем мы будем строить 500 деревьев,

86
00:07:01,156 --> 00:07:05,412
для каждого дерева случайным
образом из имеющихся n наблюдений

87
00:07:05,412 --> 00:07:08,020
выбирается с повторами n наблюдений.

88
00:07:08,020 --> 00:07:12,865
Ну то есть это означает, что одно и то
же наблюдение может попасться дважды,

89
00:07:12,865 --> 00:07:16,321
а какое-то наблюдение не
попасться ни одного раза.

90
00:07:16,321 --> 00:07:20,750
Соответственно, по этим репликам
этого исходного набора данных,

91
00:07:20,750 --> 00:07:25,320
по каждому из них строится дерево,
согласно предыдущему алгоритму.

92
00:07:25,320 --> 00:07:28,306
И когда мы получили 500 деревьев,

93
00:07:28,306 --> 00:07:33,540
мы можем легко прогнозировать с помощью
этого леса из случайных деревьев.

94
00:07:33,540 --> 00:07:37,606
Каждое дерево нам даст свой прогноз для y,
соответственно,

95
00:07:37,606 --> 00:07:42,372
у нас получится 500 прогнозов по 500-м
деревьев для объясняемой переменной и мы

96
00:07:42,372 --> 00:07:46,312
возьмем просто среднее арифметическое
из полученных прогнозов.

97
00:07:46,312 --> 00:07:48,610
Это и будет прогнозом случайного леса.

98
00:07:48,610 --> 00:07:52,290
Оказывается такой алгоритм
очень классно прогнозирует.

99
00:07:52,290 --> 00:07:57,106
Ну и для того, чтобы лучше понять,
как строится дерево,

100
00:07:57,106 --> 00:08:00,897
сейчас мы посадим дерево по
простому набору переменных.

101
00:08:00,897 --> 00:08:04,884
У нас, правда, будет всего одна
объясняющая переменная и строить дерево мы

102
00:08:04,884 --> 00:08:13,800
будем до тех пор, пока на нем не
останется три терминальных узла.

