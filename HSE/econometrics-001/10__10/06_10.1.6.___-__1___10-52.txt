
﻿1
00:00:12,620 --> 00:00:19,620
Для иллюстрации байесовского подхода
мы рассмотрим простой пример.
К примеру, у нас есть наблюдения за тем,
кого мы выловили,
закидывая удочку в очередной раз, в озере.
Итак, наши наблюдения: y₁ — в
первый раз мы выловили карася,
во второй раз мы выловили щуку,
и в третий раз мы выловили тоже карася.
Это имеющиеся наблюдения.
Соответственно, помимо имеющихся
наблюдений у нас должна быть
какая-то модель.
Ну мы предположим модель нашего
явления следующую: предположим,
что рыб в озере достаточно много,
поэтому если вы выловили одного карася,
это вряд ли сильно поменяет
вероятности вылова рыб.
Не то что там в озере водились
последние два карася,
и поэтому вероятность резко упала.
Поэтому мы предположим,
что y_i независимы и одинаково
распределены — это наша
модель явления будет.
И закон распределения будет
следующий — неизвестный.
То есть мы будем предполагать,
что отдельные наблюдения независимы,
каждое наблюдение может быть либо
карасём с некой вероятностью p, ну,
соответственно, либо щукой
с вероятностью 1 ‒ p.
Это будет модель.
И для байесовского подхода нам ещё
нужно некое априорное распределение на
неизвестный параметр p.
Априорное распределение.
И для начала мы рассмотрим
первую ситуацию,
где мы ничего не знали про параметр p.
Нам здравый смысл, естественно, говорит,
что вероятность не может вылазить за
пределы от 0 до 1, и поэтому мы говорим,
что первое априорное распределение,
которое мы рассматриваем, это равномерное
от 0 до 1, ну то есть это означает,
что график функции плотности — это 1,
когда p от 0 до 1, и 0 иначе,
то есть график функции плотности у нас
вот такой вот: здесь по горизонтали p,
здесь 0, здесь 1,
и функция плотности проходит на высоте 1.
Вот такая вот априорная функция плотности.
И наша задача — посчитать следующие вещи:
самая основная наша цель — это понять...
Вот это было априорное знание до того,
как я выловил карасей.
Но карасей-то много попалось, поэтому это
как-то меняет моё мнение о неизвестном p.
Значит, первое что нужно сделать, — это
посчитать моё мнение о неизвестном p,
априорную функцию плотности при
условии известных y_1, y_2, y_3.
Ну и для того чтобы лучше почувствовать
разницу между априорным распределением,
то есть распределение до
получения наблюдений,
то есть вот это априорное распределение,
оно — это моя вера,
мое мнение о вероятности
нахождения карася,
отлова карася в озере,
ну когда у меня ещё нет наблюдений.
А вот это — это моё же мнение о
вероятности только с учётом имеющихся
наблюдений.
И, соответственно, чтобы лучше
почувствовать разницу между моим мнением
до получения наблюдений и после получения
наблюдений о неизвестном параметре p,
мы посчитаем какие-то характеристики.
Ну, например,
математическое ожидание от p,
— p мы трактуем сейчас как случайную
величину,— до получения наблюдений
и математическое ожидание от
p после получения наблюдений.
И также, чтобы ещё сравнить,
вероятность, скажем, того,
что p больше половины до получения
наблюдений, безусловная вероятность,
априорная, и вероятность того,
что параметр p больше 0,5 апостериорное,
после получения наблюдений y_1,..., y_3.
Вот такие вот у нас вопросы,
чтобы лучше почувствовать разницу между
априорным распределением и апостериорным,
которое мы пока что не нашли.
Поехали.
По формуле условной вероятности,
условная вероятность,
условная функция плотности p
при известном y — это есть
совместная функция
плотности от p и y делить
на условную вероятность y,
условную функцию плотности y.
Ну здесь я немножко, может,
злоупотребляю обозначением,
но тем не менее из контекста понятно,
что это — совместная функция плотности,
а когда я ставлю палочку — условная.
Равняется: опять же в формуле
условной вероятности это f(y|p)
помножить на f(p) делить на f(y).
Ну нас будет интересовать
зависимость именно от p,
то есть нас интересует зависимость
именно от p, поэтому всё,
что не зависит от p, это будет константой.
И поэтому в данном случае вот это f(y),
— мы его изучать не будем,
поэтому здесь напишем такую тильдочку.
Это будет означать, что с точностью до
параметров, которые от p не зависят.
То есть всё, что не зависит от p,
— константы.
С точностью до константы.
Мы получаем f(y|p) помножить на f(p).
Ну переходим к нашему конкретному случаю.
Как определяется вероятность...
Что вот это такое?
Это априорная функция плотности,
она у нас дана.
Вот это априорная функция плотности.
А вот это наша модель для данных,
вот это — это наша модель для данных.
Наша модель для данных говорит,
что отдельные наблюдения независимы,
поэтому мне вероятность получить
карася надо перемножить на вероятность
получить щуку и на
вероятность получения карася.
И в данном случае у нас получается.
Поскольку наблюдения независимы тут,
перемножаем вероятности.
Мы получаем: вероятность
карася p помножить на (1‒ p)
помножить на вероятность карася
p и помножить на единичку.
Ещё раз, вот это, это — из модели, а вот
это — это априорная функция плотности.
Ну, естественно,
здесь я получил на участке от 0 до 1.
То есть это, значит,
у нас априорная функция плотности,
вот это при p, лежащем от 0 до 1,
ну и 0 — при p, не лежащем от 0 до 1,
поскольку что бы я не помножил на 0,
получится 0.
Соответственно, я выяснил с
точностью до константы как выглядит
апостериорная функция плотности.
Ну эту константу тоже несложно найти.
Поскольку я знаю, что на любой функции
плотности интеграл должен равняться,
— под любой функцией плотности,
— единичке.
То есть у меня есть такое условие,
что интеграл от 0 до 1 функции
плотности условной по p,
— этот интеграл должен равняться 1.
И поэтому хотя я здесь забыл константу,
я могу проинтегрировать это выражение и,
соответственно, найти условную
функцию плотности абсолютно точно.
У меня получится, что чтобы интеграл
под этим выражением равнялся 1,
его дополнительно надо помножить на 12.
Ну в этом просто несложно убедиться,
взяв интеграл.
Соответственно, я получаю ответ,
который сейчас будем интерпретировать.
Я получил, что условная функция
плотности f(p|y) равняется
12p-квадрат на 1 ‒ p при p от 0 до 1 и,
соответственно, 0 при p,
не принадлежащем от 0 до 1.
Вот у нас априорная функция плотности.
А если построить график
апостериорной функции плотности,
то мы получим следующую картинку.
Если построить график вот этой
функции плотности f(p|y),
график функции плотности
будет вот таким вот.
Здесь p, а здесь f(p).
То есть моё априорное
мнение было: я не знаю,
где p от 0 до 1, и все точки для меня
окажутся одинаково предпочтительными.
А апостериорное моё мнение о вероятности
поймать карася уже говорит о том,
что вероятность поймать карася
гораздо ближе к 1, чем к 0.
И я могу, например,
ответить на вопросы, какова...
как я оцениваю шансы того,
что вероятность поймать карася больше 0,5.
Ну если ответить на эти вопросы, то
получится, что априорная вероятность того,
что шансы поймать карася больше 0,5,
— это вот эта площадь за 0,5, — это 0,5.
А если я посчитаю апостериорную,
шансы того,
что вероятность поймать карася больше 0,5,
то есть это вероятность того,
что карасей больше, чем щук, и это
вероятность того, что карасей больше,
чем щук, До получения наблюдений она —
0,5, а после получения наблюдений...
Ну мне надо вот взять где-то вот
здесь 0,5, взять этот интеграл,
и если посчитать эту площадь,
то она окажется равной 11/16.
Если честно взять интеграл,
то окажется, он равен 11/16, 0,6875.
То есть априори я думал,
что вероятность того, что карасей больше,
чем щук, 0,5, а после учёта этой
информации я оцениваю вероятность того,
что карасей больше, чем щук, как 11/16.
Ну и то же самое можно посчитать
среднюю долю щук: мое мнение о средней
доле щук до получения наблюдений и после.
В первом случае E(p)
окажется равным 0,5 — по
формуле обычного математического ожидания.
А если я посчитаю обычное
математическое ожидание с учётом y,
то есть условное математическое ожидание,
ну то есть возьму интеграл от p помножить
на эту функция плотности, то я получу,
что средняя доля карасей, — теперь я
считаю, что средняя доля карасей 0,6.

