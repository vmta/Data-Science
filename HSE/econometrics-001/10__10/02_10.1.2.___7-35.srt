1
00:00:13,250 --> 00:00:19,699
Кратко сравним медианную
и классическую регрессии.

2
00:00:19,699 --> 00:00:25,505
В классической регрессии мы задаемся
вопросом: какие факторы связаны

3
00:00:25,505 --> 00:00:30,729
с изменением среднего значения y
при фиксированных регрессорах?

4
00:00:30,729 --> 00:00:34,610
В медианной регрессии мы задаемся
другим вопросом: мы задаемся

5
00:00:34,610 --> 00:00:39,210
вопросом о том от чего зависит
условная медиана y_i-того?

6
00:00:39,210 --> 00:00:42,624
То есть вполне возможно, что в одном
случае будут получаться одни оценки β

7
00:00:42,624 --> 00:00:47,097
с крышкой и они будут состоятельными, а в
другом случае получаются другие оценки β с

8
00:00:47,097 --> 00:00:49,640
крышкой и они тоже будут состоятельными.

9
00:00:49,640 --> 00:00:51,115
Надо еще раз понимать,

10
00:00:51,115 --> 00:00:55,470
что медианная и классическая
регрессии отвечают на разные вопросы.

11
00:00:55,470 --> 00:00:57,906
Поэтому то, что там не совпадают оценки,

12
00:00:57,906 --> 00:01:00,554
— это вполне возможно и
ничего плохого в этом нет.

13
00:01:00,554 --> 00:01:03,141
Одна не является более правильной,
чем другая.

14
00:01:03,141 --> 00:01:05,348
Они отвечают на разные вопросы.

15
00:01:05,348 --> 00:01:08,660
В них совершенно сходна проверка гипотез.

16
00:01:08,660 --> 00:01:11,361
Асимптотически мы можем сказать,

17
00:01:11,361 --> 00:01:15,582
что β с крышкой — коэффициент
оцененной регрессии минус истинное

18
00:01:15,582 --> 00:01:19,568
значение коэффициента делить на
стандартную ошибку, по распределению

19
00:01:19,568 --> 00:01:24,277
эта случайная величина стремится к
нормальной стандартной случайной величине.

20
00:01:24,277 --> 00:01:29,057
То есть фактически при большом количестве
наблюдений способ проверки гипотез,

21
00:01:29,057 --> 00:01:32,485
способ построения доверительных
интервалов будет абсолютно сходный.

22
00:01:32,485 --> 00:01:37,189
Ну, единственное, конечно что оценки β с
крышкой и стандартные ошибки β с крышкой

23
00:01:37,189 --> 00:01:39,190
считаются по разным формулам.

24
00:01:39,190 --> 00:01:44,575
Одни формулы для классической регрессии,
другие формулы для медианной регрессии,

25
00:01:44,575 --> 00:01:48,080
но тем не менее,
в целом подходы совершенно сходны.

26
00:01:48,080 --> 00:01:52,917
И, конечно, надо отметить,
что медиана и среднее медианное

27
00:01:52,917 --> 00:01:58,032
математическое ожидание для
симметричного распределения совпадают,

28
00:01:58,032 --> 00:02:03,663
поэтому, если распределение ε_i-тое
симметричное, то асимптотически никакой

29
00:02:03,663 --> 00:02:10,640
разницы между медианной регрессией
и регрессией среднего не окажется.

30
00:02:10,640 --> 00:02:14,770
Среди минусов медианной регрессии
можно отметить, пожалуй,

31
00:02:14,770 --> 00:02:19,676
что нет явных формул для β с
крышкой и нет явных формул для

32
00:02:19,676 --> 00:02:23,939
стандартных ошибок β с крышкой, то есть
некие численные компьютерные алгоритмы,

33
00:02:23,939 --> 00:02:26,900
которые позволяют их оценить,
но какой-то компактной формулы,

34
00:02:26,900 --> 00:02:30,560
чтобы можно было написать на доске
— такого в медианной регрессии нет.

35
00:02:30,560 --> 00:02:33,293
И, в частности поэтому,

36
00:02:33,293 --> 00:02:38,810
у медианой регрессии нет хороших
распределений для конечных выборок.

37
00:02:38,810 --> 00:02:42,872
То есть в классической регрессии если
предположить нормальность остатков,

38
00:02:42,872 --> 00:02:46,556
то можно получить какие-то
результаты для малых выборок.

39
00:02:46,556 --> 00:02:50,328
В медианной регрессии такое,
к сожалению, не получается.

40
00:02:50,328 --> 00:02:56,055
Даже если ε_i-тые нормальные,
все равно в медианной регрессии

41
00:02:56,055 --> 00:03:01,190
мы не получим каких-то удобных простых
законов распределения в конечной выборке.

42
00:03:01,190 --> 00:03:06,073
Ну плюсом медианной регрессии основным
является то, что она позволяет по-другому

43
00:03:06,073 --> 00:03:09,580
взглянуть на данные,
это очень важно — другой взгляд на данные.

44
00:03:09,580 --> 00:03:13,824
Ну другим тоже хорошим свойством,
но все-таки не таким важным,

45
00:03:13,824 --> 00:03:18,532
как другой взгляд, является то,
что медианная регрессия более устойчива по

46
00:03:18,532 --> 00:03:22,340
сравнению с классической к «выбросам»
— резко экстремальным значениям,

47
00:03:22,340 --> 00:03:27,188
резко отрицательным сильно или сильно
положительным значениям случайной ошибки

48
00:03:27,188 --> 00:03:28,405
ε_i-тое.

49
00:03:28,405 --> 00:03:33,774
И медианную регрессию можно
обобщить до квантильной регрессии.

50
00:03:33,774 --> 00:03:38,150
Поскольку медиана — это, говоря
другим языком, квантиль порядка 50 %,

51
00:03:38,150 --> 00:03:41,180
то есть ниже нее находится
50 % наблюдений,

52
00:03:41,180 --> 00:03:45,095
то можно говорить о квантильной
регрессии порядка τ.

53
00:03:45,095 --> 00:03:47,072
Что такое квантиль порядка τ?

54
00:03:47,072 --> 00:03:51,373
Это такое число, вероятность
попасть левей которого равна τ.

55
00:03:51,373 --> 00:03:56,332
И, соответственно, можно говорить, скажем,

56
00:03:56,332 --> 00:04:00,820
о квантиле порядка 10 % или
о квантиле порядка 90 %.

57
00:04:00,820 --> 00:04:05,185
Соответственно, квантиль
порядка 10 % — это такое число,

58
00:04:05,185 --> 00:04:08,276
вероятность попасть левей которого 10 %.

59
00:04:08,276 --> 00:04:14,795
Соответственно, скажем, квантиль
доходов 10 %-ная — это, соответственно,

60
00:04:14,795 --> 00:04:20,040
такой доход,
ниже которого имеют доходы 10 % населения.

61
00:04:20,040 --> 00:04:24,976
И в квантильной регрессии предполагается,
что квантиль порядка

62
00:04:24,976 --> 00:04:29,631
τ линейно зависит от
объясняющих переменных,

63
00:04:29,631 --> 00:04:32,920
то есть q_τ = β_1 + β_2 * x_i.

64
00:04:32,920 --> 00:04:35,712
И хотя зависимость
предполагается линейной,

65
00:04:35,712 --> 00:04:38,510
но она может быть разной
для разных квантилей.

66
00:04:38,510 --> 00:04:44,327
То есть квантиль порядка 10 % может
зависеть от регрессора одной зависимостью,

67
00:04:44,327 --> 00:04:47,528
а квантиль порядка 90 % может
зависеть от регрессоров,

68
00:04:47,528 --> 00:04:50,290
от объясняющих переменных
другой зависимостью.

69
00:04:50,290 --> 00:04:54,650
То есть хотя зависимость там и там
линейная, она может быть разной линейной.

70
00:04:54,650 --> 00:05:00,375
Для получения оценок в
квантильной регрессии

71
00:05:00,375 --> 00:05:05,079
минимизируется не сумма квадратов
ошибок прогнозов, как в классической,

72
00:05:05,079 --> 00:05:09,908
не сумма модулей ошибок прогнозов,
как в медианной,

73
00:05:09,908 --> 00:05:15,258
а взвешенная или асимметричная
сумма модулей ошибок прогнозов.

74
00:05:15,258 --> 00:05:18,914
А именно сумма w_i-тое —
какие-то веса — помножить

75
00:05:18,914 --> 00:05:22,960
на разницу по модулю y_i-тое
минус прогноз y_i-тое с крышкой.

76
00:05:22,960 --> 00:05:27,805
Соответственно, веса w_i-тое определяются
следующим образом: если в этом

77
00:05:27,805 --> 00:05:33,203
наблюдении y_i-тое меньше, чем прогноз
yi-тое с крышкой, то вес равен 1 – τ,

78
00:05:33,203 --> 00:05:38,100
а если y_i-тое больше, чем y с крышкой,
то вес определяется как τ.

79
00:05:38,100 --> 00:05:43,435
И можно показать, что при выполнении
некоторых предпосылок при минимизации этой

80
00:05:43,435 --> 00:05:48,653
взвешенной асимметричной суммы модулей
ошибок, мы получим состоятельные

81
00:05:48,653 --> 00:05:55,050
оценки β₁ с крышкой и β₂ с крышкой
для коэффициентов β₁ и β₂.

82
00:05:55,050 --> 00:05:59,397
И, соответственно, если вернуться к
изучавшемуся нами набору данных по

83
00:05:59,397 --> 00:06:04,318
стоимости квартир в Москве, если
построить регрессию ну по условно назовем

84
00:06:04,318 --> 00:06:08,669
недорогому жилью 10 %-ный квантиль,
соответственно,

85
00:06:08,669 --> 00:06:15,652
квантиль 10 %-ный зависит как 3,9 + 1,3
умножить на общую площадь квартиры,

86
00:06:15,652 --> 00:06:20,287
а для дорогого жилья — 90
%-ная квантиль окажется что

87
00:06:20,287 --> 00:06:25,500
квантиль зависит как –102 +
3,6 умножить на общую площадь.

88
00:06:25,500 --> 00:06:26,551
Что это означает?

89
00:06:26,551 --> 00:06:31,560
Это означает, что для ну условно
недорогого жилья при росте общей площади

90
00:06:31,560 --> 00:06:36,578
на 1 метр цена растет на 1,3 тысячи y.e.,

91
00:06:36,578 --> 00:06:41,820
а для дорогого жилья
при росте общей площади

92
00:06:41,820 --> 00:06:46,871
на 1 метр цена растет на 3,6 тысяч y.e..

93
00:06:46,871 --> 00:06:51,446
Ну, соответственно, можно изобразить
эту зависимость на графике следующим

94
00:06:51,446 --> 00:06:56,190
образом: по горизонтали отложена
общая площадь квартиры,

95
00:06:56,190 --> 00:06:59,220
по вертикали отложена цена в тысячах y.e.

96
00:06:59,220 --> 00:07:02,342
и, соответственно,
две линии на графике — это зависимость 10

97
00:07:02,342 --> 00:07:04,920
%-ного квантиля в предположении
что она линейная,

98
00:07:04,920 --> 00:07:10,004
и зависимость 90 %-ного квантиля
в предположении что она линейная.

99
00:07:10,004 --> 00:07:11,565
И, соответственно,

100
00:07:11,565 --> 00:07:15,966
эти две линии они позволяют по-другому
взглянуть на наш набор данных.

101
00:07:15,966 --> 00:07:21,241
Они отвечают на вопрос не как средняя
стоимость квартиры зависит от метража,

102
00:07:21,241 --> 00:07:26,100
они отвечают на вопрос как у дорогих
квартир и как у дешевых квартир

103
00:07:26,100 --> 00:07:30,660
выглядит зависимость
цены от общего метража.

