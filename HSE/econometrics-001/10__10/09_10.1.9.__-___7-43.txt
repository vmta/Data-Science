
﻿1
00:00:13,620 --> 00:00:18,594
Мы можем применить байесовский подход и к
нашей стандартной задаче классической
линейной регрессионной модели.
То есть модель у нас та
же самая: y_i = β_1 + β_2x_i
+ β_3z_i + ε_i Но мы дополняем
эту модель априорным мнением
о неизвестных коэффициентах β_1,
β_2, β_3 и параметре σ квадрат.
И мы сейчас дополним нашу модель
априорным распределением,
которое называется регрессия пик-плато.
Суть состоит в следующем:
мы будем предполагать,
что коэффициенты β либо
точно 0 с вероятностью 1/2,
либо «непонятно что» с вероятностью 1/2.
Соответственно, это распределение можно
формально математически записать следующим
образом: что β_j, j-тый коэффициент модели,
имеет нормальное распределение с
математическим ожиданием 0 и некоторой
дисперсией — дисперсия γ_j * τ_j в квадрате,
где γ_j либо 1 с вероятностью 1/2,
либо 0 с вероятностью 1/2.
Соответственно, если вот этот
множитель γ_j оказывается равным 0,
то получается, что β_j имеет нормальное
распределение с математическим
ожиданием 0 и дисперсией 0, а что такое
случайная величина с дисперсией 0?
Это константа.
То есть если γ_j принимает значение 0,
получается,
что β_j-тое в точности равно
0 с вероятностью 1/2.
Получается как бы такой острый пик,
мы с вероятностью 1/2 β_j равно 0,
а с вероятностью 1/2 γ_j окажется
равным 1 и дисперсия β_j,
то есть наше априорное
мнение будет состоять в том,
что дисперсия β_j равна τ_j в квадрате.
И τ_j в квадрате предполагается
случайной величиной,
имеющей обратное гамма-распределение.
Для тех, кто не знает,
что такое обратное гамма-распределение,
можно просто заметить,
что это некое распределение,
которое гарантирует неотрицательность
величины τ_j в квадрате.
Ну, поскольку,
дисперсия не бывает отрицательной,
то от обратного гамма-распределения
требуется, чтобы оно было неотрицательным,
и, соответственно, a_1 и a_2 — это
какие-то параметры, которые определяют
форму обратного гамма-распределения.
И, соответственно,
мы выберем форму гамма-распределения так,
чтобы τ_j в квадрате принимало
довольно большие значения.
Тогда получится, что с вероятностью
1/2 дисперсия β_j равна 0,
то есть мы точно уверены, что β_j равно 0,
и с вероятностью 1/2 дисперсия β_j,
τj в квадрате принимает огромное значение,
и это означает,
что мы абсолютно не уверенны в том,
какое же значение принимает β_j.
Вот получается у нас такая
смесь пика (мы точно уверены,
что коэффициент равен 0) и плато (мы
не знаем, где коэффициент лежит).
Поэтому эта регрессия
называется регрессия пик-плато.
Ну и, конечно, еще априорное
распределение также должно моделировать,
задавать законы распределения
неизвестного параметра σ-квадрат.
Здесь тоже мы пользуемся
обратным гамма-распределением,
чтобы гарантировать неотрицательность
параметра σ квадрат.
И, соответственно, опять же, явных формул
тут никаких для оценок коэффициентов нет.
Мы применяем алгоритм Монте-Карло по
схеме марковской цепи и на выходе,
имея данные предпосылки,
на выходе получаем выборку из
апостериорного закона распределения β_1,
β_2 β_3 и σ-квадрат.
Достоинство регрессии пик-плато состоит в
следующем: она позволяет напрямую отвечать
на вопрос: чему же равна вероятность того,
что коэффициент на самом деле 0?
То есть вопрос о том, что вероятность
того, что β_2 = 0 при заданных наблюдениях,
он вполне корректен, и на него можно в
рамках регрессии пик-плато ответить.
Тот же самый вопрос в рамках
классической модели он бессмысленный.
Мы могли проверять гипотезы,
но проверка гипотез — это
все-таки не более, чем попытка
как-то приблизиться к этому ответу.
Мы как бы говорим, что данные не сильно
противоречат гипотезе о том, что β_2 = 0,
но на вопрос «так равно ли β_2 нулю или
нет?» мы в классическом подходе никогда не
отвечаем, а регрессия пик-плато позволяет
прямо ответить на этот вопрос и сказать,
чему равна эта вероятность.
И, соответственно,
если вернуться к тому набору данных,
с рассмотрения которого мы
начали наш курс эконометрики,
с набора данных по машинам 1920-х годов,
где вот на графике по горизонтали
отложена скорость машины в км/час, по
вертикали отложена длина тормозного пути.
И мы можем оценить байесовскую
модель регрессию пик-плато,
предположив, что длина тормозного пути
зависит от скорости и квадрата скорости.
Получить апостериорное
распределение для β_1, β_2 и β_3.
Ну, в регрессию имеет смысл записать,
конечно, средние значения,
апостериорные математические ожидания.
То есть 12,81; 0,28 и 0,01,
оценки коэффициентов —
это апостериорные математические ожидания
коэффициентов β_1, β_2 и β_3 соответственно.
И, соответственно, помимо этого уравнение,
которое прекрасно позволяет, например,
прогнозировать.
Мы теперь можем напрямую
ответить на вопрос...
Поскольку за кадром у нас имеется
выборка из 1000 или 2000,
или 10 000, сколько захотим,
значений β1, β2 и β3,
мы можем напрямую ответить на
вопрос: а какой процент из них,
какой процент в выборке из апостериорного
распределения оказались равны 0?
И в данном примере оказывается,
что вероятносто того,
что коэффициент при скорости равен 0,
она 0,15,
а коэффициент при скорости в квадрате
равен 0, эта вероятность равна 5 %.
То есть, соответственно, байесовская
регрессия позволяет нам сказать,
что вот имеет смысл из двух коэффициентов,
если включать только один,
то имеет смысл включить
скорость в квадрате.
Ну, можно включить и оба.
И на этом примере байесовской
регрессии мы заканчиваем наш курс.
Большое-большое спасибо всем тем,
кто прослушал этот курс до конца.
Мы всей командой получили очень большое
удовольствие от создания данного курса.
И хотелось бы завершить его цитатой,
что на самом деле мы ни в
коем случае не закончили курс
эконометрики и мы скорее
поставили больше вопросов.
По ходу курса мы поставили больше задач,
чем смогли решить.
И в каком-то смысле мы
также ничего не знаем,
как и до начала изучения курса
эконометрики, но мы верим,
что наше незнание стало глубже, а не знаем
мы все более и более интересные вещи.

