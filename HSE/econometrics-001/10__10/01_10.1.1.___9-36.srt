1
00:00:13,270 --> 00:00:19,328
В завершающей лекции мы
расскажем о трех сюжетах,

2
00:00:19,328 --> 00:00:22,110
чтобы показать многообразие эконометрики.

3
00:00:22,110 --> 00:00:26,142
А именно эти три сюжета —
это квантильная регрессия,

4
00:00:26,142 --> 00:00:29,830
алгоритм случайного леса
и байесовский подход.

5
00:00:29,830 --> 00:00:35,018
Суть квантильной регрессии состоит в том,
чтобы отказаться

6
00:00:35,018 --> 00:00:40,268
от моделирования среднего, как это
было в классической линейной модели,

7
00:00:40,268 --> 00:00:45,210
а моделировать медиану распределения или
любой другой квантиль распределения.

8
00:00:45,210 --> 00:00:49,200
А именно напомним, что в классической
модели линейной регрессии

9
00:00:49,200 --> 00:00:53,492
предпосылки были
следующие: предполагалось,

10
00:00:53,492 --> 00:00:58,087
то Y_i = β₁ + β₂x_i + ε_i и
предполагалось экзогенность ошибок,

11
00:00:58,087 --> 00:01:02,970
а именно то, что средняя величина ошибки
при известных регрессорах равна 0.

12
00:01:02,970 --> 00:01:07,020
И были еще другие, конечно,
предпосылки, но, в частности,

13
00:01:07,020 --> 00:01:12,280
из первых двух предпосылок следовало то,
что условное математическое ожидание

14
00:01:12,280 --> 00:01:17,910
Y_i при фиксированном X_i
— это есть β₁ + β₂Х_i.

15
00:01:17,910 --> 00:01:23,192
То есть означает, что в классической
линейной регрессионной модели

16
00:01:23,192 --> 00:01:30,390
с увеличением X на 1, среднее значение Y_i,
условное среднее, меняется на β₂.

17
00:01:30,390 --> 00:01:33,977
То есть классическая линейная
регрессионная модель — это модель для

18
00:01:33,977 --> 00:01:35,140
среднего значения Y.

19
00:01:35,140 --> 00:01:40,213
И для оценки этой регрессионной
модели классической мы минимизировали

20
00:01:40,213 --> 00:01:45,265
сумму квадратов ошибок прогноза,
сумму (Y_i- Y_i с крышкой) в квадрате.

21
00:01:45,265 --> 00:01:50,290
И получались замечательные, а именно
состоятельные оценки коэффициентов,

22
00:01:50,290 --> 00:01:53,573
β₁ с крышкой и β₂ с крышкой.

23
00:01:53,573 --> 00:01:58,892
В медианной регрессии
модель состоит в том,

24
00:01:58,892 --> 00:02:07,050
что медиана Y_i условная линейно
зависит β₁ + β₂Х_i от регрессора.

25
00:02:07,050 --> 00:02:10,957
Давайте поясним еще раз разницу
между медианой и средним.

26
00:02:10,957 --> 00:02:15,935
Если представить себе большую-большую
выборку при одинаковых X_i для

27
00:02:15,935 --> 00:02:20,988
Y большую выборку, то,
соответственно, что такое среднее?

28
00:02:20,988 --> 00:02:25,343
Ну, это просто среднее арифметическое,
то есть математическое ожидание похоже на

29
00:02:25,343 --> 00:02:27,616
среднее арифметическое
при большой выборке.

30
00:02:27,616 --> 00:02:29,050
А медиана — это такое число,

31
00:02:29,050 --> 00:02:34,830
выше которого лежит 50 % наблюдений и
ниже которого тоже лежит 50 % наблюдений.

32
00:02:34,830 --> 00:02:39,179
И, соответственно,
в медианной регрессии предполагается,

33
00:02:39,179 --> 00:02:44,020
что не среднее,
а именно медиана зависит от регрессора.

34
00:02:44,020 --> 00:02:46,534
И алгоритм оценивания немножко другой.

35
00:02:46,534 --> 00:02:51,058
Мы минимизируем не сумму квадратов
остатков, а сумму модулей остатков,

36
00:02:51,058 --> 00:02:53,191
сумму |Y_i- Y_i с крышкой|.

37
00:02:53,191 --> 00:02:56,011
И при ее минимизации можно доказать,

38
00:02:56,011 --> 00:03:00,653
что получаются состоятельные
оценки для медианной регрессии.

39
00:03:00,653 --> 00:03:05,788
И сейчас мы рассмотрим совсем простой
пример, где будет одна объясняющая

40
00:03:05,788 --> 00:03:11,400
переменная, и мы получим оценку β
с крышкой для медианной регрессии.

41
00:03:11,400 --> 00:03:14,237
К сожалению,
явных формул в медианной регрессии нет,

42
00:03:14,237 --> 00:03:18,747
но в каждом конкретном случае можно
численно получить оценку β с крышкой.

43
00:03:18,747 --> 00:03:20,710
Рассмотрим пример задачи.

44
00:03:20,710 --> 00:03:22,369
У нас есть некая модель.

45
00:03:22,369 --> 00:03:24,502
На этот раз модель для медианы.

46
00:03:24,502 --> 00:03:29,119
Мы предполагаем, что медиана Y_i при
известном значении X очень просто

47
00:03:29,119 --> 00:03:33,951
зависит от X, а именно равняется просто
некой неизвестной — коэффициент β * Х_i.

48
00:03:33,951 --> 00:03:37,920
Рассмотрим совсем простую
модель для решения руками.

49
00:03:37,920 --> 00:03:42,110
И мы хотим в этой модели получить
оценку коэффициента β с крышкой.

50
00:03:42,110 --> 00:03:45,801
Ну и, соответственно, у нас должны быть,
естественно, какие-то данные,

51
00:03:45,801 --> 00:03:48,521
потому что без данных
оценить модель невозможно.

52
00:03:48,521 --> 00:03:51,490
Ну, к примеру,
у нас будет всего три наблюдения.

53
00:03:51,490 --> 00:03:55,620
Y-зависимая переменная будет
принимать значение 1, 2 и 6,

54
00:03:55,620 --> 00:04:00,083
а X-объясняющая переменная будет
принимать значение 1, 5 и 5.

55
00:04:00,083 --> 00:04:05,250
И я предполагаю, что медиана Y
зависит от X, зависит очень просто.

56
00:04:05,250 --> 00:04:08,076
Вот хочу получить оценку β с крышкой.

57
00:04:08,076 --> 00:04:13,128
Ну, соответственно,
идея медианной регрессии говорит,

58
00:04:13,128 --> 00:04:17,254
что надо выписать, как от β с крышкой

59
00:04:17,254 --> 00:04:22,354
зависит сумма модулей ошибок прогноза.

60
00:04:22,354 --> 00:04:28,430
Ну, естественно, у нас i будет меняться
от 1 до 3 (всего 3 наблюдения),

61
00:04:28,430 --> 00:04:32,637
и если модель устроена следующим образом,
то, соответственно,

62
00:04:32,637 --> 00:04:36,930
у нас Y_i с крышкой,
прогноз Y будет устроен довольно просто.

63
00:04:36,930 --> 00:04:41,070
Это будет β с крышкой помножить
на значение регрессора.

64
00:04:41,070 --> 00:04:46,370
Ну и в нашем случае конкретном
трех наблюдений мы получаем

65
00:04:46,370 --> 00:04:51,165
следующую формулу для суммы
модулей ошибок прогноза.

66
00:04:51,165 --> 00:04:56,199
Это, соответственно, |Y₁- Y₁ с
крышкой| ошибка прогноза для первого

67
00:04:56,199 --> 00:05:01,573
наблюдения плюс ошибка прогноза
для второго наблюдения по модулю

68
00:05:01,573 --> 00:05:06,915
плюс ошибка прогноза для
третьего наблюдения.

69
00:05:06,915 --> 00:05:11,905
Ну и в нашем случае поскольку прогнозы
у нас считаются в соответствии

70
00:05:11,905 --> 00:05:16,881
с формулой для медианы,
то мы получаем |1- β с

71
00:05:16,881 --> 00:05:21,883
крышкой * 1| + |2

72
00:05:21,883 --> 00:05:28,070
(второй Y)- (формула для второго прогноза)

73
00:05:28,070 --> 00:05:33,025
β с крышкой * 5 (второй X)|

74
00:05:33,025 --> 00:05:38,541
+ |6 (последний Y) -

75
00:05:38,541 --> 00:05:43,034
β крышкой * 5| И, соответственно,

76
00:05:43,034 --> 00:05:48,450
медианная регрессия говорит,
что вот эту сумму надо минимизировать,

77
00:05:48,450 --> 00:05:53,430
подбирая какое-нибудь β с крышкой, которое
обеспечит минимальную сумму модуля ошибок.

78
00:05:53,430 --> 00:05:57,917
Ну, к сожалению или к счастью, эта функция
недифференцируемая, но она достаточно

79
00:05:57,917 --> 00:06:03,137
проста, то есть график функции M(β
с крышкой) он довольно простой.

80
00:06:03,137 --> 00:06:07,709
Здесь просто модули, и поэтому мы
знаем что при разных значениях β,

81
00:06:07,709 --> 00:06:11,505
модули будут по-разному раскрываться,
но в любом случае на каждом участке,

82
00:06:11,505 --> 00:06:15,313
где бы ни раскрывались модули,
будет получаться линейная функция.

83
00:06:15,313 --> 00:06:22,240
Соответственно, наша вся функция M(β
с крышкой) – она кусочно-линейная,

84
00:06:22,240 --> 00:06:28,671
кусочно-линейная, и благодаря этому
факту мы легко построим ее график.

85
00:06:28,671 --> 00:06:30,454
Давайте поймем, где у нее изломы?

86
00:06:30,454 --> 00:06:33,790
Ну, изломы там, где выражение
внутри модуля будет менять знак.

87
00:06:33,790 --> 00:06:38,900
Первое выражение внутри модуля будет
менять знак, когда β с крышкой равно 1,

88
00:06:38,900 --> 00:06:45,780
изломы этой функции — β с крышкой равно 1,
и значение функции в точке 1...

89
00:06:45,780 --> 00:06:52,920
Ну, просто подставляем,
получаем, что это равно 4.

90
00:06:52,920 --> 00:06:56,688
Другой излом, когда второй модуль равен 0,

91
00:06:56,688 --> 00:07:00,724
то есть в точке β с крышкой равное 2/5,

92
00:07:00,724 --> 00:07:05,020
и значение функции в точке 2/5,

93
00:07:05,020 --> 00:07:10,706
если подставить 2/5 сюда, сюда и сюда
и все это сложить, то получится 4,6.

94
00:07:10,706 --> 00:07:14,512
И последний излом нашей
функции в точке β с крышкой,

95
00:07:14,512 --> 00:07:17,050
когда последний модуль равен 0, 6/5.

96
00:07:17,050 --> 00:07:20,004
Соответственно, значение
функции в точке 6/5,

97
00:07:20,004 --> 00:07:22,786
просто подставляем 6/5 в нашу функцию.

98
00:07:22,786 --> 00:07:25,200
Получаем, что это равно 4,2.

99
00:07:25,200 --> 00:07:30,580
И мы уже можем нарисовать
график нашей функции.

100
00:07:30,580 --> 00:07:35,960
Значит, во вертикали мы откладываем
сумму модулей ошибок прогноза,

101
00:07:35,960 --> 00:07:40,415
а по горизонтали откладываем β с крышкой.

102
00:07:40,415 --> 00:07:46,854
Мы знаем,
что изломы в точке 0,4; 1 и 1,2 (это 6/5).

103
00:07:46,854 --> 00:07:52,350
Соответственно, вот один
излом в точке 0,4 (это 2/5),

104
00:07:52,350 --> 00:07:58,050
другой излом в точке 1 и
еще один излом в точке 1,2.

105
00:07:58,050 --> 00:08:03,270
Значение функции в единичке — 4.

106
00:08:03,270 --> 00:08:07,009
Масштаб у меня по горизонтали и по
вертикали может не соответствовать,

107
00:08:07,009 --> 00:08:12,298
поэтому пусть будет тут 4, в 1,2 чуть

108
00:08:12,298 --> 00:08:18,350
побольше и в единичке...

109
00:08:18,350 --> 00:08:22,040
в 0,4 еще больше.

110
00:08:22,040 --> 00:08:27,590
Соответственно, на этих участках функция
выглядит кусочно-линейно вот так.

111
00:08:27,590 --> 00:08:32,275
Но остается понять, как функция будет
выглядеть за пределами этих участков.

112
00:08:32,275 --> 00:08:36,551
Ну, например, если β с крышкой очень-очень
маленькое, очень отрицательное, ну,

113
00:08:36,551 --> 00:08:39,653
например, 0,
то все модули раскрываются с плюсом,

114
00:08:39,653 --> 00:08:44,560
и функция очень быстро убывает, то есть
у нее здесь резко отрицательный наклон.

115
00:08:44,560 --> 00:08:49,661
Если все модули раскрыть, просто убрать
палочки вертикальные, то получится

116
00:08:49,661 --> 00:08:54,417
итоговый наклон (- β с крышкой)- 5β с
крышкой- 5β с крышкой- 11β с крышкой.

117
00:08:54,417 --> 00:08:56,107
Вот здесь вот наклон (-11).

118
00:08:56,107 --> 00:08:59,500
А здесь, соответственно,
все модули раскроются с другим знаком,

119
00:08:59,500 --> 00:09:01,164
и наклон будет положительный.

120
00:09:01,164 --> 00:09:02,830
Вот так выглядит наша функция.

121
00:09:02,830 --> 00:09:05,305
И несмотря на то,
что она не дифференцируема,

122
00:09:05,305 --> 00:09:09,505
мы не можем взять производную,
приравнять к нулю, тем не менее, очевидно,

123
00:09:09,505 --> 00:09:13,867
в прямом смысле этого слова,
что оптимальная оценка,

124
00:09:13,867 --> 00:09:18,893
которая минимизирует сумму модулей ошибок

125
00:09:18,893 --> 00:09:23,298
прогноза β с крышкой равно 1.

126
00:09:23,298 --> 00:09:28,824
Таким образом,
мы в простом примере показали,

127
00:09:28,824 --> 00:09:31,990
как получить оценку медианной регрессии.

