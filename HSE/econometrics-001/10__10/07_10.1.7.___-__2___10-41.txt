
﻿1
00:00:13,065 --> 00:00:15,413
Рассмотрим второй пример,
где будет использоваться другое
априорное распределение.
То есть мы, предположим,
ту же самую модель.
Модель будет состоять в том, что в пруду
караси встречаются с вероятностью p,
а щуки встречаются с вероятностью (1- p).
Но на этот раз у нас будет некая
априорная информация об этом p.
Ну, например, бабушка сказала,
которая вот живет рядом с этим озером,
она сказала, что, ну, скажем, она
сказала: «Караси встречаются чаще щук».
Караси встречаются чаще щук.
И наша задача эту априорную информацию
записать в виде функции плотности.
Ну, тут, к сожалению, мы сталкиваемся с
такой проблемой, как в любой реальной
модели, что у нас, как правило,
информация несколько вот такая размытая.
Ну, чаще, а что означает это «чаще»?
Насколько чаще?
И нам надо реализовать это
как-то математически строго
в виде функции плотности
в байесовском подходе.
Ну, давайте для простоты мы скажем,
что функция плотности имеет вот такой вид.
Здесь вот p, здесь 0, здесь 1,
здесь, соответственно, f(p).
Ну и мы будем считать, что, скажем,
априорная функция плотности вот
имеет какой-то такой возрастающий...
Ну, самая простая возрастающая функция
— это, соответственно, линейная.
Здесь вот двоечка, чтобы площадь
под функцией плотности равнялась 1.
Ну и если эту функцию
плотности записывать формулой,
то f(p) окажется равным 2p
при p[0;1] и 0 иначе.
Это, соответственно, модель,
априорное распределение.
Вот я напишу,
что это априорное распределение.
И у меня должны быть какие-то наблюдения.
Ну, пусть наблюдения будут те же самые,
что и были в предыдущем примере.
Наблюдения будут...
Первое наблюдение — это карась,
второе наблюдение — это
щука и третье наблюдение — это карась.
И точно так же еще надо сказать,
что отдельные наблюдения: в модели
мы предполагаем, Y_i-тые независимы.
Вот у нас имеет место полное описание,
необходимое для байесовского анализа.
Есть наблюдения.
Есть априорное мнение о
неизвестном параметре p.
И есть модель для наблюдений.
Вот эти три ингредиента позволяют
нам получить апостериорное мнение,
то есть мнение с учетом наблюдений,
с учетом имеющейся информации.
Ну, значит, наша задача будет
посчитать следующее: во-первых,
посчитать апостериорное
распределение f(p|Y_1,Y_2,Y_3) и
сравнить E(p) и
E(p) с учетом информации,
содержащейся в Y1, ..., Y3.
И сравнить вероятность того,
что p > 0,5 без учета наблюдений,
и сравнить ту же самую вероятность с
учетом имеющихся наблюдений Y_1, ..., Y_3.
То есть еще раз, по смыслу,
что вот это за показатель?
Это ожидаемая доля,
ожидаемая доля карасей.
А что вот это такое?
Это вероятность того,
что карасей больше, чем щук.
Ну, соответственно,
априорная и апостериорная.
Это вероятность того,
что карасей больше, чем щук.
Ну, поехали.
Ну, для начала давайте посмотрим,
чему равно E(p).
Изначально, если я вот пользуюсь только
информацией «караси встречаются чаще щук»,
реализованной в виде функции плотности,
то, соответственно,
я должен взять интеграл от 0 до 1,
p помножить на функцию плотности,
и у меня получится интеграл от 0 до 1,
p * 2pdp, получается равно 2/3.
И априорная вероятность того,
что карасей больше,
чем щук, то есть карасей больше 50
процентов, это, соответственно,
интеграл от 0,5 до 1,
функция от плотности pdp и это есть...
Ну, если взять этот
интеграл от 0,5 до 1 от 2p,
то есть это площадь...
Здесь 0,5.
Это вот эта площадь.
И она окажется — ну, например,
по формуле площади трапеции или
через взятие интеграла — равна 0,75.
Вот это мое априорное мнение о ситуации
в озере до получения информации.
Ну а теперь поехали.
Исследуем апостериорную функцию плотности.
Давайте оставим место
для графика и получим
апостериорную функцию плотности Y_1,
Y_2, Y_3.
Мы уже говорили,
что она с точностью до сомножителя равна
произведению модели f(Y|p),
— то есть чему равна вероятность
получить наши данные,
если p мысленно зафиксировать, — помножить
на априорную функцию плотности p.
Ну, давайте подумаем, чему равна
вероятность получить такие Y-ки,
вот такие вот, как у нас, если p известно.
Ну, если p известно, то вероятность
карася — p, щуки — (1- p), карася — p,
и нам надо их все
перемножить: p * (1- p) * p.
p * (1- p) * p, это,
соответственно, взялось из модели.
И еще априорная функция
плотности — она просто 2p,
и получаем,
что с точностью до сомножителя,
до константы — это p куб * (1- p) Ну,
соответственно, это верна формула при
p от 0 до 1, а иначе получается 0.
Вот такая вот у нас
апостериорная функция плотности.
Ну, поскольку интеграл под любой
функцией плотности должен равняться 1,
то можно восстановить пропущенный
множитель, который я потерял,
когда здесь не поделил
на функцию плотности Y.
То есть можно восстановить пропущенную
константу так, чтобы интеграл...
То есть у меня есть условие,
что интеграл от 0 до 1,
f(p|Y)dp должен равняться 1,
и отсюда если взять интеграл,
он окажется равен 1/20 вот этот,
и его надо будет домножить на 20.
Соответственно, f(p|Y) = 20
* p в кубе * (1- p) или 0 — это при p,
лежащем от 0 до 1.
И можно нарисовать, соответственно,
апостериорную функцию плотности,
опять же, от 0 до 1.
Выглядит она немножко другим образом.
Она выглядит...
Вот здесь она начинается очень медленно,
потом она резко поднимается вверх
и вот так вот опускается вниз.
То есть это апостериорная
функция плотности.
Она имеет, соответственно, вот такую
вот формулу: 20p в кубе * (1- p), и,
соответственно, я вижу,
что если учесть информацию от
бабушки априорную до получения наблюдений,
учесть наблюдения,
то у нас получится
апостериорное мнение о p.
То есть шансы, что я верю,
что карасей в озере мало, они минимальны.
Вот здесь вот очень низко
проходит функция плотности.
Ну и, соответственно, эта новая функция
плотности апостериорная, — давайте отмечу,
что здесь f(p|Y) при условии
известных Y-ов наблюдений,
— она позволяет мне пересчитать,
что я ожидаю от доли карасей и
что я ожидаю от вероятности того,
что карасей больше, чем щук.
Соответственно, с использованием вот
этой функции плотности, если я считаю
математическое ожидание как интеграл,
E(p|Y), то есть это интеграл от 0 до 1,
p помножить на условную функцию
плотности по dp, и окажется,
если я проинтегрирую p помножить на
эту штуку, здесь окажется тоже 2/3.
То есть оказывается, что мои, как бы,
повышенные наблюдения карасей оно
вот подтверждает информацию от
бабушки и поэтому никак не
искажает математическое ожидание.
Что я думал, так я примерно...
Данные подтверждают вот это матожидание,
поэтому оно не поменялось.
А вероятность она еще вырастет.
То есть вероятность того, что карасей
больше, чем щук при известных Y-ках...
Мне, соответственно,
надо взять интеграл от 0,5 до 1 условной
функции f(p|Y) И если взять
интеграл от этой функции плотности,
ну, не забыв двадцатку, конечно,
то получится результат 13/16.
Ну, это примерно 0,81.
То есть это означает, что изначально
я думал, что вероятность того,
что карасей больше,
чем щук — 0,75, три четверти,
а когда я получил вот эти
наблюдения — карась, щука, карась,
я стал оценивать вероятность того,
что карасей больше, чем щук, как 0,81.
Еще раз хочу подчеркнуть,
что в байесовском подходе вся информация о
неизвестном параметре
описывается функцией плотности.
Вот это функция плотности
до получения наблюдений,
вот это функция плотности
после получения наблюдений.
И дальше с помощью нее можно
ответить на любые вопросы,
как расчет любого среднего
или любой вероятности.
Но еще раз — надо помнить о том,
что p трактуется
как случайная величина.

