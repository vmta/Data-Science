
﻿1
00:00:13,250 --> 00:00:16,815
И завершающий сюжет — байесовский подход.
Во-первых, следует обратить внимание,
что байесовский подход
— это именно другой подход к
оцениванию неизвестных коэффициентов.
Это не другая модель, ну то есть вот,
например, есть медианная регрессия — это
одна модель для данных, есть классическая
регрессия — это другая модель для данных,
а байесовский подход,
он устроен принципиально по-иному,
то есть в рамках байесовского подхода
можно изучать классическую регрессию,
в рамках байесовского подхода
можно изучать медианную регрессию.
Байесовский подход — это другой подход
к оцениванию, а не другая модель.
Суть байесовского подхода сводится
к следующей простой идее.
Давайте наше незнание,
нашу неуверенность в истинном значении
параметра θ оформим в виде функции
распределения, в виде функции плотности.
То есть мы не уверены чему равно θ,
но давайте скажем, что мы считаем,
что вот оно в среднем около нуля,
там или что-то в этом духе.
Ну, например: если неизвестным является
параметр вероятности p какого-либо
события, то мы можем предположить,
что у него есть априорная плотность,
мы можем считать априорно,
что p равномерно распределен от 0 до 1.
Ну раз я не знаю, чему равна вероятность,
ну за пределы 0, 1 она выходить не может,
вот я и буду считать,
что она равномерно распределена от 0 до 1.
А потом,
когда я получу какие-то наблюдения,
я изменю свою мнение в соответствии
с законами теории вероятности.
Если какой-то коэффициент, скажем,
я уверен, что он положительный, ну я,
например, из экономических соображений
ожидаю, что предложение какого-то товара,
величина предложения, положительно
связана с ценой этого товара, и,
соответственно, я могу считать,
что коэффициент β,
который показывает эту зависимость,
он положительный, и, соответственно,
я могу считать, что он, допустим, может
иметь экспоненциальное распределение,
то есть функция плотности может быть
сосредоточена на положительных β.
И, соответственно, по прежнему,
у нас остается модель, то есть модель
может быть, например, та же самая
классическая модель линейной регрессии,
где y_i = β₁ + β₂x_i + ε_i,
где ε_i нормально (0, σ квадрат).
Еще раз — изменения касаются моего способа
моделирования неизвестных параметров.
Сейчас я считаю в байесовском подходе,
что неизвестные параметры β1,
β2, σ квадрат — это случайные величины,
и я предполагаю некоторый закон
распределения априорный на них,
который отражает мое
незнание этих параметров.
И логика байесовского подхода,
она предельно проста и понятна —
я специфицирую модель для
наблюдаемых данных, модель для y_i,
которой может быть, например,
классическая модель линейной регрессии,
я специфицирую априорное распределение
на неизвестные параметры.
Например, на — β₁, β₂ и σ квадрат.
И дальше по формулам условной вероятности
я получаю то, что что называется
апостериорным распределением, то есть моим
мнением с учетом имеющейся информации.
То есть до того, как я приступал к анализу
данных, до того, как я имел какие-либо
наблюдения, у меня было заранее
сформировано некоторое мнение,
априорное мнение, после того, как я учел
имеющиеся наблюдения, у меня получилось
апостериорное распределение, то есть мое
мнение с учетом имеющихся наблюдений.
Формула условной вероятности, она,
которая преобразует априорное
распределение в апостериорное
распределение, предельно проста.
Это, соответственно, условная вероятность
y при фиксированных параметрах θ,
помножить на вероятность для параметра θ,
делить на вероятность y.
Ну или тоже самое в непрерывном
случае с функциями плотности.
Но, поскольку нас интересует зависимость
именно от неизвестного параметра,
а в знаменателе неизвестного
параметра θ нет, то можно сказать,
что условная функция плотности θ
при известных y пропорциональна
произведению условной функции
плотности y при известных θ,
помножить на априорную
функцию плотности f от θ.
И сейчас мы на простом примере покажем,
как из априорной информации,
из априорной функции плотности получается
в простейшем случае апостериорное
мнение о неизвестном параметре,
апостериорная функция плотности.

