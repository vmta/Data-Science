1
00:00:13,320 --> 00:00:17,934
Этот фрагмент особо полезен тем,
кто знает линейную алгебру.

2
00:00:17,934 --> 00:00:22,769
Оказывается, средствами линейной
алгебры легко не только сразу

3
00:00:22,769 --> 00:00:26,470
посчитать дисперсию β1 с
крышкой или β2 с крышкой,

4
00:00:26,470 --> 00:00:29,970
одним махом можно найти все эти
дисперсии и все ковариации.

5
00:00:29,970 --> 00:00:32,870
Они все находятся в этой
ковариационной матрице.

6
00:00:32,870 --> 00:00:36,879
Действительно, это матрица,
которая устроена следующим образом.

7
00:00:36,879 --> 00:00:40,370
Здесь находится дисперсия β1 с
крышкой при фиксированном X,

8
00:00:40,370 --> 00:00:46,507
дальше идет ковариация β1 с крышкой β2 с
крышкой при фиксированном X и так далее.

9
00:00:46,507 --> 00:00:49,130
Здесь идёт ковариация — вторая срока,

10
00:00:49,130 --> 00:00:53,910
первый столбец — β2 с крышкой с
β1 с крышкой при фиксированном X,

11
00:00:53,910 --> 00:00:59,043
дальше идёт дисперсия β2 с крышкой
при фиксированном X и так далее.

12
00:00:59,043 --> 00:01:04,530
И заканчивается это всё дисперсией
βk с крышкой при фиксированном X.

13
00:01:04,530 --> 00:01:09,410
Оказывается, очень компактная
формула в терминах линейной алгебры

14
00:01:09,410 --> 00:01:12,440
есть для этой матрицы.

15
00:01:12,440 --> 00:01:16,610
βk с крышкой при фиксированном X.

16
00:01:16,610 --> 00:01:21,198
И здесь точно такое же, ковариационная
матрица, она всегда симметричная.

17
00:01:21,198 --> 00:01:25,480
β1 с крышкой βk с крышкой при
фиксированных регрессорах.

18
00:01:25,480 --> 00:01:30,495
Ну чтобы понять,
как легко получить эту формулу,

19
00:01:30,495 --> 00:01:34,220
нам сначала надо понять, какими свойствами
обладает ковариационная матрица.

20
00:01:34,220 --> 00:01:40,230
Значит, во-первых,
свойства ковариационных матриц.

21
00:01:40,230 --> 00:01:44,393
Во-первых, посмотрим, какие есть
свойства у математического ожидания.

22
00:01:44,393 --> 00:01:47,981
Вот если у меня есть математическое
ожидание от вектора,

23
00:01:47,981 --> 00:01:52,350
то это имеется в виду вектор
из математических ожиданий.

24
00:01:52,350 --> 00:01:56,117
И у математического

25
00:01:56,117 --> 00:02:01,266
ожидания свойства совершенно аналогичные,

26
00:02:01,266 --> 00:02:06,418
у векторного математического ожидания
свойства совершенно аналогичные скалярным.

27
00:02:06,418 --> 00:02:12,500
Ну то есть для одномерных случайных
величин, одномерные случайные величины,

28
00:02:12,500 --> 00:02:17,812
было свойство: математическое
ожидание от a на у равняется

29
00:02:17,812 --> 00:02:23,522
a (давайте y1 напишем) на
математическое ожидание y1.

30
00:02:23,522 --> 00:02:28,143
В многомерном случае,
многомерные случайные величины,

31
00:02:28,143 --> 00:02:30,942
здесь несколько дело обстоит посложнее,

32
00:02:30,942 --> 00:02:36,340
поскольку a — это должна быть матрица,
и важен порядок умножения матриц.

33
00:02:36,340 --> 00:02:38,260
Тут будет два свойства.

34
00:02:38,260 --> 00:02:42,884
E(A) * y будет равняться A * E(y),
это нетрудно доказать,

35
00:02:42,884 --> 00:02:44,817
но это достаточно интуитивно.

36
00:02:44,817 --> 00:02:48,575
И второе свойство,
что если у меня y умножается на матрицу B,

37
00:02:48,575 --> 00:02:53,212
B с другой стороны, то и выносить B
можно только направо из математического

38
00:02:53,212 --> 00:02:57,650
ожидания: E(y) * B.

39
00:02:57,650 --> 00:03:02,847
Соответственно, как можно

40
00:03:02,847 --> 00:03:07,645
определить вот эту самую ковариационную

41
00:03:07,645 --> 00:03:12,636
матрицу от вектора β с
крышкой при фиксированном X?

42
00:03:12,636 --> 00:03:16,105
Это есть не что иное, как условное...

43
00:03:16,105 --> 00:03:18,812
Это определение ковариационной матрицы,

44
00:03:18,812 --> 00:03:21,820
его выражение через
математическое ожидание.

45
00:03:21,820 --> 00:03:27,370
Это математическое ожидание вектора
β с крышкой на вектор β с крышкой

46
00:03:27,370 --> 00:03:32,322
транспонированное при
фиксированном X минус

47
00:03:32,322 --> 00:03:39,736
математическое ожидание от β
с крышкой при фиксированном

48
00:03:39,736 --> 00:03:44,755
X на математическое ожидание β с крышкой
транспонированное при фиксированном X.

49
00:03:44,755 --> 00:03:49,650
Эта формула является
обобщением одномерной формулы,

50
00:03:49,650 --> 00:03:54,782
что дисперсия y1 при

51
00:03:54,782 --> 00:03:59,681
фиксированном X — это

52
00:03:59,681 --> 00:04:05,110
есть математическое
ожидание от y1-квадрат при

53
00:04:05,110 --> 00:04:10,460
фиксированном X минус математическое

54
00:04:10,460 --> 00:04:14,500
ожидание от y1 при фиксированном X,
взятое в квадрат.

55
00:04:14,500 --> 00:04:21,881
Соответственно, вернёмся
к этому обобщению.

56
00:04:21,881 --> 00:04:22,851
Что мы получаем?

57
00:04:22,851 --> 00:04:24,856
Мы получаем такое важное свойство.

58
00:04:24,856 --> 00:04:30,630
Если скомбинировать свойство
математического ожидания и определение,

59
00:04:30,630 --> 00:04:37,306
то мы получим такое важное
свойство ковариационной матрицы.

60
00:04:37,306 --> 00:04:43,350
Ковариационная матрица A на β с
крышкой при фиксированном X равняется:

61
00:04:43,350 --> 00:04:48,602
математическое ожидание от
A на β с крышкой помножить

62
00:04:48,602 --> 00:04:53,711
A на β с крышкой транспонированное
при фиксированном

63
00:04:53,711 --> 00:04:58,809
X минус математическое
ожидание от A на β с крышкой

64
00:04:58,809 --> 00:05:03,864
при фиксированном X на
математическое ожидание от A на β

65
00:05:03,864 --> 00:05:09,940
с крышкой потом транспонированное
при фиксированном X.

66
00:05:09,940 --> 00:05:14,197
При транспонировании меняется
порядок следования матриц,

67
00:05:14,197 --> 00:05:17,480
меняется порядок,
в котором они умножаются.

68
00:05:17,480 --> 00:05:20,080
И мы получаем, что это есть...

69
00:05:20,080 --> 00:05:24,750
Дальше из этого математического
ожидания наружу вылезет A,

70
00:05:24,750 --> 00:05:27,328
а вот здесь поменяется порядок.

71
00:05:27,328 --> 00:05:29,820
И если налево будет вылезать A,

72
00:05:29,820 --> 00:05:34,610
то вот из этого сомножителя направо
будет вылезать A транспонированное.

73
00:05:34,610 --> 00:05:37,479
Здесь тоже A вылезет налево,

74
00:05:37,479 --> 00:05:42,997
а вот здесь вот направо
вылезет A транспонированное.

75
00:05:42,997 --> 00:05:47,690
И получится: A помножить

76
00:05:47,690 --> 00:05:52,860
на E от β с крышкой на β с
крышкой транспонированное

77
00:05:52,860 --> 00:05:58,015
при фиксированных X минус
E от β с крышкой при

78
00:05:58,015 --> 00:06:02,945
фиксированных X на E от β с
крышкой транспонированное

79
00:06:02,945 --> 00:06:08,128
при фиксированных X и еще
помножить на A транспонированное.

80
00:06:08,128 --> 00:06:12,490
И получится у нас такое
замечательное свойство.

81
00:06:12,490 --> 00:06:17,290
A вышла налево,
посерёдке осталась ковариационная

82
00:06:17,290 --> 00:06:20,580
матрица вектора β с крышкой,
а справа появилась A транспонированная.

83
00:06:20,580 --> 00:06:27,519
То есть аналогом формулы: дисперсия

84
00:06:27,519 --> 00:06:33,108
a на y1 при фиксированном X — a-квадрат

85
00:06:33,108 --> 00:06:37,687
на дисперсию y1 при фиксированном X,

86
00:06:37,687 --> 00:06:41,860
— аналогом этой формулы
выступает следующая:

87
00:06:41,860 --> 00:06:46,800
ковариационная матрица A на
вектор y при фиксированном X

88
00:06:46,800 --> 00:06:52,093
равняется A на
ковариационную матрицу y при

89
00:06:52,093 --> 00:06:57,661
фиксированном X

90
00:06:57,661 --> 00:07:03,110
умножить на A транспонированную.

91
00:07:03,110 --> 00:07:07,346
И этого свойства нам будет
совершенно достаточно,

92
00:07:07,346 --> 00:07:11,967
чтобы посчитать вот эту
самую ковариационную матрицу

93
00:07:11,967 --> 00:07:16,129
оценок коэффициентов β
с крышкой в общем виде.

94
00:07:16,129 --> 00:07:18,300
Ну давайте попробуем.

95
00:07:18,300 --> 00:07:25,940
Я напомню, что β с крышкой
равняется X'X в минус первой X'y.

96
00:07:25,940 --> 00:07:29,680
И у нас есть предпосылка,

97
00:07:29,680 --> 00:07:34,825
что ковариационная матрица вектора

98
00:07:34,825 --> 00:07:39,460
ε при фиксированных X имеет вид
σ-квадрат умножить на единичную.

99
00:07:39,460 --> 00:07:44,269
Ну и, конечно же,
у нас в матричном виде наша

100
00:07:44,269 --> 00:07:48,310
модель записывается как y
равняется X на β плюс ε.

101
00:07:48,310 --> 00:07:52,573
На первом шаге, шаг 1,

102
00:07:52,573 --> 00:08:00,037
мы найдём ковариационную матрицу
вектора y при фиксированных X.

103
00:08:00,037 --> 00:08:07,580
Это есть ковариационная матрица вектора
X на β плюс ε при фиксированных X.

104
00:08:07,580 --> 00:08:13,060
Но если X фиксированы,
то вот это — это просто константа.

105
00:08:13,060 --> 00:08:18,006
Константы не влияют ни на дисперсии,
ни на ковариации, которые «живут» в этой

106
00:08:18,006 --> 00:08:22,705
матрице, поэтому их
можно просто не писать.

107
00:08:22,705 --> 00:08:26,750
Это есть ковариационная матрица вектора
ε при фиксированных X, и это есть,

108
00:08:26,750 --> 00:08:30,610
по предположению,
σ-квадрат умножить на единичную матрицу.

109
00:08:30,610 --> 00:08:35,930
И остался шаг 2.

110
00:08:35,930 --> 00:08:41,147
Ковариационная матрица вектора
β с крышкой при фиксированных

111
00:08:41,147 --> 00:08:46,900
X равняется:

112
00:08:46,900 --> 00:08:52,074
ковариационная матрица
вектора X'X в минус первой

113
00:08:52,074 --> 00:08:56,570
X'y при фиксированных X.

114
00:08:56,570 --> 00:09:01,100
Это какая-то одна здоровая
матрица констант.

115
00:09:01,100 --> 00:09:05,175
Поскольку у нас регрессоры, иксы,

116
00:09:05,175 --> 00:09:09,250
считаются константами, мы выносим ее —
налево, и направо — транспонированную.

117
00:09:09,250 --> 00:09:14,432
Получаем X'X в минус первой X' умножить на

118
00:09:14,432 --> 00:09:20,805
ковариационную матрицу вектора y
при фиксированных X умножить на

119
00:09:20,805 --> 00:09:26,260
X'X в минус первой X' транспонированная.

120
00:09:26,260 --> 00:09:32,210
Равняется, это так и остаётся,

121
00:09:32,210 --> 00:09:39,140
X'X в минус первой X', это получается
σ-квадрат умножить на единичную матрицу.

122
00:09:39,140 --> 00:09:40,992
А здесь надо транспонировать.

123
00:09:40,992 --> 00:09:45,403
При транспонировании меняется порядок,
и надо ещё раз транспонировать.

124
00:09:45,403 --> 00:09:49,830
Значит, вот этот X — он станет первым,
а вот эта матрица встанет направо.

125
00:09:49,830 --> 00:09:54,755
То есть вот эта и вот эта
матрица поменяются местам,

126
00:09:54,755 --> 00:09:56,275
и надо будет ещё транспонировать.

127
00:09:56,275 --> 00:09:58,870
Ну X транспонированный
транспонированное будет просто X.

128
00:09:58,870 --> 00:10:01,960
А эта матрица — она симметричная.

129
00:10:01,960 --> 00:10:06,070
Ну потому что, действительно,
X транспонированное X,

130
00:10:06,070 --> 00:10:08,588
если ее транспонировать, будет...

131
00:10:08,588 --> 00:10:12,150
Переставляем местами и
довешиваем транспонирование.

132
00:10:12,150 --> 00:10:15,132
X транспонированное на X,
дважды транспонированное, это X'X.

133
00:10:15,132 --> 00:10:18,230
То есть вот эта матрица симметричная,
её можно не транспонировать.

134
00:10:18,230 --> 00:10:23,970
Получаем X'X в минус первой.

135
00:10:23,970 --> 00:10:28,855
И замечаем, что единичную матрицу
можно при умножении не писать.

136
00:10:28,855 --> 00:10:31,350
Константу можно вынести вперёд.

137
00:10:31,350 --> 00:10:36,257
И получится: σ-квадрат умножить на X'X в

138
00:10:36,257 --> 00:10:41,789
минус первой X' на X
на X'X в минус первой.

139
00:10:41,789 --> 00:10:49,361
Вот эти матрицы обратные,
при умножении они взаимно уничтожатся,

140
00:10:49,361 --> 00:10:56,410
и останется готовый приятный ответ:
σ-квадрат на X'X в минус первой.

141
00:10:56,410 --> 00:11:02,209
Соответственно, мы пришли к выводу,
что ковариационная матрица вектора

142
00:11:02,209 --> 00:11:09,025
β с крышкой при фиксированных X имеет вид
σ-квадрат помножить на X'X в минус первой.

143
00:11:09,025 --> 00:11:15,020
В этой матрице находятся и дисперсии
условные каждого β с крышкой,

144
00:11:15,020 --> 00:11:18,446
и ковариации каждого β с
крышкой с каждым β с крышкой.

145
00:11:18,446 --> 00:11:22,930
И в скалярном виде мы их выводили долго
по отдельности и только для случая

146
00:11:22,930 --> 00:11:27,891
парной регрессии, а в матричном виде
они выводятся легко, все и сразу,

147
00:11:27,891 --> 00:11:30,960
и этой формулой можно будет пользоваться.

