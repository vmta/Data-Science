1
00:00:16,230 --> 00:00:19,838
Мы говорили о том,
что коэффициенты бывают значимыми,

2
00:00:19,838 --> 00:00:22,988
но несущественными,
и существенными, но не значимыми.

3
00:00:22,988 --> 00:00:26,198
Один из способов почувствовать
существенный коэффициент или нет,

4
00:00:26,198 --> 00:00:31,600
— это посчитать стандартизированные
коэффициенты β с крышкой,

5
00:00:31,600 --> 00:00:37,028
то есть привести все объясняющие
переменные и объясняемую переменную

6
00:00:37,028 --> 00:00:42,254
к неким универсальным единицам измерения,
чтобы они были сравнимы, а именно: вычесть

7
00:00:42,254 --> 00:00:47,268
из каждой переменной её среднее и поделить
на оценённое стандартное отклонение.

8
00:00:47,268 --> 00:00:52,105
Соответственно, мы это сделаем, построим
регрессию в стандартизированных переменных

9
00:00:52,105 --> 00:00:56,917
и получим стандартизированные коэффициенты
β с крышкой, которые можно уже, например,

10
00:00:56,917 --> 00:00:59,430
корректно сравнивать между собой,

11
00:00:59,430 --> 00:01:04,130
и тем самым оценить силу влияния
переменной, не говоря про значимость.

12
00:01:08,770 --> 00:01:14,700
Стандартизированные коэффициенты.

13
00:01:14,700 --> 00:01:17,911
На шаге один мы преобразуем
каждую переменную,

14
00:01:17,911 --> 00:01:20,262
масштабируем каждую переменную.

15
00:01:20,262 --> 00:01:27,087
Значит, создадим набор h_st,
где мы изменим каждую переменную,

16
00:01:27,087 --> 00:01:32,083
функция называется mutate_each, в наборе
данных h, а формула, по которой мы будем,

17
00:01:32,083 --> 00:01:35,810
функция, по которой мы будем менять
каждую переменную, называется scale,

18
00:01:35,810 --> 00:01:40,314
она осуществляет как раз
масштабирование, вычитание среднего и

19
00:01:40,314 --> 00:01:44,350
деления на стандартную ошибку.

20
00:01:44,350 --> 00:01:46,343
Стандартизировали переменные.

21
00:01:46,343 --> 00:01:50,610
Можем также посмотреть на этот набор
стандартизированных переменных.

22
00:01:50,610 --> 00:01:55,607
И теперь мы оцениваем ту же самую модель,
то есть я просто скопирую эту строчку

23
00:01:55,607 --> 00:01:59,791
кода, за тем исключением, что нам надо её,
конечно, по-другому назвать.

24
00:01:59,791 --> 00:02:01,075
Пусть будет model_st.

25
00:02:01,075 --> 00:02:06,080
И, конечно, данные надо брать
не из исходного набора данных,

26
00:02:06,080 --> 00:02:09,940
а там, где они уже стандартизированы,
то есть из набора данных h_st.

27
00:02:09,940 --> 00:02:14,075
Запускаем.

28
00:02:14,075 --> 00:02:18,210
Смотрим отчёт по
стандартизированной модели.

29
00:02:18,210 --> 00:02:21,860
И здесь уже вот эти коэффициенты,

30
00:02:21,860 --> 00:02:25,924
их можно сравнивать между собой,
они уже показывают более,

31
00:02:25,924 --> 00:02:29,950
в каком-то смысле,
объективно силу влияния каждой переменной.

32
00:02:29,950 --> 00:02:34,415
Можно также визуализировать зависимость.

33
00:02:34,415 --> 00:02:39,387
Вот была визуализирована зависимость
коэффициентов исходных не

34
00:02:39,387 --> 00:02:41,220
стандартизированных.

35
00:02:41,220 --> 00:02:46,297
Точно так же с помощью
функции sjp.lm можно

36
00:02:46,297 --> 00:02:51,960
визуализировать коэффициенты
в стандартизированных,

37
00:02:51,960 --> 00:02:55,200
в стандартизированных переменных.

38
00:02:55,200 --> 00:02:58,510
Для этого на самом деле даже не
нужны все эти преобразования,

39
00:02:58,510 --> 00:03:00,620
функция sjp.lm всё это сделает сама.

40
00:03:00,620 --> 00:03:05,060
Можно просто указать исходную
модель model и указать,

41
00:03:05,060 --> 00:03:09,344
что нам нужны
стандартизованные коэффициенты.

42
00:03:09,344 --> 00:03:14,530
Это опция showStandardBeta = TRUE.

43
00:03:14,530 --> 00:03:19,100
И, соответственно, сейчас на

44
00:03:19,100 --> 00:03:24,760
графике появятся на этот раз
стандартизированные коэффициенты.

45
00:03:32,760 --> 00:03:37,305
Здесь уже доверительные
интервалы не строятся,

46
00:03:37,305 --> 00:03:41,850
потому что они в других единицах
измерения по сравнению с исходными.

47
00:03:41,850 --> 00:03:45,483
Сейчас мы на искусственных данных
проиллюстрируем идею того,

48
00:03:45,483 --> 00:03:49,527
что нельзя просто так построить
регрессию и отвечать на вопрос,

49
00:03:49,527 --> 00:03:52,250
а какие коэффициенты у меня значимы.

50
00:03:52,250 --> 00:03:55,936
Надо сначала сформулировать гипотезу
и проверять те коэффициенты,

51
00:03:55,936 --> 00:03:57,280
которые вас интересуют.

52
00:03:57,280 --> 00:04:02,030
Давайте попробуем.

53
00:04:02,030 --> 00:04:05,670
Искусственный эксперимент.

54
00:04:05,670 --> 00:04:11,440
Мы сочиним в нашем искусственном
эксперименте совершенно несвязанный игрек,

55
00:04:11,440 --> 00:04:15,427
который никак не зависит от
якобы объясняющих переменных.

56
00:04:15,427 --> 00:04:18,400
У нас будет 40 якобы
объясняющих переменных,

57
00:04:18,400 --> 00:04:21,769
одна якобы зависимая,
хотя на самом деле независимая,

58
00:04:21,769 --> 00:04:25,164
и мы будем строить,
оценивать модель линейной регрессии.

59
00:04:25,164 --> 00:04:27,291
Давайте сначала сгенерим наши данные.

60
00:04:27,291 --> 00:04:28,800
Сначала сгенерим матрицу.

61
00:04:28,800 --> 00:04:34,340
Наша матрица D, это будет матрица,

62
00:04:34,340 --> 00:04:37,710
мы расположим в этой матрице,

63
00:04:37,710 --> 00:04:42,720
соответственно, пусть в
матрице будет 100 строк.

64
00:04:42,720 --> 00:04:46,220
Количество строк равно ста.

65
00:04:46,220 --> 00:04:51,350
И в этой матрице мы, соответственно,
расположим нормальные случайные величины,

66
00:04:51,350 --> 00:04:55,835
случайно сгенерированные,
в количестве 100 умножить на 41,

67
00:04:55,835 --> 00:05:01,070
потому что у нас будет 40 регрессоров,
одна объясняемая переменная.

68
00:05:01,070 --> 00:05:07,670
Давайте укажем, что среднее равно там
будет 0, и стандартная ошибка равна 1.

69
00:05:07,670 --> 00:05:11,026
Соответственно, сгенерировали
матрицу иксов.

70
00:05:11,026 --> 00:05:12,980
Превратим её в набор данных.

71
00:05:12,980 --> 00:05:18,720
df — это будет data.frame (D).

72
00:05:18,720 --> 00:05:20,930
И теперь оценим новую модель.

73
00:05:20,930 --> 00:05:24,850
Как бы мы знаем,
что на самом деле зависимости нет,

74
00:05:24,850 --> 00:05:31,060
поэтому давайте так и
напишем: model_pusto.

75
00:05:31,060 --> 00:05:35,173
Это линейная модель,

76
00:05:35,173 --> 00:05:40,200
данные мы берём из таблички данных df.

77
00:05:40,200 --> 00:05:43,515
А что у нас является регрессорами?

78
00:05:43,515 --> 00:05:47,778
Давайте посмотрим, какие названия
присвоил R по умолчанию нашим переменным,

79
00:05:47,778 --> 00:05:49,040
которые мы сгенерили.

80
00:05:49,040 --> 00:05:53,516
Смотрим на набор данных df и видим,что

81
00:05:53,516 --> 00:05:58,348
здесь 41 переменная: x1,
сгенерированная случайно, x2,

82
00:05:58,348 --> 00:06:02,918
сгенерированная случайно, и так далее,
x41, сгенерированная случайно.

83
00:06:02,918 --> 00:06:06,580
По каждой будет 100 значений,
но показаны только первые несколько.

84
00:06:06,580 --> 00:06:11,643
И мы, соответственно, построим
регрессию переменной x1 на остальные.

85
00:06:11,643 --> 00:06:15,980
Когда переменных много,
то перечислять их все, конечно, лень,

86
00:06:15,980 --> 00:06:20,300
и в R для ленивых сделано
специальное сокращение «точка»,

87
00:06:20,300 --> 00:06:25,493
которое означает, что, пытаюсь объяснить
переменную x1 всеми остальными,

88
00:06:25,493 --> 00:06:27,720
имеющимися в моём наборе данных.

89
00:06:27,720 --> 00:06:32,084
Оцениваем эту модель-«пустышку».

90
00:06:32,084 --> 00:06:36,696
И смотрим на значимость
коэффициентов: обнаружит ли компьютер,

91
00:06:36,696 --> 00:06:40,100
что якобы какие-то коэффициенты
являются значимыми.

92
00:06:40,100 --> 00:06:45,297
И здесь мы видим следующий факт,
что вот видно,

93
00:06:45,297 --> 00:06:49,564
тут компьютер поставил автоматом
точечку рядом с теми коэффициентами,

94
00:06:49,564 --> 00:06:52,570
которые значимы на десятипроцентном
уровне значимости.

95
00:06:52,570 --> 00:06:57,448
Соответственно, на десятипроцентном уровне
значимости у меня будет отвергаться

96
00:06:57,448 --> 00:07:02,804
гипотеза о том, что x17 не влияет,
будет отвергаться гипотеза о том,

97
00:07:02,804 --> 00:07:07,712
что x6 не влияет, и будет отвергаться
гипотеза о том, что x21 не влияет,

98
00:07:07,712 --> 00:07:12,586
то есть эти три переменные, выходит,
влияют на зависимую переменную x1,

99
00:07:12,586 --> 00:07:15,779
хотя на самом деле всё
генерировалось случайно.

100
00:07:15,779 --> 00:07:17,000
С чем это связано?

101
00:07:17,000 --> 00:07:23,027
Это связано с тем,
что когда мы фиксируем уровень значимости,

102
00:07:23,027 --> 00:07:26,330
мы соглашаемся на некоторую
вероятность ошибиться.

103
00:07:26,330 --> 00:07:31,295
Соответственно, когда мы зафиксировали
уровень значимости 10%, это означает,

104
00:07:31,295 --> 00:07:35,211
что с вероятностью 10%
мы в случае на самом деле

105
00:07:35,211 --> 00:07:39,960
отсутствия зависимости якобы её обнаружим.

106
00:07:39,960 --> 00:07:44,888
Соответственно, с десятипроцентным
шансом мы в данной ситуации

107
00:07:44,888 --> 00:07:50,120
каждый коэффициент признаём значимым.

108
00:07:50,120 --> 00:07:54,930
Ну вот у меня компьютер обнаружил
три ложно значимых коэффициента.

109
00:07:54,930 --> 00:07:58,314
Но на самом деле,
поскольку данные генерировались случайно,

110
00:07:58,314 --> 00:08:02,149
у вас их может быть чуть больше или
чуть меньше, тут уж как повезёт,

111
00:08:02,149 --> 00:08:07,032
но хотя бы один будет практически
наверняка, потому что 40 экспериментов,

112
00:08:07,032 --> 00:08:10,810
и в каждом эксперименте —
десятипроцентный шанс сделать ошибку.

113
00:08:10,810 --> 00:08:16,350
Соответственно, из этого искусственного
эксперимента нужно сделать простой вывод,

114
00:08:16,350 --> 00:08:21,031
что стратегия «я оценю
модель с большим количеством

115
00:08:21,031 --> 00:08:25,610
объясняющих переменных и
выпишу из них значимые,

116
00:08:25,610 --> 00:08:30,316
и скажу, что от них игрек зависит»,
— неправильная,

117
00:08:30,316 --> 00:08:35,187
потому что в силу того, что есть для
каждого регрессора десятипроцентный

118
00:08:35,187 --> 00:08:40,005
или пятипроцентный шанс сделать ошибку,
при большом количестве регрессоров

119
00:08:40,005 --> 00:08:44,690
кто-то якобы значимым будет, даже если
на самом деле никакой зависимости нет.

120
00:08:44,690 --> 00:08:50,792
И ещё один маленький полезный сюжет.

121
00:08:50,792 --> 00:08:54,840
Иногда возникает необходимость
сравнить рядом несколько моделей.

122
00:08:54,840 --> 00:09:00,210
Сравнить несколько моделей.

123
00:09:00,210 --> 00:09:06,340
К примеру, я оценил очень похожую
на исходную самую первую модель,

124
00:09:06,340 --> 00:09:12,906
оценю очень похожую модель,
но куда не включу Examination.

125
00:09:12,906 --> 00:09:15,600
Вот не включил сюда Examination.

126
00:09:15,600 --> 00:09:18,690
Ой, надо было её model2 назвать.

127
00:09:18,690 --> 00:09:23,652
Давайте, значит,
ещё раз запустим первую строчку.

128
00:09:23,652 --> 00:09:28,120
А эту модель более простую назовём model2.

129
00:09:28,120 --> 00:09:32,825
И теперь хочу сравнить
несколько моделей рядом.

130
00:09:32,825 --> 00:09:36,353
Можно, конечно, смотреть на первый
результат оценивания, на второй,

131
00:09:36,353 --> 00:09:37,530
но так иногда неудобно.

132
00:09:37,530 --> 00:09:40,802
Поэтому мы давайте сделаем табличку,

133
00:09:40,802 --> 00:09:45,670
в которой сравниваются сразу
несколько моделей compar_12.

134
00:09:45,670 --> 00:09:51,370
Функция mtable нам поможет из пакета memisc.

135
00:09:51,370 --> 00:09:55,560
И тут мы напишем,
что мы сравниваем model и model2.

136
00:09:55,560 --> 00:10:01,040
Всё, сравнили, теперь можно
посмотреть на результаты сравнения.

137
00:10:01,040 --> 00:10:07,720
И у нас просто рядом будут
написаны две модели.

138
00:10:07,720 --> 00:10:11,900
Для каждой — все оценки коэффициентов

139
00:10:11,900 --> 00:10:15,531
друг напротив друга и в
скобках стандартные ошибки.

140
00:10:15,531 --> 00:10:17,600
Также указана значимость в виде звёздочек.

141
00:10:17,600 --> 00:10:22,660
Соответственно, мы можем сразу
одним взглядом видеть две модели.

142
00:10:22,660 --> 00:10:26,334
И также для сравнения приведены
R-квадраты в каждой модели.

143
00:10:26,334 --> 00:10:31,266
Вот видно, например, что при выкидывании
переменной Examination R-квадрат

144
00:10:31,266 --> 00:10:33,950
резко падает, практически в два раза.

145
00:10:33,950 --> 00:10:37,442
Также у нас есть
оценка σ с крышкой,

146
00:10:37,442 --> 00:10:41,140
да, 9.6 в первой модели, 11 — во второй.

147
00:10:41,140 --> 00:10:43,512
И количество наблюдений 47.

148
00:10:43,512 --> 00:10:48,680
Остальные показатели мы пока ещё не знаем,
но скоро с ними познакомимся.

