Этот фрагмент особо полезен тем,
кто знает линейную алгебру.
Оказывается, средствами линейной
алгебры легко не только сразу
посчитать дисперсию β1 с
крышкой или β2 с крышкой,
одним махом можно найти все эти
дисперсии и все ковариации.
Они все находятся в этой
ковариационной матрице.
Действительно, это матрица,
которая устроена следующим образом.
Здесь находится дисперсия β1 с
крышкой при фиксированном X,
дальше идет ковариация β1 с крышкой β2 с
крышкой при фиксированном X и так далее.
Здесь идёт ковариация — вторая срока,
первый столбец — β2 с крышкой с
β1 с крышкой при фиксированном X,
дальше идёт дисперсия β2 с крышкой
при фиксированном X и так далее.
И заканчивается это всё дисперсией
βk с крышкой при фиксированном X.
Оказывается, очень компактная
формула в терминах линейной алгебры
есть для этой матрицы.
βk с крышкой при фиксированном X.
И здесь точно такое же, ковариационная
матрица, она всегда симметричная.
β1 с крышкой βk с крышкой при
фиксированных регрессорах.
Ну чтобы понять,
как легко получить эту формулу,
нам сначала надо понять, какими свойствами
обладает ковариационная матрица.
Значит, во-первых,
свойства ковариационных матриц.
Во-первых, посмотрим, какие есть
свойства у математического ожидания.
Вот если у меня есть математическое
ожидание от вектора,
то это имеется в виду вектор
из математических ожиданий.
И у математического
ожидания свойства совершенно аналогичные,
у векторного математического ожидания
свойства совершенно аналогичные скалярным.
Ну то есть для одномерных случайных
величин, одномерные случайные величины,
было свойство: математическое
ожидание от a на у равняется
a (давайте y1 напишем) на
математическое ожидание y1.
В многомерном случае,
многомерные случайные величины,
здесь несколько дело обстоит посложнее,
поскольку a — это должна быть матрица,
и важен порядок умножения матриц.
Тут будет два свойства.
E(A) * y будет равняться A * E(y),
это нетрудно доказать,
но это достаточно интуитивно.
И второе свойство,
что если у меня y умножается на матрицу B,
B с другой стороны, то и выносить B
можно только направо из математического
ожидания: E(y) * B.
Соответственно, как можно
определить вот эту самую ковариационную
матрицу от вектора β с
крышкой при фиксированном X?
Это есть не что иное, как условное...
Это определение ковариационной матрицы,
его выражение через
математическое ожидание.
Это математическое ожидание вектора
β с крышкой на вектор β с крышкой
транспонированное при
фиксированном X минус
математическое ожидание от β
с крышкой при фиксированном
X на математическое ожидание β с крышкой
транспонированное при фиксированном X.
Эта формула является
обобщением одномерной формулы,
что дисперсия y1 при
фиксированном X — это
есть математическое
ожидание от y1-квадрат при
фиксированном X минус математическое
ожидание от y1 при фиксированном X,
взятое в квадрат.
Соответственно, вернёмся
к этому обобщению.
Что мы получаем?
Мы получаем такое важное свойство.
Если скомбинировать свойство
математического ожидания и определение,
то мы получим такое важное
свойство ковариационной матрицы.
Ковариационная матрица A на β с
крышкой при фиксированном X равняется:
математическое ожидание от
A на β с крышкой помножить
A на β с крышкой транспонированное
при фиксированном
X минус математическое
ожидание от A на β с крышкой
при фиксированном X на
математическое ожидание от A на β
с крышкой потом транспонированное
при фиксированном X.
При транспонировании меняется
порядок следования матриц,
меняется порядок,
в котором они умножаются.
И мы получаем, что это есть...
Дальше из этого математического
ожидания наружу вылезет A,
а вот здесь поменяется порядок.
И если налево будет вылезать A,
то вот из этого сомножителя направо
будет вылезать A транспонированное.
Здесь тоже A вылезет налево,
а вот здесь вот направо
вылезет A транспонированное.
И получится: A помножить
на E от β с крышкой на β с
крышкой транспонированное
при фиксированных X минус
E от β с крышкой при
фиксированных X на E от β с
крышкой транспонированное
при фиксированных X и еще
помножить на A транспонированное.
И получится у нас такое
замечательное свойство.
A вышла налево,
посерёдке осталась ковариационная
матрица вектора β с крышкой,
а справа появилась A транспонированная.
То есть аналогом формулы: дисперсия
a на y1 при фиксированном X — a-квадрат
на дисперсию y1 при фиксированном X,
— аналогом этой формулы
выступает следующая:
ковариационная матрица A на
вектор y при фиксированном X
равняется A на
ковариационную матрицу y при
фиксированном X
умножить на A транспонированную.
И этого свойства нам будет
совершенно достаточно,
чтобы посчитать вот эту
самую ковариационную матрицу
оценок коэффициентов β
с крышкой в общем виде.
Ну давайте попробуем.
Я напомню, что β с крышкой
равняется X'X в минус первой X'y.
И у нас есть предпосылка,
что ковариационная матрица вектора
ε при фиксированных X имеет вид
σ-квадрат умножить на единичную.
Ну и, конечно же,
у нас в матричном виде наша
модель записывается как y
равняется X на β плюс ε.
На первом шаге, шаг 1,
мы найдём ковариационную матрицу
вектора y при фиксированных X.
Это есть ковариационная матрица вектора
X на β плюс ε при фиксированных X.
Но если X фиксированы,
то вот это — это просто константа.
Константы не влияют ни на дисперсии,
ни на ковариации, которые «живут» в этой
матрице, поэтому их
можно просто не писать.
Это есть ковариационная матрица вектора
ε при фиксированных X, и это есть,
по предположению,
σ-квадрат умножить на единичную матрицу.
И остался шаг 2.
Ковариационная матрица вектора
β с крышкой при фиксированных
X равняется:
ковариационная матрица
вектора X'X в минус первой
X'y при фиксированных X.
Это какая-то одна здоровая
матрица констант.
Поскольку у нас регрессоры, иксы,
считаются константами, мы выносим ее —
налево, и направо — транспонированную.
Получаем X'X в минус первой X' умножить на
ковариационную матрицу вектора y
при фиксированных X умножить на
X'X в минус первой X' транспонированная.
Равняется, это так и остаётся,
X'X в минус первой X', это получается
σ-квадрат умножить на единичную матрицу.
А здесь надо транспонировать.
При транспонировании меняется порядок,
и надо ещё раз транспонировать.
Значит, вот этот X — он станет первым,
а вот эта матрица встанет направо.
То есть вот эта и вот эта
матрица поменяются местам,
и надо будет ещё транспонировать.
Ну X транспонированный
транспонированное будет просто X.
А эта матрица — она симметричная.
Ну потому что, действительно,
X транспонированное X,
если ее транспонировать, будет...
Переставляем местами и
довешиваем транспонирование.
X транспонированное на X,
дважды транспонированное, это X'X.
То есть вот эта матрица симметричная,
её можно не транспонировать.
Получаем X'X в минус первой.
И замечаем, что единичную матрицу
можно при умножении не писать.
Константу можно вынести вперёд.
И получится: σ-квадрат умножить на X'X в
минус первой X' на X
на X'X в минус первой.
Вот эти матрицы обратные,
при умножении они взаимно уничтожатся,
и останется готовый приятный ответ:
σ-квадрат на X'X в минус первой.
Соответственно, мы пришли к выводу,
что ковариационная матрица вектора
β с крышкой при фиксированных X имеет вид
σ-квадрат помножить на X'X в минус первой.
В этой матрице находятся и дисперсии
условные каждого β с крышкой,
и ковариации каждого β с
крышкой с каждым β с крышкой.
И в скалярном виде мы их выводили долго
по отдельности и только для случая
парной регрессии, а в матричном виде
они выводятся легко, все и сразу,
и этой формулой можно будет пользоваться.

