При оценке линейной модели регрессии,
любой статистический пакет выдает
более-менее стандартную табличку.
Вот такую табличку выдает R.
Что она означает?
Первый столбик в ней это,
собственно, оценки коэффициентов.
То есть в данном случае мы можем сказать,
что оцениваемая модель имеет
вид: Fertility_i c крышечкой равняется,
первый коэффициент —
это свободный член 59.86
+ 0,109 умножить на
переменную доля мужского
сельскохозяйственного населения
(agriculture_i)
+ 0,115 умножить на долю
католического населения в провинции.
Это смысл первого столбика.
Второй столбик содержит стандартные
ошибки, соответственно.
Если у нас первый коэффициент
— это β₁ с крышкой,
второй коэффициент, давайте для удобства
его назовем, не β₂, а β_а с крышечкой.
И третий коэффициент, для удобства
назовем не 3, а β_с с крышечкой.
Соответственно, второй столбик
— это стандартные ошибки.
Стандартная ошибка β_а с
крышечкой равняется 0.075.
Скажем, стандартная ошибка β_с
с крышечкой равняется 0.043.
Эти стандартные ошибки,
я напомню, что они получаются,
как корни из диагональных
элементов ковариационная матрицы,
то есть компьютер оценивает
ковариационную матрицу.
Это матрица размера 3х3 и соответственно,
если извлечь корень из вот этого элемента,
то получится стандартная
ошибка β_а с крышечкой,
извлечь корень из этого элемента,
получится стандартная
ошибка β_с с крышечкой.
Третий столбец это компьютер
автоматом проверяет гипотезу о том,
что на самом деле,
зависимости от данной переменной нет.
То есть компьютер автоматом тестирует
гипотезу о том, что β_а = 0 против
H альтернативная о том, что β_а не равно 0.
Автоматом тестируется гипотеза о том,
что β_с = 0,
против альтернативной, что β_с не равно 0.
Соответственно, он это делает
с помощью t-статистики.
Как выглядит t-статистика
для j-го коэффициента?
Берется оценка j-го коэффициента, регрессия,
вычитается истинное значение и
делится на стандартную
ошибку β_j с крышкой.
Поскольку мы тестируем гипотезу о том,
что коэффициент равен 0.
Вот этот вот коэффициент = 0,
соответственно, статистика имеет простой
вид, β_j с крышечкой делить на
стандартную ошибку β_j с крышкой.
То есть третий столбик получается — это
просто первый столбец делить на второй.
Это значение t-статистики.
Например, t-статистика,
которая тестирует гипотезу о том,
что коэффициент при доле
мужского населения,
занятого в сельском хозяйстве равен 0,
это t-статистика = 1.396,
t-статистика для другого
коэффициента = 2.690.
И наконец, конечно можно просто сравнить
эти t-статистики с критическим,
t-критическое,
как правило находится в районе двойки,
в нашем случае для 47 наблюдений,
критическое значение, у нас
оценивается три коэффициента,
поэтому это t-распределение с 44 степенями
свободы и критическое равно 2.02.
И в принципе, для проверки гипотез можно
устно сравнить 2.02 с посчитанными
наблюдаемыми значениями статистик.
Получится, что первый коэффициент при доле
сельскохозяйственного населения не значим,
а коэффициент при доле
католического населения значим.
Однако, чтобы не помнить это самое
t-критическое,
чтобы его не считать для каждого случая,
компьютер автоматом считает четвертый
столбец, а это столбец с P-значениями.
То есть автоматом посчитано
P-значение для
тестирования гипотезы о том, что β_а = 0.
И это P-значение равно 0.1698
и автоматом считается
P-значение для гипотезы о том,
что коэффициент β_с = 0 и
это P-значение равно 0.001.
Я напомню на всякий случай картинку о том,
что есть t-критическое, t-критическое,
минус t-критическое, площадь слева
и справа от него по альфа пополам.
И есть t-наблюдаемое.
Вот допустим, такая картинка —
это минус t-наблюдаемое,
а тут плюс t-наблюдаемое.
И площадь слева и справа от него — это
P-value пополам, P-значение пополам.
Соответственно, что я вижу?
Какой простой критерий, как по
последнему столбику легко сравнить и
легко выяснить,
значим коэффициент или не значим.
Если P-значение больше, чем α,
как у меня на рисунке,
то тогда можно сделать вывод,
что t-наблюдаемое очень близко к нулю.
Это говорит о том,
что коэффициент не значим.
Если же оказывается, что P-value,
Р-значение меньше выбранного
уровня значимости, то это значит,
что наблюдаемая t-статистика
слишком большая и H0 отвергается.
Гипотеза H0 состоит в том,
что коэффициент равен нулю, истинный,
соответственно, в этом
случае β с крышкой значим.
В нашем случае мы видим,
что если выбрать, скажем,
уровень значимости 5%,
если выбрать уровень значимости 5%,
тогда мы получим,
что при таком уровне значимости,
глядя только на третий столбик,
мы можем легко определить, что, скажем,
коэффициент β с крышкой при доле
сельскохозяйственного населения не значим,
у него слишком большое 
P-value — больше порогового.
А наоборот, коэффициент при доле
католического населения, значим.
У него P-value меньше
порогового α, равного 5%, и,
соответственно, R отмечает это
звездочками рядом с P-значением,
то есть одна звездочка означает, что один
коэффициент значим при альфа равном 5%.
А соответственно, большее количество
звездочек означает, что коэффициент
значим даже при меньшей α, то есть при
меньшей вероятности ошибки первого рода.

