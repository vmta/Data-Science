1
00:00:13,270 --> 00:00:20,105
При оценке линейной модели регрессии,

2
00:00:20,105 --> 00:00:24,241
любой статистический пакет выдает
более-менее стандартную табличку.

3
00:00:24,241 --> 00:00:25,881
Вот такую табличку выдает R.

4
00:00:25,881 --> 00:00:26,940
Что она означает?

5
00:00:26,940 --> 00:00:30,486
Первый столбик в ней это,
собственно, оценки коэффициентов.

6
00:00:30,486 --> 00:00:35,129
То есть в данном случае мы можем сказать,
что оцениваемая модель имеет

7
00:00:35,129 --> 00:00:39,390
вид: Fertility_i c крышечкой равняется,

8
00:00:39,390 --> 00:00:45,096
первый коэффициент —
это свободный член 59.86

9
00:00:45,096 --> 00:00:50,910
+ 0,109 умножить на
переменную доля мужского

10
00:00:50,910 --> 00:00:58,126
сельскохозяйственного населения
(agriculture_i)

11
00:00:58,126 --> 00:01:05,802
+ 0,115 умножить на долю
католического населения в провинции.

12
00:01:05,802 --> 00:01:07,630
Это смысл первого столбика.

13
00:01:07,630 --> 00:01:13,760
Второй столбик содержит стандартные
ошибки, соответственно.

14
00:01:13,760 --> 00:01:20,075
Если у нас первый коэффициент
— это β₁ с крышкой,

15
00:01:20,075 --> 00:01:24,993
второй коэффициент, давайте для удобства
его назовем, не β₂, а β_а с крышечкой.

16
00:01:24,993 --> 00:01:31,120
И третий коэффициент, для удобства
назовем не 3, а β_с с крышечкой.

17
00:01:31,120 --> 00:01:35,809
Соответственно, второй столбик
— это стандартные ошибки.

18
00:01:35,809 --> 00:01:42,570
Стандартная ошибка β_а с
крышечкой равняется 0.075.

19
00:01:42,570 --> 00:01:50,610
Скажем, стандартная ошибка β_с
с крышечкой равняется 0.043.

20
00:01:50,610 --> 00:01:54,362
Эти стандартные ошибки,
я напомню, что они получаются,

21
00:01:54,362 --> 00:01:58,693
как корни из диагональных
элементов ковариационная матрицы,

22
00:01:58,693 --> 00:02:02,780
то есть компьютер оценивает
ковариационную матрицу.

23
00:02:02,780 --> 00:02:08,858
Это матрица размера 3х3 и соответственно,

24
00:02:08,858 --> 00:02:14,132
если извлечь корень из вот этого элемента,

25
00:02:14,132 --> 00:02:19,236
то получится стандартная
ошибка β_а с крышечкой,

26
00:02:19,236 --> 00:02:22,960
извлечь корень из этого элемента,

27
00:02:22,960 --> 00:02:27,790
получится стандартная
ошибка β_с с крышечкой.

28
00:02:27,790 --> 00:02:32,361
Третий столбец это компьютер
автоматом проверяет гипотезу о том,

29
00:02:32,361 --> 00:02:35,770
что на самом деле,
зависимости от данной переменной нет.

30
00:02:35,770 --> 00:02:40,970
То есть компьютер автоматом тестирует
гипотезу о том, что β_а = 0 против

31
00:02:40,970 --> 00:02:45,864
H альтернативная о том, что β_а не равно 0.

32
00:02:45,864 --> 00:02:50,320
Автоматом тестируется гипотеза о том,
что β_с = 0,

33
00:02:50,320 --> 00:02:52,877
против альтернативной, что β_с не равно 0.

34
00:02:52,877 --> 00:02:56,540
Соответственно, он это делает
с помощью t-статистики.

35
00:02:56,540 --> 00:03:00,170
Как выглядит t-статистика
для j-го коэффициента?

36
00:03:00,170 --> 00:03:04,828
Берется оценка j-го коэффициента, регрессия,
вычитается истинное значение и

37
00:03:04,828 --> 00:03:10,460
делится на стандартную
ошибку β_j с крышкой.

38
00:03:10,460 --> 00:03:16,820
Поскольку мы тестируем гипотезу о том,
что коэффициент равен 0.

39
00:03:16,820 --> 00:03:20,668
Вот этот вот коэффициент = 0,
соответственно, статистика имеет простой

40
00:03:20,668 --> 00:03:25,120
вид, β_j с крышечкой делить на
стандартную ошибку β_j с крышкой.

41
00:03:25,120 --> 00:03:33,185
То есть третий столбик получается — это
просто первый столбец делить на второй.

42
00:03:33,185 --> 00:03:35,460
Это значение t-статистики.

43
00:03:35,460 --> 00:03:39,660
Например, t-статистика,
которая тестирует гипотезу о том,

44
00:03:39,660 --> 00:03:42,088
что коэффициент при доле
мужского населения,

45
00:03:42,088 --> 00:03:47,525
занятого в сельском хозяйстве равен 0,
это t-статистика = 1.396,

46
00:03:47,525 --> 00:03:54,620
t-статистика для другого
коэффициента = 2.690.

47
00:03:54,620 --> 00:03:59,681
И наконец, конечно можно просто сравнить
эти t-статистики с критическим,

48
00:03:59,681 --> 00:04:04,208
t-критическое,
как правило находится в районе двойки,

49
00:04:04,208 --> 00:04:07,819
в нашем случае для 47 наблюдений,

50
00:04:07,819 --> 00:04:12,862
критическое значение, у нас
оценивается три коэффициента,

51
00:04:12,862 --> 00:04:17,735
поэтому это t-распределение с 44 степенями
свободы и критическое равно 2.02.

52
00:04:17,735 --> 00:04:22,724
И в принципе, для проверки гипотез можно
устно сравнить 2.02 с посчитанными

53
00:04:22,724 --> 00:04:25,591
наблюдаемыми значениями статистик.

54
00:04:25,591 --> 00:04:30,943
Получится, что первый коэффициент при доле
сельскохозяйственного населения не значим,

55
00:04:30,943 --> 00:04:33,450
а коэффициент при доле
католического населения значим.

56
00:04:33,450 --> 00:04:38,000
Однако, чтобы не помнить это самое
t-критическое,

57
00:04:38,000 --> 00:04:40,433
чтобы его не считать для каждого случая,

58
00:04:40,433 --> 00:04:45,310
компьютер автоматом считает четвертый
столбец, а это столбец с P-значениями.

59
00:04:45,310 --> 00:04:49,991
То есть автоматом посчитано
P-значение для

60
00:04:49,991 --> 00:04:55,222
тестирования гипотезы о том, что β_а = 0.

61
00:04:55,222 --> 00:04:59,120
И это P-значение равно 0.1698

62
00:04:59,120 --> 00:05:06,613
и автоматом считается
P-значение для гипотезы о том,

63
00:05:06,613 --> 00:05:12,990
что коэффициент β_с = 0 и
это P-значение равно 0.001.

64
00:05:12,990 --> 00:05:19,671
Я напомню на всякий случай картинку о том,

65
00:05:19,671 --> 00:05:26,166
что есть t-критическое, t-критическое,

66
00:05:26,166 --> 00:05:32,970
минус t-критическое, площадь слева
и справа от него по альфа пополам.

67
00:05:32,970 --> 00:05:34,920
И есть t-наблюдаемое.

68
00:05:34,920 --> 00:05:40,413
Вот допустим, такая картинка —

69
00:05:40,413 --> 00:05:45,622
это минус t-наблюдаемое,
а тут плюс t-наблюдаемое.

70
00:05:45,622 --> 00:05:51,838
И площадь слева и справа от него — это
P-value пополам, P-значение пополам.

71
00:05:51,838 --> 00:05:53,530
Соответственно, что я вижу?

72
00:05:53,530 --> 00:05:58,010
Какой простой критерий, как по
последнему столбику легко сравнить и

73
00:05:58,010 --> 00:06:02,980
легко выяснить,
значим коэффициент или не значим.

74
00:06:02,980 --> 00:06:07,655
Если P-значение больше, чем α,
как у меня на рисунке,

75
00:06:07,655 --> 00:06:11,730
то тогда можно сделать вывод,
что t-наблюдаемое очень близко к нулю.

76
00:06:11,730 --> 00:06:14,934
Это говорит о том,
что коэффициент не значим.

77
00:06:14,934 --> 00:06:17,941
Если же оказывается, что P-value,

78
00:06:17,941 --> 00:06:23,062
Р-значение меньше выбранного
уровня значимости, то это значит,

79
00:06:23,062 --> 00:06:27,559
что наблюдаемая t-статистика
слишком большая и H0 отвергается.

80
00:06:27,559 --> 00:06:32,300
Гипотеза H0 состоит в том,
что коэффициент равен нулю, истинный,

81
00:06:32,300 --> 00:06:38,670
соответственно, в этом
случае β с крышкой значим.

82
00:06:38,670 --> 00:06:43,665
В нашем случае мы видим,
что если выбрать, скажем,

83
00:06:43,665 --> 00:06:48,653
уровень значимости 5%,
если выбрать уровень значимости 5%,

84
00:06:48,653 --> 00:06:53,216
тогда мы получим,
что при таком уровне значимости,

85
00:06:53,216 --> 00:06:57,188
глядя только на третий столбик,
мы можем легко определить, что, скажем,

86
00:06:57,188 --> 00:07:01,784
коэффициент β с крышкой при доле
сельскохозяйственного населения не значим,

87
00:07:01,784 --> 00:07:04,980
у него слишком большое 
P-value — больше порогового.

88
00:07:04,980 --> 00:07:09,960
А наоборот, коэффициент при доле
католического населения, значим.

89
00:07:09,960 --> 00:07:14,622
У него P-value меньше
порогового α, равного 5%, и,

90
00:07:14,622 --> 00:07:20,085
соответственно, R отмечает это
звездочками рядом с P-значением,

91
00:07:20,085 --> 00:07:26,314
то есть одна звездочка означает, что один
коэффициент значим при альфа равном 5%.

92
00:07:26,314 --> 00:07:32,066
А соответственно, большее количество
звездочек означает, что коэффициент

93
00:07:32,066 --> 00:07:36,920
значим даже при меньшей α, то есть при
меньшей вероятности ошибки первого рода.

