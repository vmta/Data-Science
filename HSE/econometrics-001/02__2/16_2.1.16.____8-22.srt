1
00:00:13,060 --> 00:00:17,477
Хочется отметить следующие
особенности проверки

2
00:00:17,477 --> 00:00:20,870
гипотез об отдельных коэффициентах.

3
00:00:20,870 --> 00:00:24,035
Во-первых, это отвратительное название.

4
00:00:24,035 --> 00:00:28,582
Во всех работах всегда пишут: «мы
проверили 

5
00:00:28,582 --> 00:00:29,800
гипотезу о значимости коэффициента».

6
00:00:29,800 --> 00:00:31,635
На самом деле — это гнусная ложь.

7
00:00:31,635 --> 00:00:34,551
Проверяется гипотеза о
незначимости коэффициента.

8
00:00:34,551 --> 00:00:38,519
Просто есть такая устная традиция,
она и в русском языке, и в английском.

9
00:00:38,519 --> 00:00:41,347
Проверяется гипотеза о том,
что коэффициент равен нулю,

10
00:00:41,347 --> 00:00:43,510
то есть на самом деле о том,
что он не значим.

11
00:00:43,510 --> 00:00:49,323
Но очень часто пишут что: «мы проверили
гипотезу о значимости коэффициента», хотя,

12
00:00:49,323 --> 00:00:52,937
на самом деле, проверяется совершенно
противоположная нулевая гипотеза.

13
00:00:52,937 --> 00:00:58,109
То есть если H0 не отвергается,
это говорит о том, что зависимости нет.

14
00:00:58,109 --> 00:01:02,821
Вторая особенность,
которую нужно отметить — это почему мы

15
00:01:02,821 --> 00:01:07,150
говорим: «H0 не отвергается,
а не скажем H0 принимается»?

16
00:01:07,150 --> 00:01:11,819
Статистическое тестирование устроено так,

17
00:01:11,819 --> 00:01:16,837
что фраза «H0 не отвергается»
означает буквально следующее:

18
00:01:16,837 --> 00:01:23,960
«недостаточно данных чтобы отвергнуть H0,
данные не противоречат гипотезе H0».

19
00:01:23,960 --> 00:01:27,932
Это, в частности, означает, что данные
могут еще много чему не противоречить.

20
00:01:27,932 --> 00:01:31,540
Они могут, в частности, не противоречить
H0, их может быть просто мало.

21
00:01:31,540 --> 00:01:36,500
Может быть, не противоречить и
H-альтернативной, такое вполне бывает.

22
00:01:36,500 --> 00:01:42,143
Поэтому здесь надо говорить аккуратно:
«H0 не отвергается» — это означает,

23
00:01:42,143 --> 00:01:45,420
что данные не противоречат гипотезе H0.

24
00:01:45,420 --> 00:01:49,006
Следующая особенность,
которую также необходимо осознавать

25
00:01:49,006 --> 00:01:52,400
— это отличие значимости и
существенности коэффициента.

26
00:01:52,400 --> 00:01:57,881
Коэффициент может быть значим,
но совершенно неважным, несущественным.

27
00:01:57,881 --> 00:02:01,730
Например, если мы по большому
количеству наблюдений обнаружили,

28
00:02:01,730 --> 00:02:06,557
что зарплата мужчин и женщин
отличается в месяц на 3 рубля,

29
00:02:06,557 --> 00:02:11,072
то можно говорить о том,
что никакой дискриминации нет, и,

30
00:02:11,072 --> 00:02:15,360
хотя, отличие мы выявили,
оно значимое, гипотеза о том,

31
00:02:15,360 --> 00:02:20,638
что отличия нет, может отвергаться, но тем
не менее, это отличие несущественное.

32
00:02:20,638 --> 00:02:23,097
Да, отличие есть, но оно настолько мало.

33
00:02:23,097 --> 00:02:28,814
Мы его, конечно, обнаружили статистически,
но оно ни на какие практические выводы,

34
00:02:28,814 --> 00:02:32,600
ни на какую политику в сфере
труда влиять не будет.

35
00:02:32,600 --> 00:02:35,345
То есть не надо путать
значимость и существенность.

36
00:02:35,345 --> 00:02:39,261
Значимость — это математический,
некий статистический факт о том,

37
00:02:39,261 --> 00:02:41,630
равен коэффициент нулю или не равен.

38
00:02:41,630 --> 00:02:44,657
А существенность — это 
насколько он не равен нулю.

39
00:02:44,657 --> 00:02:48,086
Может быть он, конечно,
не равен нулю, но настолько мал,

40
00:02:48,086 --> 00:02:50,595
что и этим отличием от
нуля можно пренебречь.

41
00:02:50,595 --> 00:02:53,265
Здесь нужно отметить,
что на больших выборках,

42
00:02:53,265 --> 00:02:57,299
когда у вас много-много-много-много
наблюдений, то любое,

43
00:02:57,299 --> 00:03:01,751
даже самое малейшее отличие,
будет поймано регрессией.

44
00:03:01,751 --> 00:03:05,195
В частности, на большом количестве
наблюдений, как правило,

45
00:03:05,195 --> 00:03:09,920
все коэффициенты становятся значимы,
если очень-очень много наблюдений.

46
00:03:09,920 --> 00:03:12,344
И возможна обратная ситуация.

47
00:03:12,344 --> 00:03:15,063
Коэффициент может быть существенным,

48
00:03:15,063 --> 00:03:20,160
то есть по величине он может быть очень
сильным, скажем, так может выходить,

49
00:03:20,160 --> 00:03:25,525
что по нескольким наблюдениям у вас там,
всего мало наблюдений, там 20,

50
00:03:25,525 --> 00:03:30,410
скажем, и коэффициент может быть
большим по абсолютной величине,

51
00:03:30,410 --> 00:03:35,150
но при этом, из-за того, что данных мало,
то оценка обладает большой дисперсией,

52
00:03:35,150 --> 00:03:39,603
и гипотеза о том, что на самом деле
коэффициент равен нулю не отвергается,

53
00:03:39,603 --> 00:03:43,381
хотя оценка β_j с крышкой очень большая,
такое тоже бывает.

54
00:03:43,381 --> 00:03:47,125
То есть надо осознавать,
что значимость — это не то же самое,

55
00:03:47,125 --> 00:03:50,084
что существенность или
важность для нас коэффициента.

56
00:03:50,084 --> 00:03:54,172
Значимость — это факт о том равен он нулю,
точнее не факт, а это отвержение или 

57
00:03:54,172 --> 00:03:59,381
не отвержение гипотезы о том, что истинный
коэффициент равен нулю или не равен нулю.

58
00:03:59,381 --> 00:04:04,360
Чтобы как-то попытаться померить
существенность коэффициента,

59
00:04:04,360 --> 00:04:05,886
есть много способов.

60
00:04:05,886 --> 00:04:09,659
Они неоднозначны,
их довольно много, но, пожалуй,

61
00:04:09,659 --> 00:04:14,094
самый простой — это способ посчитать
стандартизированные коэффициенты.

62
00:04:14,094 --> 00:04:16,850
Что такое стандартизированные
коэффициенты?

63
00:04:16,850 --> 00:04:19,494
Это попытка перевести все регрессоры,

64
00:04:19,494 --> 00:04:24,314
все объясняющие переменные и объясняемую
переменную в общие единицы измерения.

65
00:04:24,314 --> 00:04:28,610
Вот иксы могут измеряться,
скажем, опыт работы измеряется в годах,

66
00:04:28,610 --> 00:04:30,510
заплата измеряется в рублях.

67
00:04:30,510 --> 00:04:34,336
Соответственно, можно попытаться
перевести все регрессоры,

68
00:04:34,336 --> 00:04:38,336
все объясняющие переменные в одни
универсальные единицы измерения.

69
00:04:38,336 --> 00:04:41,510
То есть мы возьмем,
из каждой переменой вычтем ее среднее

70
00:04:41,510 --> 00:04:46,040
и поделим на стандартную
ошибку этой самой переменной.

71
00:04:46,040 --> 00:04:48,816
Сделаем эту операцию для
объясняемой переменной и для

72
00:04:48,816 --> 00:04:50,570
каждой объясняющей переменной.

73
00:04:50,570 --> 00:04:54,900
И после этого мы оценим ту же
самую модель, что и хотели,

74
00:04:54,900 --> 00:04:58,340
но в этих стандартизированных переменных.

75
00:04:58,340 --> 00:05:00,854
Мы получим, естественно,
другие оценки коэффициентов.

76
00:05:00,854 --> 00:05:03,782
Эти оценки коэффициентов
называются стандартизированными.

77
00:05:03,782 --> 00:05:08,796
И, соответственно, помимо того,
что их можно будет сравнивать между собой,

78
00:05:08,796 --> 00:05:14,964
помимо этого у нас еще получится некая
мера существенности коэффициента.

79
00:05:14,964 --> 00:05:19,130
И следующая небольшая особенность —
это проблема множественных сравнений.

80
00:05:19,130 --> 00:05:24,381
Если исследователь хочет проверить
гипотезу о том, что какой-то коэффициент

81
00:05:24,381 --> 00:05:29,400
β_{42} конкретно равен нулю,
то способ с t-статистикой подходит.

82
00:05:29,400 --> 00:05:35,365
Но, к сожалению, очень часто
распространена такая порочная практика,

83
00:05:35,365 --> 00:05:40,729
что исследователь берет, включает кучу,
не задумываясь о теоретической модели,

84
00:05:40,729 --> 00:05:45,979
включает кучу объясняющих переменных
в свою модель и выбирает те из них,

85
00:05:45,979 --> 00:05:51,070
которые по t-статистикам
оказались значимы.

86
00:05:51,070 --> 00:05:55,555
Это подход неправильный, поскольку как

87
00:05:55,555 --> 00:06:00,725
только мы согласились на некую вероятность
ошибки первого рода, например,

88
00:06:00,725 --> 00:06:05,809
мы выбрали вероятность ошибки первого рода
типичную в экономических приложениях 5%.

89
00:06:05,809 --> 00:06:14,150
Соответственно, если мы возьмем просто
100 никак не связанных с y регрессоров,

90
00:06:14,150 --> 00:06:18,230
то есть все коэффициенты β
по настоящему равны нулю,

91
00:06:18,230 --> 00:06:22,082
то в каждом случае вероятность обнаружить

92
00:06:22,082 --> 00:06:27,010
ложно якобы имеющуюся зависимость, будет
равна ошибке первого рода, то есть 5%.

93
00:06:27,010 --> 00:06:29,983
То есть мы с вероятностью 5% увидим,

94
00:06:29,983 --> 00:06:33,959
что первый коэффициент значим,
с вероятностью 5% увидим,

95
00:06:33,959 --> 00:06:38,020
что второй коэффициент значим, хотя,
на самом деле, все истинные β равны нулю.

96
00:06:38,020 --> 00:06:43,200
И получается,
что из 100 регрессоров, в среднем,

97
00:06:43,200 --> 00:06:49,160
100 умножаем на 5%, в среднем 5
коэффициентов должны быть значимы.

98
00:06:49,160 --> 00:06:51,788
Хотя, на самом деле никакой связи нет.

99
00:06:51,788 --> 00:06:56,313
Это надо иметь в виду и понимать,
что политика: «я запустил регрессию на

100
00:06:56,313 --> 00:07:01,303
кучу переменных и отобрал те, которые
значимы» — это неправильный подход.

101
00:07:01,303 --> 00:07:05,052
Помимо поверки гипотезы
об отдельно взятом β,

102
00:07:05,052 --> 00:07:10,295
не трудно модифицировать нашу статистику,

103
00:07:10,295 --> 00:07:15,216
наш подход, чтобы проверять гипотезы
о некой линейной комбинации или о

104
00:07:15,216 --> 00:07:18,780
некоторой формуле,
связывающей несколько коэффициентов.

105
00:07:18,780 --> 00:07:21,499
Например, я могу желать
проверить гипотезу о том,

106
00:07:21,499 --> 00:07:24,075
что эффект воздействия двух
переменных одинаковый.

107
00:07:24,075 --> 00:07:25,480
То есть о том, что β₂ = β_3.

108
00:07:25,480 --> 00:07:30,155
В этом случае я использую
несколько модифицированную

109
00:07:30,155 --> 00:07:34,909
t-статистику, она, соответственно,
равна β₂ с крышкой минус β_3 с крышкой –

110
00:07:34,909 --> 00:07:39,118
(β₂ – β_3) делить стандартную ошибку
(β₂ с крышкой – β_3 с крышкой).

111
00:07:39,118 --> 00:07:44,055
К счастью, выводы полостью аналогичны, то
есть при большом количестве наблюдений эта

112
00:07:44,055 --> 00:07:47,961
статистика будет распределена
стандартно-нормально, при малом количестве

113
00:07:47,961 --> 00:07:51,266
наблюдений и дополнительном
предположении о нормальности ε,

114
00:07:51,266 --> 00:07:56,000
эта статистика будет иметь t-распределение
с (n – k) степенями свободы.

115
00:07:56,000 --> 00:08:02,058
И помимо обобщения t-статистики,
есть еще один способ.

116
00:08:02,058 --> 00:08:09,107
Можно переформулировать всегда модель так,
чтобы (β₂ – β_3) стало новым коэффициентом.

117
00:08:09,107 --> 00:08:15,217
И сейчас мы рассмотрим пример, как можно
проверить чуть более сложную гипотезу,

118
00:08:15,217 --> 00:08:18,350
чем гипотеза об отдельно
взятом коэффициенте.

