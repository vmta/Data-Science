1
00:00:13,330 --> 00:00:19,668
Аналогично можно разобрать
случай ридж-регрессии.

2
00:00:19,668 --> 00:00:21,853
Мы не будем на нем
подробно останавливаться,

3
00:00:21,853 --> 00:00:26,182
поскольку единственное отличие с
точки зрения языка программирования R

4
00:00:26,182 --> 00:00:29,500
состоит в том, что мы используем α = 0.

5
00:00:29,500 --> 00:00:35,118
То есть если я хочу оценить
ридж-регрессию с теми же lambdas,

6
00:00:35,118 --> 00:00:43,850
то я тут должен написать модель
ридж-регрессии и здесь указать α = 0.

7
00:00:43,850 --> 00:00:49,480
В остальном, оценивание и графики можно
построить совершенно аналогичные.

8
00:00:49,480 --> 00:00:51,893
Возникает естественный вопрос.Ну,

9
00:00:51,893 --> 00:00:55,480
а как же выбрать этот самый
штрафной коэффициент lambda?

10
00:00:55,480 --> 00:00:58,355
Первое желание.

11
00:00:58,355 --> 00:01:03,026
А давайте выберем штрафной
коэффициент lambda так, чтобы

12
00:01:03,026 --> 00:01:07,642
величина суммарная RSS плюс штраф была
поменьше, к сожалению, не срабатывает.

13
00:01:07,642 --> 00:01:12,309
Потому что в этом случае надо взять lambda
= 0 и мы таким образом получим случай

14
00:01:12,309 --> 00:01:13,655
обычной регрессии.

15
00:01:13,655 --> 00:01:17,830
Здесь используется так называемый
метод кросс-валидации.

16
00:01:17,830 --> 00:01:20,976
Я не буду на нем подробно останавливаться.

17
00:01:20,976 --> 00:01:23,927
Кратко лишь скажу, что строятся,

18
00:01:23,927 --> 00:01:29,511
наши данные разбиваются на
десять случайных групп.

19
00:01:29,511 --> 00:01:35,570
Соответственно, по девяти группам мы
оцениваем модель и предсказываем,

20
00:01:35,570 --> 00:01:40,625
находим сумму квадратов ошибок для
десятой группы и соответственно,

21
00:01:40,625 --> 00:01:45,759
посчитав десять вариантов суммы квадратов
ошибок, мы выбираем то lambda, при

22
00:01:45,759 --> 00:01:51,350
котором сумма квадратов ошибок каждый раз
выкидывая одну группу, будет наименьшей.

23
00:01:51,350 --> 00:01:58,140
Соответственно, покажем как реализовать
этот метод на примере регрессии lasso

24
00:02:02,405 --> 00:02:07,710
Это один из способов
выбрать оптимальное lambda.

25
00:02:07,710 --> 00:02:13,045
Соответственно, делаем кросс-валидацию

26
00:02:13,045 --> 00:02:18,527
для алгоритма LASSO, значит,

27
00:02:18,527 --> 00:02:25,540
у нас регрессоры будут в x0,
зависимая переменная в y и α,

28
00:02:25,540 --> 00:02:30,110
alpha = 1.

29
00:02:30,110 --> 00:02:38,387
Соответственно, компьютер подобрал
оптимальное lambda, можно посмотреть.

30
00:02:38,387 --> 00:02:43,009
Например, давайте построим
график для нашей ситуации.

31
00:02:43,009 --> 00:02:47,007
Соответственно, что сделал компьютер?

32
00:02:47,007 --> 00:02:53,988
Компьютер перебрал разные
варианты lambdas и обнаружил,

33
00:02:53,988 --> 00:02:57,498
при каком lambda сумма квадратов остатков,

34
00:02:57,498 --> 00:03:02,102
посчитанная путем кросс-валидации
будет наименьшей.

35
00:03:02,102 --> 00:03:07,974
И вторая оценка это там,
где резко увеличив величину штрафа,

36
00:03:07,974 --> 00:03:13,240
мы не сильно проиграем в
сумме квадратов ошибок.

37
00:03:13,240 --> 00:03:19,290
Соответственно есть две ошибки,
две идеи оценивать lambda с крышкой.

38
00:03:19,290 --> 00:03:21,684
Одна – по минимуму суммы квадратов ошибок.

39
00:03:21,684 --> 00:03:25,415
Другая – с некоторой подстраховкой,

40
00:03:25,415 --> 00:03:30,450
которая предпочитает модель с
коэффициентами более близкими к нулю.

41
00:03:30,450 --> 00:03:34,140
Ну, соответственно,
можно посмотреть на оба варианта.

42
00:03:34,140 --> 00:03:38,062
Соответственно, можно вытащить из нашей,

43
00:03:38,062 --> 00:03:44,903
алгоритма можно вытащить lambda
минимизирующая сумма квадратов ошибок.

44
00:03:44,903 --> 00:03:50,163
То есть вот это один из способов
выбрать оптимальное lambda и второй

45
00:03:50,163 --> 00:03:56,425
способ выбрать оптимальное lambda,
он выбирает большее lambda и

46
00:03:56,425 --> 00:04:01,869
при нем коэффициенты соответственно
ближе к нулю оказываются

47
00:04:01,869 --> 00:04:06,627
и можно выбрать для каждого из lambdas,
можно посмотреть, чему равны коэффициенты.

48
00:04:06,627 --> 00:04:11,584
Соответственно, в первом случае можно
посмотреть коэффициенты из модели,

49
00:04:11,584 --> 00:04:18,170
a s указывается, как lambda.1se, например.

50
00:04:18,170 --> 00:04:23,597
Соответственно, это коэффициенты
в модели для случая

51
00:04:23,597 --> 00:04:28,140
lambda равны 7,48.

52
00:04:28,140 --> 00:04:33,000
В этом видеофрагменте мы показали,

53
00:04:33,000 --> 00:04:39,843
как находить оценки ридж и лассо-регрессии
и как с помощью метода кросс-валидации,

54
00:04:39,843 --> 00:04:44,246
не вдаваясь в его детали, получать
некоторое оптимальное lambda и оценки,

55
00:04:44,246 --> 00:04:47,380
которые соответствуют этому
самому оптимальному lambda.

