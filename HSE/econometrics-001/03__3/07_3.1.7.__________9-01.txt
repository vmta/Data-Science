Самым простым примером проверки гипотезы
о нескольких ограничениях является
гипотеза следующего вида.
Иногда смотришь на регрессию и думаешь, ну
вот а вдруг все те объясняющие переменные,
которые я использую,
вдруг они все совершенно бесполезные,
вдруг ни одна из них не помогает
объяснить зависимую переменную y.
Соответственно, эта гипотеза математически
сводится к тому, что коэффициент β₂,
коэффициент при x, равен нулю, 
коэффициент β_3, коэффициент при z, равен нулю.
Если ещё есть объясняющие переменные,
то, соответственно,
все остальные β_4, β_5, β_6,...,
β_k равны нулю.
То есть всего у нас имеется
(k – 1) ограничение.
Мы предполагаем, что у y может быть
какое-то своё математическое ожидание,
поэтому y_i будет иметь вид β₁ + ε_i.
Но вот от объясняющих переменных, от x,
z и так далее зависимости нет,
то есть (k – 1) ограничение.
В этом случае можно получить
более простую формулу,
нежели RSS_R минус RSS_UR, делённое на
соответствующее RSS_UR и подправленное
на соответствующие константы.
И сейчас мы выведем эту более простую
формулу, которая относится к данному
распространённому случаю проверки гипотезы
о незначимости всей регрессии в целом.
Как это выглядит формально?
У нас есть модель 
y_i = β₁ + β₂x_i + β_3 z_i + ε_i.
Я буду разбирать ситуацию множественной
регрессии на примере двух регрессоров.
Я хочу проверить гипотезу о том,
что те две объясняющие переменные x и z,
которые я включил в модель,
— это абсолютно полная ерунда,
их не стоило включать,
и мой y вообще ни от чего не зависит.
То есть гипотеза формулируется о том,
что β₂ = 0, β_3 = 0 и так далее,
β_k = 0, если у меня здесь
будет всего k коэффициентов β.
То есть зависимости нет ни от этого
объясняющего регрессора, ни от z,
ни от остальных потенциальных.
А альтернативная — хотя бы один из
коэффициентов β₂,...,
β_k не равен нулю.
Такая нулевая гипотеза
и такая альтернативная.
В соответствии с нашим подходом
тестирования, нам надо оценить две модели.
Первая модель, неограниченная,
в которой мы не предполагаем,
что β₂ и β_3 равны нулю, то есть исходная.
Это у нас будет неограниченная модель.
И вторая модель ограниченная.
В ограниченной модели мы предполагаем,
что β₂ равно и β_3 равно нулю,
поэтому мы оценим модель y_i = β₁ + ε_i.
И, формально,
чтобы проверить эту гипотезу,
надо воспользоваться F-статистикой,
которая равна RSS_R, то есть RSS
из такой простой-простой модели,
где нет вообще объясняющих переменных,
минус RSS_UR,
то есть RSS из исходной модели,
делить на количество ограничений.
Ну сколько у нас ограничений?
Если у меня k коэффициентов,
то регрессоров будет (k – 1),
— вот это свободный член,
при нём нет регрессоров.
Соответственно, ограничений у меня здесь
— первого нет, а всего тут было бы k,
значит, (k – 1).
Здесь вот (k – 1) ограничение.
Соответственно, делить здесь надо на 
(k – 1) и делить на RSS_UR.
А в неограниченной модели
у меня тут k коэффициентов
оценивается, поэтому (n – k),
давайте я уточню,
unrestricted, потому что здесь
коэффициент в restricted всего один.
То есть нашу статистику, вообще говоря,
для оценки надо… для расчёта
статистики надо оценивать обе модели.
Однако оказывается, что при такой
простой гипотезе можно обойтись
оценкой только одной вот этой вот модели,
а вторую вообще не оценивать.
И вызвано это явление следующими фактами.
Мы знаем, что RSS_R больше,
чем RSS_UR,
ну потому что одно — это
ограниченный минимум,
а второе — это неограниченный минимум.
И неограниченный минимум,
если я ищу минимум на плоскости,
у меня получится меньше, чем если я ищу
минимум только на одной прямой плоскости.
Мы также знаем,
что TSS restricted равен TSS unrestricted.
Это связано с тем,
что TSS — это есть просто
сумма y_i минус y среднее в квадрате,
и она не зависит от того,
каким конкретно способом я моделирую y.
Общая сумма квадратов зависит только от
столбика y, и она не зависит от того,
какая правая часть у меня
используется для объяснения y.
Поэтому TSS у них одинаковые.
Ну и стало быть,
руководствуясь этим простым принципом...
значит, здесь у нас restricted,
и эта же величина — это TSS unrestricted.
И можно просто писать TSS,
потому что он одинаковый в обеих моделях.
Но эта модель очень простая.
И мы уже говорили о том,
что если оценить эту модель,
то окажется,
что β₁ с крышкой просто равно y среднему.
И в этой модели окажется,
что прогноз по такой простой
модели ŷ — это будет 
β₁ с крышкой, это будет y среднее.
А стало быть RSS в ограниченной модели,
в restricted модели — это сумма (y_i- y_i с крышкой)
в квадрате, сумма квадратов,
— это сумма (y_i- y среднее) в квадрате,
и это выходит ни что иное,
как TSS в ограниченной или
в неограниченной модели.
Давайте, я отмечу — в неограниченной.
Соответственно, я могу упростить
формулу для данной конкретной гипотезы,
что регресссия — это полная ерунда,
то есть β₂ = 0, β_3 = 0, β_k = 0.
Я могу упростить до
следующего выражения: TSSUR,
поскольку оно равно RSS_R, минус RSS_UR,
делить на RSS_UR.
Ну и здесь (k – 1),
а здесь (n – k_UR).
И поскольку разница (TSS – RSS) — это ESS,
мы получаем следующий простой
результат: ESS_UR делить
на (k – 1) на RSS_UR делить на (n – k).
И в этой формуле видно,
что при проверке гипотезы H_0,
достаточно оценивать
только исходную модель.
Поэтому, собственно,
даже unrestricted можно не писать.
Когда я оцениваю одну модель,
мне индекс нижний не нужен,
и поэтому у нас получилась
формула для проверки гипотезы H_0,
где достаточно оценить только одну модель.
На самом деле она unrestricted,
но поскольку мы оцениваем одну модель,
то мы можем это не уточнять.
И мы получили следующую формулу,
что для проверки H_0 нам надо
взять ESS поделить на (k – 1),
поделить на RSS на (n – k).
И у нас получится статистика F, которая
имеет при верной H_0 распределение с
(k – 1) и (n – k) степенями
свободы при верной H_0.
И этот способ позволяет нам проверить
гипотезу о том, что регрессия незначима.
Хотя опять же на сленге часто говорят
«мы проверили гипотезу о значимости
регрессии».
Когда говорят такие слова, имеют в
виду на самом деле проверку гипотезы о
незначимости регрессии,
о том, что β₂, β_3,...,
β_k все равны нулю.

