Рассмотрим такой маленький вопрос,
а что было бы,
если бы мы неправильно
включили дамми-переменные,
то есть мы бы использовали сразу две,
например, дамми-переменные: одну,
которая бы обозначала, что дом кирпичный,
единичка, и нолик, что дом некирпичный,
а вторую, наоборот, что единичка — дом
не кирпичный, а нолик — дом кирпичный.
Давайте мы создадим искусственно
эту лишнюю дамми-переменную.
В наборе данных f в переменной nonbrick мы
применим функцию recode из пакета memisc.
Если название у функции часто
используется, например,
recode — это такое очень
часто используемое слово,
то поэтому иногда дополнительно надо
указывать, в каком пакете «живёт» функция.
Если функция имеет уникальное имя,
то в этом необходимости нет,
но если в нескольких пакетах содержится
функция с одним и тем же именем,
то тогда надо указывать,
в каком пакете она «живёт».
Наша функция «живёт» в пакете memisc,
два двоеточия, и тут мы указываем recode.
Переменную из набора данных f,
которая называется brick,
мы меняем по принципу:
единичка переходит в нолик,
а нолик переходит в единичку.
Соответственно, теперь если мы
посмотрим на наш набор данных f,
то у нас есть переменная brick,
которая принимает значение 1 и 0,
и переменная nonbrick,
которая принимает значение 0 и 1,
ну совершенно противоположно
с переменной brick.
Что произойдет, если я в модель включу две
эти переменные, что, конечно же, ошибка?
Но, тем не менее, давайте попробуем:
model_wrong равняется линейная модель,
данные беру из набора данных f,
логарифм цены квартиры зависит
от логарифма общей площади,
от переменной brick и
от переменной nonbrick.
Вот модель, смотрим, что произошло.
Смотрите, R даже никак не ругнулся,
как будто ничего не произошло.
Но на самом деле,
если посмотреть описание модели,
summary(model_wrong), то мы увидим,
что на самом деле,
во-первых, естественно, оценить и тот
и тот коэффициент он не смог, потому что у
нас появляется неоднозначность в оценке
коэффициентов, он просто один выкинул.
И, соответственно,
здесь вот фигурирует предупреждение о том,
что одна из оценок коэффициентов
не определена по причине,
что в этом случае тогда
матрица X'X необратима.
Ну то есть что у нас происходит?
R автоматом выкидывает лишние данные
переменной, если вы их по ошибке введёте.
Хорошо.
Следующий сюжет простой, что вместо
сложной проверки гипотез, сравнения
нескольких моделей люди всегда хотели
вот придумать какой-то простой критерий.
Конечно же, надо чётко осознавать, что
использование какого-то одного простого
показателя, это сильное упрощение теории,
но, тем не менее,
в качестве грубого ориентира можно
ориентироваться на простые показатели,
например, на штрафные критерии Акаике
(AIC) и на штрафной критерий BIC.
Соответственно, давайте ещё
раз посмотрим на табличку,
которую мы уже строили:
mtable и посмотрим тут наши
модели model_0, model_1 и model_2.
Соответственно, вот вместо сравнения
этих моделей с помощью f-статистики,
можно просто грубо,
и в данном случае этот критерий сработает,
можно грубо посмотреть вот
на штрафной критерий AIC.
Ещё раз, это штраф: чем штраф меньше,
тем лучше, то есть большой положительный
штраф — это означает плохую модель.
Еще раз, AIC — туда в формулу входит
штраф за большое значение RSS,
за большую непохожесть, за сильную
непохожесть y на прогнозный ŷ,
и сюда же в этот штраф входит штраф за
большое количество коэффициентов в модели.
И, соответственно, по критерию Акаике,
по критерию AIC, видно,
что наименьшее значение,
самое отрицательное, у критерия AIC
достигается для третьей модели, ну,
для модели два, model2 — она третья
по счёту, но вторая по номеру.
И, соответственно,
по этому критерию третья модель лучше.
Заметьте, что разница между нулевой
и первой, — она существенная,
да, от 840 до 1036, в процентах если
мерить, а здесь уже не такая существенная.
То есть по критерию Акаике
модель один и модель два похожи,
но они сильно лучше модели ноль.
И то же самое можно сказать про
скорректированный R²,
вот она строчка R² adjusted.
Тоже простой критерий, который в отличие
от R², он обладает
тем свойством, что он всегда растёт,
когда мы добавляем переменные в модель,
то есть вот R²всегда растёт:
чем больше коэффициентов оценивается,
тем больше R², — а вот
R² adjusted, это тут так вышло,
что он тоже растёт,
но на самом деле он мог бы и упасть.
То есть если б мы включили совершенно
какие-то «левые» бессмысленные переменные,
то R²adjusted
бы скорее всего упал.
И здесь мы видим, что по этому
критерию тоже первая и вторая модели
примерно похожи и существенно лучше,
чем нулевая.
И ещё один, последний,
маленький сюжет — это проверка
гипотезы о пропущенных переменных.
То есть, а вдруг мы оценили модель,
а на самом деле надо было ещё,
не хватает кучи переменных,
то есть тест Рамсея.
Давайте проведём тест
Рамсея для модели два.
Ну, к счастью,
в R он уже реализован одной командой,
то есть считать нам руками ничего не надо.
Мы просто пишем resettest.
Ещё раз, я вот, например, не помню,
как оно называется: resettest с точкой или
без: я набрал reset,
нажал Tab и посмотрел, выбрал функцию.
Просто пакеты пишут разные авторы,
и зачастую трудно угадать,
напишет автор название функции resettest
слитно или resettest с точкой,
или resettest с подчёркиванием.
И мы применяем тест к модели
два и смотрим на результат.
Соответственно, что произошло за кадром?
За кадром эта функция построила
вспомогательную регрессию,
куда были включены прогнозы из модели
два в квадрате, кубы прогнозов,
тут вот написано,
степени свободы равны двум — это означает,
что было включено две
вспомогательных переменных:
ŷ в квадрате и ŷ в кубе, 
две последовательные степени.
И мы видим, что p-value = 0.01,
ну то есть это означает,
что уже всё не так плохо в этой модели.
Хотя на 5 % уровне
значимости гипотеза о том,
что нет пропущенных факторов,
будет отвергнута,
но уже на 1 % уровне
значимости мы можем не
отвергнуть гипотезу о том,
что нет пропущенных переменных.
Соответственно, вот модель
два уже не такая плохая,
но в принципе с ней ещё можно
работать и включать кучу переменных,
которые здесь не упомянуты:
там про расстояние до метро и
так далее.

