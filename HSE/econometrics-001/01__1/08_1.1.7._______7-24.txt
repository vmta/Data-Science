
﻿1
00:00:13,250 --> 00:00:17,917
Как правило,
в моделях в исходных данных у нас
имеется много наблюдений,
n может равняться 100 или 1 000.
Сейчас мы покажем картинку
для линейной модели
регрессии в n-мерном пространстве, то есть
в 100-мерном или 1000-мерном пространстве.
Для того чтобы рисовать в
100-мерном пространстве,
вам потребуется клетчатый шарф,
как у настоящего художника.
Итак, у нас есть исходные данные y_i y_1
и так далее, y_100.
Это вектор,
мы его обозначаем просто буковкой y.
Еще давайте рассмотрим
вектор из одних единичек.
Один, один, один.
Нарисуем эти два вектора.
Тут главное — смелые первые мазки.
На вопрос,
почему именно так мы нарисовали вектор
y 100-мерный и вектор из 1,
можно ответить: «Я так вижу».
Дело в том, что у нас слишком много
свободы в 100-мерном пространстве,
чтобы рисовать векторы, можно посмотреть
на него под разными углами, и векторы,
которые под одним углом перпендикулярны,
могут иметь произвольный
угол под другим углом.
Давайте проиллюстрируем модель, с помощью
этого простого рисунка проиллюстрируем
простую модель y_і = β + ε_i Я напомню,
что мы установили,
что в этой модели бета с крышкой по методу
наименьших квадратов равняется y среднему.
Соответственно, отдельно взятый прогноз
для i наблюдения — это есть просто
игрек среднее.
И если я рассмотрю вектор прогноза для
всех наблюдений, то это y_i с крышкой 1,
y_2 с крышкой и так далее,
игрек n-ное с крышкой, но поскольку
все они одинаковые в такой простой модели,
где нет объясняющей переменной фактически,
то поэтому в этой модели все
эти числа равны y среднему.
y среднее можно вынести за скобки вектора,
и получить, что это y среднее
помножить на вектор из 1.
И это у нас — вектор прогнозов.
Соответственно, вектор прогнозов
пропорционален единичному вектору в
этой модели, то есть?
мы растягиваем вектор
из 1 в y среднее раз,
получаем вектор y среднее
* на вектор из 1.
Давайте заметим,
что ε_i с крышкой равняется y_i-
y_i с крышкой — это ошибка прогноза.
Поэтому y_i = y_i с крышкой + ε_i с крышкой,
прогноз + ошибка.
И если записывать в векторной форме,
то это означает,
что вектор y равен вектору,
по компонентам если складывать вектора,
y с крышкой плюс вектор ε с крышкой,
то получится вектор y.
Это означает на картинке,
это равенство означает,
что если я соединю кончик
вектора y с крышкой до y,
то вот этот вектор — это
будет вектор ε с крышкой.
Действительно, можно пройти вектор y,
а можно пройти вектор y с крышкой,
а потом прибавить к нему ε с крышкой.
Но это еще не всё.
Давайте заметим,
что у нас есть условия первого порядка,
мы находили,
у нас y_i с крышкой равняется y среднее,
ну, то есть, говоря по-другому, мы знаем,
что сумма y_i с крышкой
равняется сумма y среднее,
равняется n умножить на y среднее,
равняется сумма y_i.
То есть, получается, что сумма y_i
с крышкой = сумма y_i среднее, и,
вычитая одно из другого,
получаем, что сумма y_i-
y_i с крышкой = 0, то есть
сумма ε_i с крышкой на 1 равняется 0,
а это условие мы можем
трактовать геометрически.
Вот это условие означает, что вектор
ε с крышкой перпендикулярен
вектору из одних единичек.
Соответственно, мы получили
замечательный результат.
Результат следующий — интерпретация
вот этой простой модели.
Если мне надо с помощью метода наименьших
квадратов оценить модель y_i = β + ε_i,
то для того чтобы найти β с крышкой,
оказывается, это можно сделать
геометрически в n-мерном пространстве,
где n — это количество наблюдений.
А именно, я беру вектор y,
нахожу его проекцию на прямую,
которая задается вектором из одних 1,
и результат проецирования —
это будет вектор y с крышкой.
Еще раз.
Есть у меня вектор y,
есть у меня вектор из одних 1,
я продолжаю этот вектор
до прямой и оказывается,
что в простой модели без регрессоров
спроецировав вектор y на эту прямую,
я получу вектор y с крышкой.
Соответственно, мы получили попутно еще
один факт: если любой вектор
проецировать на вектор из 1,
то получится вектор средних значений.
y среднее и так далее, y среднее.
Ну, например, если у меня есть три вектора
в 100-мерном пространстве — вектор y,
вектор из 1 и вектор х,
если я спроецирую вектор y на вектор из 1,
я получу вот здесь вот вектор y среднее,
y среднее, y среднее, а если я спроецирую
вектор x на тот же самый вектор из 1,
то я, соответственно, получу,
руководствуясь соображениями, что вектор
x ничем не отличается от вектора y,
я получу вектор из x среднее,
x среднее, x среднее и так далее,
x среднее.

