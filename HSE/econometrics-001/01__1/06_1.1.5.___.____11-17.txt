
﻿1
00:00:13,270 --> 00:00:18,740
Применив метод наименьших квадратов
к двум простым моделям, мы
получили следующие результаты: в модели,
где нет фактически объясняющих переменных,
где y_i = β + ε_i в такой модели мы
получили оценку метода наименьших
квадратов — β с крышкой равно просто y
среднему, среднему арифметическому всех y.
В линейной модели, где y_i = β₁ + β₂x_i +
ε_i мы получили более сложные формулы.
Формулу для β₂ с крышкой,
она немножко громоздкая,
ее трудно напрямую проинтерпретировать,
что это отношение ∑(x_i-
x среднее) * (y_i-
y среднее) деленное на ∑(x_i-
x среднее) в квадрате.
И в этой же модели β₁
с крышкой = y среднее-
β₂ с крышкой * x среднее.
То есть второе уравнение означает,
что линия регрессии y с крышкой
= β₁ с крышкой + β₂ с крышкой * х проходит
через точку (х среднее, у среднее).
Еще раз подведем итог всей
используемой терминологии:
y_i — зависимая или объясняемая
переменная (синонимы).
x_i — регрессор или объясняющая переменная.
ε_i — просто ошибка или ошибка модели,
или случайная составляющая,
или случайная ошибка.
То есть та величина, которая для нас
непредсказуема, мы ее не моделируем.
y_i с крышкой — прогноз
или прогнозное значение.
ε_i с крышкой — остаток, ошибка прогноза.
И RSS (residual sum of squares)
— сумма квадратов остатков,
сумма квадратов ошибок прогнозов,
∑ε_i с крышкой в квадрате.
Нарисуем на графике,
покажем наше стандартное обозначение.
Итак, у нас есть набор данных: (x_i,
y_i, x_1, y_1, x_2, y_2) и так далее.
Этому множеству наблюдений соответствует
облако точек на плоскости.
Ось х, ось у и некоторое облако точек.
Заметим, что есть некий
геометрический центр этого облака,
этот геометрический центр не обязан
совпадать ни с одной из точек, ну может,
конечно, случайно так выйти.
Ну в принципе, не обязан.
То есть это некая точка в центре облака
с формальной математической точки
зрения определяется как х среднее
арифметическое и у среднее арифметическое.
И когда мы оцениваем модель y_i =
β₁ + β₂*x_i + ε_i мы получаем по
методу МНК — методу наименьших квадратов
оценки β₁ с крышкой и β₂ с крышкой.
Есть некая достаточно большая
формула для β₂ с крышкой,
выражаемая через отклонение ∑(x_i-
x среднее) * (y_i-
y среднее) делить на ∑(x_i-
x среднее) в квадрате.
И β₁ с крышкой = y среднее-
β₂ с крышкой * х среднее.
Ну еще второе уравнение можно трактовать
как β₁ с крышкой + β₂ с крышкой
* х среднее равняется у среднее.
То есть мы проводим некоторую прямую,
которая заменяет это облако точек.
Вот какая-то такая
прямая.
Заметим, что эта прямая y с крышкой
= β₁ с крышкой + β₂ с крышкой * х,
эта прямая обязана проходить через
геометрический центр облака точек,
потому что y среднее = β₁ с крышкой
+ β₂ с крышкой * х среднее.
Кроме того на этой прямой можно
изобразить значение β₁ с крышкой.
Вот эта величина — это β₁ с крышкой,
потому что при х = 0,
у с крышкой = β₁ с крышкой.
И именно поэтому,
из-за того что β₁ с крышкой
— это пересечение нашей прямой
регрессии с вертикальной осью,
то поэтому по английски β₁ с крышкой
называется intercept (пересечение).
Дальше, рассмотрим какое-нибудь
типичное наблюдение,
вот это пусть это будет
первое наблюдение (х_1,у_1).
Соответственно для заданного х
мы прогнозируем вот такой вот у.
Эта высота — это настоящий у_1,
то есть вот если так мы обозначим:
это будет у_1, а это будет х_1.
А вот эта величина — это, соответственно,
будет у_1 с крышечкой — прогноз,
который соответствует первому наблюдению.
А ошибка — разница между
первым у и первым у с
крышечкой — это будет ошибка
прогноза ε_1 с крышечкой.
Соответственно, метод наименьших
квадратов, он подбирает прямую так,
чтобы ошибки вот они, я нарисую ошибки —
это расстояние от каждой точки до прямой,
измеренное по вертикали.
Соответственно, метод наименьших
квадратов подбирает прямую так,
чтобы сумма квадратов
ошибок была минимальна.
Теперь перейдем к случаю большого
количества объясняющих переменных.
К счастью, случай двадцати объясняющих
переменных концептуально ничем не
отличается от случая всего лишь
двух объясняющих переменных x и z,
поэтому соответствующие
выкладки мы будем делать для
модели y_i = β₁ + β₂x_i + β₃z_i + ε_i.
И наша задача выписать систему уравнений,
из которой будут находиться β₁ с крышкой,β₂ с крышкой и β₃ с крышкой.
Что произойдет в случае большого
количества объясняющих переменных?
Мы рассмотрим на примере двух, потому
что даже уже с двумя готовые формулы для
β с крышкой в явном виде будут
иметь слишком громоздкий вид.
Итак, у нас имеется модель
y_i = β₁ + β₂x_i + β₃z_i + ε_i.
Поскольку ε_i — непрогнозируемая часть,
то формулы для прогнозов будут иметь
вид y_i с крышкой = β₁ с крышкой + β₂
с крышкой * x_i + β₃ с крышкой * z_i.
Ошибка прогноза ε_i с крышкой,
соответственно, равняется y_i-
y_i с крышкой.
И метод наименьших квадратов минимизирует
сумму ε_i с крышкой в квадрате.
Эта величина — это функция от β₁ с
крышкой, β₂ с крышкой и β₃ с крышкой.
Мы хотим приравнять производную
по каждой переменной к нулю и
посмотреть какие условия
первого порядка выйдут.
Соответственно, давайте заметим,
что вот у_i они от β с крышкой не зависят.
От β с крышкой зависят только прогнозы,
поэтому если я возьму производную
от ε_i с крышкой по dβ₁ с крышкой,
то от у_i там нет β₁ с крышкой,
там только настоящий β₁ есть,
который мы не знаем и никогда не узнаем.
А производная от у с крышкой
по β с крышкой — это единичка.
Соответственно, это будет минус единичка.
Производная ε_i с крышкой по dβ₂ по
аналогичным соображениям
— это будет минус x_i.
И производная ε_i с крышкой по β₃
с крышкой — это будет минус z_i.
Ну теперь мы можем выписать
условие первого порядка.
Условие первого порядка будет
производная Q по β₁ с крышкой =
0 Производная Q по β₂ с крышкой = 0.
Производная Q по β₃ с крышкой = 0.
Берем производное от суммы.
Соответственно, получаем первую.
Сумма, производное от квадрата —
это 2 умножить на ε_i с крышкой
на производное от ε с крышкой.
А производное от ε с крышкой это минус 1.
Равняется нулю.
Берем производную это условие dQ
по dβ₁ с крышкой равняется нулю.
Аналогично берем производную
от этой суммы по β₂ с крышкой
получаем сумму 2 * ε_i с крышкой
на производную ε с крышкой по β₂.
Получаем минус x_i = 0.
И аналогично взяв производную от суммы
ε_i с крышкой по β₃ с крышкой мы получим
сумму 2 * ε_i с крышкой на
минус z_i равняется нулю.
Мы получили три условия первого порядка
и из этой системы из трех уравнений мы
можем найти три неизвестных: β₁ с крышкой,
β₂ с крышкой и β₃ с крышкой.
Можно немножко упростить эту систему,
поделить на минус 2 и получится
вот такая вот симпатичная система,
из которой находятся неизвестные
оценки коэффициентов.
Сумма ε_i с крышкой на
единичку равняется нулю.
Опять же единичку можно не писать,
но для ясности я напишу.
Сумма ε_i с крышкой на x_i равняется нулю.
И сумма ε_i с крышкой на z_i равняется нулю.
Оказывается у этих условий есть
очень интересная интерпретация,
о которой мы поговорим прямо сейчас.
Итак, решая эту систему мы
получили следующий вывод: что
неизвестные оценки β₁ с крышкой,
β₂ с крышкой,
β₃ с крышкой — три неизвестных числа
находятся из системы трех уравнений.
Сумма ε_i с крышкой равно нулю.
Сумма произведений ε_i с
крышкой на x_i равно нулю.
И сумма ε_i с крышкой на z_i равно нулю.

