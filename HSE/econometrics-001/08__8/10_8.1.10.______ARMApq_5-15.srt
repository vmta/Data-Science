1
00:00:08,230 --> 00:00:16,993
Модель авторегрессии

2
00:00:16,993 --> 00:00:19,984
и скользящего среднего обобщает собой,
соответственно,

3
00:00:19,984 --> 00:00:23,610
модель авторегрессии и модель
процесса скользящего среднего.

4
00:00:23,610 --> 00:00:31,974
То есть это — стационарный процесс вида
yt = константа + b1yt − 1 + b2y2 − 2 +...

5
00:00:31,974 --> 00:00:36,438
+, p прошлых значений игрека используется,

6
00:00:36,438 --> 00:00:42,412
+ εt + a1εt − 1 + a2 на εt − 2 ,...,

7
00:00:43,902 --> 00:00:47,930
всего q предыдущих значений ε.

8
00:00:47,930 --> 00:00:51,444
И мы предполагаем,
что сумма p + q минимально возможна,

9
00:00:51,444 --> 00:00:53,610
то есть эта запись самая короткая.

10
00:00:53,610 --> 00:00:56,502
Процессы авторегрессии
скользящего среднего,

11
00:00:56,502 --> 00:00:59,116
сокращенно обозначается: ARMA (p, q).

12
00:00:59,116 --> 00:01:03,742
Первое, параметр p — это количество
лагов по AR-части, по y,

13
00:01:03,742 --> 00:01:06,434
и MA — это количество лагов по...

14
00:01:06,434 --> 00:01:10,690
q — это количество лагов по
части скользящего среднего.

15
00:01:10,690 --> 00:01:16,247
Что означает фраза: сумма
p + q минимальна возможна?

16
00:01:16,247 --> 00:01:20,892
Оказывается, один и тот же процесс я
могу записать несколькими уравнениями.

17
00:01:20,892 --> 00:01:24,734
Ну, например, если yt — это просто
белый шум, то есть yt = εt,

18
00:01:24,734 --> 00:01:29,260
то я возьму из сегодняшнего y вычту
вчерашний, и у меня получится,

19
00:01:29,260 --> 00:01:34,896
что yt − yt −1 = εt − εt − 1.

20
00:01:34,896 --> 00:01:37,363
И, соответственно, получается,

21
00:01:37,363 --> 00:01:41,430
что у меня две формы записи по
сути одного и того же процесса.

22
00:01:41,430 --> 00:01:44,988
И, естественно,
мы выбираем самую кратчайшую,

23
00:01:44,988 --> 00:01:47,895
в самой кратчайшей форме записи yt = εt.

24
00:01:47,895 --> 00:01:52,196
Это процесс ARMA (0, 0),
у него нет предыдущих

25
00:01:52,196 --> 00:01:56,673
значений y уравнений и нет
предыдущих значений ε уравнений.

26
00:01:56,673 --> 00:01:59,747
Процессы ARMA — это в каком-то смысле все,

27
00:01:59,747 --> 00:02:04,080
что нам нужно знать про
стационарные процессы.

28
00:02:04,080 --> 00:02:06,232
Есть теорема, которая говорит о том,

29
00:02:06,232 --> 00:02:10,603
что любой стационарный процесс можно
представить в виде AR-бесконечность.

30
00:02:10,603 --> 00:02:15,930
То есть AR-процесс с бесконечным
количеством предыдущих лагов.

31
00:02:15,930 --> 00:02:21,011
А ARMA- процесс, можно выбрать
количество лагов p,q достаточно большим

32
00:02:21,011 --> 00:02:26,275
и выбрать коэффициенты перед игреками
прошлыми и перед эпсилонами прошлыми так,

33
00:02:26,275 --> 00:02:32,190
чтоб приблизить с высокой степенью
точности любой AR (∞) процесс.

34
00:02:32,190 --> 00:02:37,117
Соответственно, получается на практике,
что ARMA (p, q) процессов достаточна,

35
00:02:37,117 --> 00:02:40,280
чтобы моделировать любой
стационарный процесс.

36
00:02:40,280 --> 00:02:45,616
Итого, про ARMA-процессы мы получаем
следующие выводы: что коэффициенты

37
00:02:45,616 --> 00:02:50,436
у них не интерпретируются, интерпретация
коэффициентов отдельных невозможна,

38
00:02:50,436 --> 00:02:53,770
однако они достаточно хорошо прогнозируют,

39
00:02:53,770 --> 00:02:57,110
и именно для этого мы их
и будем использовать.

40
00:02:57,110 --> 00:03:00,870
Чтобы прогнозировать,
надо сначала оценить модель.

41
00:03:00,870 --> 00:03:07,190
Соответственно, у нас на входе
будет T наблюдений: y1, y2,..., yT.

42
00:03:07,190 --> 00:03:12,007
И для оценки неизвестных коэффициентов
мы будем использовать метод

43
00:03:12,007 --> 00:03:14,340
максимального правдоподобия.

44
00:03:14,340 --> 00:03:18,815
В методе максимального
правдоподобия необходимы более

45
00:03:18,815 --> 00:03:23,290
конкретные предпосылки на закон
распределения случайной величины ε.

46
00:03:23,290 --> 00:03:25,622
Стандартно предполагается,

47
00:03:25,622 --> 00:03:29,684
что ε независимы и имеют
нормальное распределение с нулевым

48
00:03:29,684 --> 00:03:33,340
математическим ожиданием и
постоянной дисперсией ς-квадрат.

49
00:03:33,340 --> 00:03:38,115
Также мы предполагаем стационарность
процесса yt и выполнение

50
00:03:38,115 --> 00:03:41,294
уравнения ARMA-процесса на yt.

51
00:03:41,294 --> 00:03:45,493
В результате применения метода
максимального правдоподобия,

52
00:03:45,493 --> 00:03:48,166
мы получаем вектор оценок
неизвестных коэффициентов.

53
00:03:48,166 --> 00:03:53,586
Неизвестными у нас являются показателями:
а1, а2, а3,..., аq, соответственно,

54
00:03:53,586 --> 00:03:58,430
мы получаем а1 с крышечкой,
а2 с крышечкой,..., аq с крышечкой.

55
00:03:58,430 --> 00:04:03,282
И также неизвестными показателями
являются коэффициенты b1, b2,...,

56
00:04:03,282 --> 00:04:06,533
bp, мы получаем их оценки,
то есть bi с крышечками,

57
00:04:06,533 --> 00:04:11,354
и также неизвестными являются
показатели дисперсии белого шума ε,

58
00:04:11,354 --> 00:04:15,180
ς-квадрат, мы получаем его оценку.

59
00:04:15,180 --> 00:04:17,248
Помимо оценок сами коэффициентов,

60
00:04:17,248 --> 00:04:22,060
метод максимального правдоподобия дает
нам также оценку ковариационной матрицы.

61
00:04:22,060 --> 00:04:26,120
VAR с крышкой, θ с скрышкой.

62
00:04:26,120 --> 00:04:31,005
И, соответственно, имея оценки
коэффициентов и оценку их ковариационной

63
00:04:31,005 --> 00:04:35,890
матрицы, мы можем строить доверительные
интервалы и проверять гипотезы.

64
00:04:35,890 --> 00:04:39,594
К сожалению, только асимптотически,
то есть только при больших N.

65
00:04:39,594 --> 00:04:45,330
Здесь результатов для малых выборок
нет даже в предположении нормальности

66
00:04:45,330 --> 00:04:51,403
отдельных εt, но тем не менее при
больших выборках мы можем утверждать,

67
00:04:51,403 --> 00:04:56,315
что оценка коэффициента aj с
крышкой минус настоящая aj,

68
00:04:56,315 --> 00:05:01,902
делить на стандартную ошибку aj с крышкой,
стремится к нормальному стандартному

69
00:05:01,902 --> 00:05:06,285
распределению с математическим
ожиданием 0 и дисперсией, равной 1.

70
00:05:06,285 --> 00:05:11,040
Это нам позволяет проверять гипотезы
и строить доверительные интервалы.

