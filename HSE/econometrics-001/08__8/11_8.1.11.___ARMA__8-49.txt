По имеющимся у нас реальным данным (Y1,
..., Yt) мы можем оценить неизвестную
нам автокорреляционную функцию,
поскольку настоящие значения
параметров не известны,
то и настоящая автокорреляционная
функция ρk не известна.
Однако, мы можем оценить
каждую корреляцию,
получить ρ (с крышечкой) k по
следующей формуле: это дробь,
где используется обычная оценка
корреляции между Yt и Yt – k,
то есть это сумма (Yt – Y
среднее) * (Y(t- k)- Y среднее),
деленное на сумму
квадратов (Yt- Y среднее).
И аналогичным образом мы можем оценить
частную автокорреляционную функцию.
А именно, для того чтобы получить
коэффициент φ (с крышкой) k-тое,
оценку неизвестной
автокорреляционной функции,
мы строим регрессию Yt на константу
Yt – 1, Yt – 2, Yt – 3, ..., Yt – k.
И из этой регрессии нас интересует
всего один коэффициент.
Потому что что меряет частная
автокорреляционная функция по смыслу?
Она меряет насколько изменится Yt,
если Yt – k изменится на 1,
а остальные будут константами?
То есть фактически она меряет...
равна коэффициенту в обычной регрессии.
И, соответственно,
чтобы оценить несколько значений частной
автокорреляционной функции, мы построим
для каждой оценки одну свою регрессию,
то есть чтобы получить φ1 (с крышкой) мы
построим регрессию Yt на константу Yt – 1
(с крышкой),
возьмем последний коэффициент.
Чтобы оценить φ2 (с крышкой),
мы оценим регрессию Yt * Yt
– 1 * Yt – 2 (с крышкой) и опять
возьмем последний коэффициент.
И, соответственно,
оценив несколько регрессий,
мы получим оценку частной
автокорреляционной функции.
Соответственно, на практике алгоритм
оценивания ARMA модели выглядит следующим
образом: мы строим график самого ряда,
график
оцененных автокорреляционной функции,
частной автокорреляционной функции.
Соответственно, по этим графикам
мы определяем характеристики ряда.
Если ряд нестационарный, то, естественно,
ARMA модели для него не подходят,
ARMA модели у нас стационарные,
и нам необходимо применить какое-то
преобразование, чтобы
сделать ряд стационарным.
На третьем шаге мы выбираем
параметры p и q, то есть по,
например, графически,
мы определяем число лагов по Y,
перед Yt,
Yt– 1 и количество лагов по MA части.
Дальше, определив количество лагов,
мы оценивам ARMA модель,
и дальше мы можем использовать эту
оцененную ARMA модель для прогнозирования.
Основным преобразованием,
которое используется для приведения
нестационарных рядов к стационарному
виду — это взятие разности.
То есть вместо того, чтобы моделировать
ряд Yt, мы моделируем ряд ΔYt.
Вместо того, чтобы моделировать,
скажем, сам валютный курс,
мы моделируем его приращение.
Вместо того,
чтобы моделировать денежную массу,
мы моделируем изменение денежной массы.
Тут используют следующие обозначения:
если мы пишем, что Yt — это ARIMA (p,
1, q), это означает,
что надо взять разницу один раз,
то есть вместо Yt перейти к ΔYt, и уже ряд
ΔYt моделировать ARMA(p, q) процессом.
Ну и, соответственно,
обозначение ARIMA(p, 0, q) означает,
что сам ряд Yt мы моделируем
процессом ARMA(p, q).
И, соответственно, рассмотрим на примерах,
как по графикам выборочных корреляционных
функций можно выбрать p и q.
Единственное, что здесь надо понимать,
что обычная автокорреляционная функция
ρk и частная автокорреляционная φk она
определена только для
стационарного процесса.
У процесса, у которого меняется
математическое ожидание или меняется
дисперсия или ковариация между
сегодня и вчера не такая, как
между вчера и позавчера, у него понятие
автокорреляционной функции не определено.
Однако, частную автокорреляционную функцию
и выборочную корреляционную функцию,
оцененную по выборке, мы всегда увидим
даже у нестационарного процесса.
Надо понимать,
что у нестационарного процесса эта оценка
корреляционной функции
немного бессмысленна.
Да, она нам позволяет узнать процесс,
но поскольку настоящая корреляционная
функция не существует,
то и оценка автокорреляционной функции
не несет в себе прямой смысл оценки.
Давайте рассмотрим несколько примеров.
Вот ситуация с белым шумом.
Как выглядит сам ряд?
Он живет в полоске постоянной ширины.
У него, естественно, поскольку разные
эпсилоны независимы: ε1, ε2, ε3, ε7,
то поэтому здесь нулевые автокорреляции
и нулевые частные автокорреляции.
Перейдем к графику случайного блуждания.
Здесь мы видим,
что процесс может далеко отходить от нуля,
и видим медленно убывающую
автокорреляционную функцию,
очень медленно убывающую
автокорреляционную функцию.
Это такой серьезный признак
случайного блуждания.
Еще раз подчеркну, что это нестационарный
процесс, и у такого процесса
некорректно говорить об автокорреляционной
функции, однако оценка автокорреляционной
функции по стандартным формулам считается
и есть, и мы ее увидим на графике.
Аналогично — процесс с трендом.
Это нестационарный процесс.
У него не определена
автокорреляционная функция,
однако оценку автокорреляционной
функции мы увидим.
Она плавно убывает.
Частная автокорреляционная
функция убывает довольно резко.
И ряд на самом графике для исходного
ряда колеблется вокруг тренда.
Аналогичные графики для AR(1)
процесса и для AR(2) процесса
выглядят следующим образом: мы видим,
что по графику
самого ряда его не отличить
от случайного блуждания...
его не отличить от белого шума.
Однако если посмотреть на графики
автокорреляционной функции и частной
автокорреляционной функции,
то можно увидеть закономерность.
График автокорреляционной функции
довольно резко убывает к нулю,
довольно быстро убывает к нулю,
но тем не менее не ноль некоторое время,
а график частной автокорреляционной
функции для AR(1) процесса только
первое значение частной
автокорреляционной функции не равно нулю,
а остальные уже практически все равны
нулю, а для AR(2) процесса первые
два значения частной автокорреляционной
функции не нули, а остальные нули.
На графике для удобства мы
видим две пунктирные линии,
которые показывают границы доверительного
интервала и позволяют визуально
проверить гипотезу о том,
равен настоящий коэффициент корреляции
или частной корреляции нулю или нет.
Аналогичные графики для процессов
скользящего среднего MA(1) и
MA(2) выглядят в некотором
смысле зеркально графикам
для AR процесса, а именно
автокорреляционная функция — первое
одно значение или первые два значения
не равны нулю, а, соответственно,
частная автокорреляционная функция
убывает довольно быстро к нулю.
Соответственно, по этим признакам
мы можем по графикам выбрать
параметры p и q,
определить: стационарный процесс или нет.
Аналогичный график для ARMA процесса
выглядит следующим образом: мы видим,
опять же, что сам процесс практически
неотличим по графику ни от AR,
ни от MA, ни от белого шума,
однако на графиках частной
автокорреляционной функции и просто
автокорреляционной функции мы
видим довольно быстрое
убывание коэффициентов к нулю.
Итак, подведем мораль сегодняшней лекции:
временные ряды бывают стационарные
или нет; стационарные временные ряды
моделируются с помощью модели класса ARMA,
а нестационарные, как правила,
приводятся преобразованием к стационарным.

