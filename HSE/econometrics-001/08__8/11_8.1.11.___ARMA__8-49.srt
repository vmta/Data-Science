1
00:00:13,270 --> 00:00:18,708
По имеющимся у нас реальным данным (Y1,

2
00:00:18,708 --> 00:00:23,583
..., Yt) мы можем оценить неизвестную
нам автокорреляционную функцию,

3
00:00:23,583 --> 00:00:26,570
поскольку настоящие значения
параметров не известны,

4
00:00:26,570 --> 00:00:30,477
то и настоящая автокорреляционная
функция ρk не известна.

5
00:00:30,477 --> 00:00:33,454
Однако, мы можем оценить
каждую корреляцию,

6
00:00:33,454 --> 00:00:37,305
получить ρ (с крышечкой) k по
следующей формуле: это дробь,

7
00:00:37,305 --> 00:00:42,313
где используется обычная оценка
корреляции между Yt и Yt – k,

8
00:00:42,313 --> 00:00:48,795
то есть это сумма (Yt – Y
среднее) * (Y(t- k)- Y среднее),

9
00:00:48,795 --> 00:00:53,590
деленное на сумму
квадратов (Yt- Y среднее).

10
00:00:53,590 --> 00:01:00,510
И аналогичным образом мы можем оценить
частную автокорреляционную функцию.

11
00:01:00,510 --> 00:01:05,370
А именно, для того чтобы получить
коэффициент φ (с крышкой) k-тое,

12
00:01:05,370 --> 00:01:08,874
оценку неизвестной
автокорреляционной функции,

13
00:01:08,874 --> 00:01:14,756
мы строим регрессию Yt на константу
Yt – 1, Yt – 2, Yt – 3, ..., Yt – k.

14
00:01:14,756 --> 00:01:18,342
И из этой регрессии нас интересует
всего один коэффициент.

15
00:01:18,342 --> 00:01:22,090
Потому что что меряет частная
автокорреляционная функция по смыслу?

16
00:01:22,090 --> 00:01:26,348
Она меряет насколько изменится Yt,

17
00:01:26,348 --> 00:01:31,400
если Yt – k изменится на 1,
а остальные будут константами?

18
00:01:31,400 --> 00:01:34,701
То есть фактически она меряет...

19
00:01:34,701 --> 00:01:38,540
равна коэффициенту в обычной регрессии.

20
00:01:38,540 --> 00:01:44,105
И, соответственно,
чтобы оценить несколько значений частной

21
00:01:44,105 --> 00:01:48,490
автокорреляционной функции, мы построим
для каждой оценки одну свою регрессию,

22
00:01:48,490 --> 00:01:53,258
то есть чтобы получить φ1 (с крышкой) мы
построим регрессию Yt на константу Yt – 1

23
00:01:53,258 --> 00:01:56,180
(с крышкой),
возьмем последний коэффициент.

24
00:01:56,180 --> 00:02:00,815
Чтобы оценить φ2 (с крышкой),
мы оценим регрессию Yt * Yt

25
00:02:00,815 --> 00:02:04,670
– 1 * Yt – 2 (с крышкой) и опять
возьмем последний коэффициент.

26
00:02:04,670 --> 00:02:07,537
И, соответственно,
оценив несколько регрессий,

27
00:02:07,537 --> 00:02:10,670
мы получим оценку частной
автокорреляционной функции.

28
00:02:10,670 --> 00:02:15,521
Соответственно, на практике алгоритм
оценивания ARMA модели выглядит следующим

29
00:02:15,521 --> 00:02:20,175
образом: мы строим график самого ряда,
график

30
00:02:20,175 --> 00:02:24,210
оцененных автокорреляционной функции,
частной автокорреляционной функции.

31
00:02:24,210 --> 00:02:28,520
Соответственно, по этим графикам
мы определяем характеристики ряда.

32
00:02:28,520 --> 00:02:32,984
Если ряд нестационарный, то, естественно,
ARMA модели для него не подходят,

33
00:02:32,984 --> 00:02:36,329
ARMA модели у нас стационарные,
и нам необходимо применить какое-то

34
00:02:36,329 --> 00:02:38,760
преобразование, чтобы
сделать ряд стационарным.

35
00:02:38,760 --> 00:02:43,570
На третьем шаге мы выбираем
параметры p и q, то есть по,

36
00:02:43,570 --> 00:02:49,120
например, графически,
мы определяем число лагов по Y,

37
00:02:49,120 --> 00:02:53,760
перед Yt,
Yt– 1 и количество лагов по MA части.

38
00:02:53,760 --> 00:02:57,670
Дальше, определив количество лагов,
мы оценивам ARMA модель,

39
00:02:57,670 --> 00:03:01,800
и дальше мы можем использовать эту
оцененную ARMA модель для прогнозирования.

40
00:03:01,800 --> 00:03:05,709
Основным преобразованием,
которое используется для приведения

41
00:03:05,709 --> 00:03:09,285
нестационарных рядов к стационарному
виду — это взятие разности.

42
00:03:09,285 --> 00:03:13,259
То есть вместо того, чтобы моделировать
ряд Yt, мы моделируем ряд ΔYt.

43
00:03:13,259 --> 00:03:16,912
Вместо того, чтобы моделировать,
скажем, сам валютный курс,

44
00:03:16,912 --> 00:03:18,289
мы моделируем его приращение.

45
00:03:18,289 --> 00:03:20,540
Вместо того,
чтобы моделировать денежную массу,

46
00:03:20,540 --> 00:03:23,248
мы моделируем изменение денежной массы.

47
00:03:23,248 --> 00:03:28,448
Тут используют следующие обозначения:
если мы пишем, что Yt — это ARIMA (p,

48
00:03:28,448 --> 00:03:32,984
1, q), это означает,
что надо взять разницу один раз,

49
00:03:32,984 --> 00:03:38,723
то есть вместо Yt перейти к ΔYt, и уже ряд
ΔYt моделировать ARMA(p, q) процессом.

50
00:03:38,723 --> 00:03:44,086
Ну и, соответственно,
обозначение ARIMA(p, 0, q) означает,

51
00:03:44,086 --> 00:03:49,149
что сам ряд Yt мы моделируем
процессом ARMA(p, q).

52
00:03:49,149 --> 00:03:53,568
И, соответственно, рассмотрим на примерах,

53
00:03:53,568 --> 00:03:58,935
как по графикам выборочных корреляционных
функций можно выбрать p и q.

54
00:03:58,935 --> 00:04:01,483
Единственное, что здесь надо понимать,

55
00:04:01,483 --> 00:04:06,251
что обычная автокорреляционная функция
ρk и частная автокорреляционная φk она

56
00:04:06,251 --> 00:04:09,160
определена только для
стационарного процесса.

57
00:04:09,160 --> 00:04:13,154
У процесса, у которого меняется
математическое ожидание или меняется

58
00:04:13,154 --> 00:04:17,848
дисперсия или ковариация между
сегодня и вчера не такая, как

59
00:04:17,848 --> 00:04:22,690
между вчера и позавчера, у него понятие
автокорреляционной функции не определено.

60
00:04:22,690 --> 00:04:29,403
Однако, частную автокорреляционную функцию
и выборочную корреляционную функцию,

61
00:04:29,403 --> 00:04:34,630
оцененную по выборке, мы всегда увидим
даже у нестационарного процесса.

62
00:04:34,630 --> 00:04:39,285
Надо понимать,
что у нестационарного процесса эта оценка

63
00:04:39,285 --> 00:04:41,855
корреляционной функции
немного бессмысленна.

64
00:04:41,855 --> 00:04:43,940
Да, она нам позволяет узнать процесс,

65
00:04:43,940 --> 00:04:48,120
но поскольку настоящая корреляционная
функция не существует,

66
00:04:48,120 --> 00:04:53,010
то и оценка автокорреляционной функции
не несет в себе прямой смысл оценки.

67
00:04:53,010 --> 00:04:56,210
Давайте рассмотрим несколько примеров.

68
00:04:56,210 --> 00:04:58,263
Вот ситуация с белым шумом.

69
00:04:58,263 --> 00:04:59,887
Как выглядит сам ряд?

70
00:04:59,887 --> 00:05:02,720
Он живет в полоске постоянной ширины.

71
00:05:02,720 --> 00:05:09,820
У него, естественно, поскольку разные
эпсилоны независимы: ε1, ε2, ε3, ε7,

72
00:05:09,820 --> 00:05:16,910
то поэтому здесь нулевые автокорреляции
и нулевые частные автокорреляции.

73
00:05:16,910 --> 00:05:20,700
Перейдем к графику случайного блуждания.

74
00:05:20,700 --> 00:05:25,470
Здесь мы видим,
что процесс может далеко отходить от нуля,

75
00:05:25,470 --> 00:05:30,927
и видим медленно убывающую
автокорреляционную функцию,

76
00:05:30,927 --> 00:05:33,489
очень медленно убывающую
автокорреляционную функцию.

77
00:05:33,489 --> 00:05:36,545
Это такой серьезный признак
случайного блуждания.

78
00:05:36,545 --> 00:05:41,532
Еще раз подчеркну, что это нестационарный
процесс, и у такого процесса

79
00:05:41,532 --> 00:05:46,325
некорректно говорить об автокорреляционной
функции, однако оценка автокорреляционной

80
00:05:46,325 --> 00:05:49,710
функции по стандартным формулам считается
и есть, и мы ее увидим на графике.

81
00:05:49,710 --> 00:05:52,327
Аналогично — процесс с трендом.

82
00:05:52,327 --> 00:05:54,680
Это нестационарный процесс.

83
00:05:54,680 --> 00:05:57,081
У него не определена
автокорреляционная функция,

84
00:05:57,081 --> 00:05:59,650
однако оценку автокорреляционной
функции мы увидим.

85
00:05:59,650 --> 00:06:00,913
Она плавно убывает.

86
00:06:00,913 --> 00:06:04,847
Частная автокорреляционная
функция убывает довольно резко.

87
00:06:04,847 --> 00:06:11,590
И ряд на самом графике для исходного
ряда колеблется вокруг тренда.

88
00:06:11,590 --> 00:06:16,981
Аналогичные графики для AR(1)
процесса и для AR(2) процесса

89
00:06:16,981 --> 00:06:21,955
выглядят следующим образом: мы видим,
что по графику

90
00:06:21,955 --> 00:06:26,883
самого ряда его не отличить
от случайного блуждания...

91
00:06:26,883 --> 00:06:29,050
его не отличить от белого шума.

92
00:06:29,050 --> 00:06:33,062
Однако если посмотреть на графики
автокорреляционной функции и частной

93
00:06:33,062 --> 00:06:36,760
автокорреляционной функции,
то можно увидеть закономерность.

94
00:06:36,760 --> 00:06:41,432
График автокорреляционной функции
довольно резко убывает к нулю,

95
00:06:41,432 --> 00:06:46,512
довольно быстро убывает к нулю,
но тем не менее не ноль некоторое время,

96
00:06:46,512 --> 00:06:51,721
а график частной автокорреляционной
функции для AR(1) процесса только

97
00:06:51,721 --> 00:06:56,651
первое значение частной
автокорреляционной функции не равно нулю,

98
00:06:56,651 --> 00:07:03,589
а остальные уже практически все равны
нулю, а для AR(2) процесса первые

99
00:07:03,589 --> 00:07:08,890
два значения частной автокорреляционной
функции не нули, а остальные нули.

100
00:07:08,890 --> 00:07:13,136
На графике для удобства мы
видим две пунктирные линии,

101
00:07:13,136 --> 00:07:18,114
которые показывают границы доверительного
интервала и позволяют визуально

102
00:07:18,114 --> 00:07:19,725
проверить гипотезу о том,

103
00:07:19,725 --> 00:07:24,950
равен настоящий коэффициент корреляции
или частной корреляции нулю или нет.

104
00:07:24,950 --> 00:07:29,894
Аналогичные графики для процессов
скользящего среднего MA(1) и

105
00:07:29,894 --> 00:07:35,099
MA(2) выглядят в некотором
смысле зеркально графикам

106
00:07:35,099 --> 00:07:40,205
для AR процесса, а именно
автокорреляционная функция — первое

107
00:07:40,205 --> 00:07:45,400
одно значение или первые два значения
не равны нулю, а, соответственно,

108
00:07:45,400 --> 00:07:51,090
частная автокорреляционная функция
убывает довольно быстро к нулю.

109
00:07:51,090 --> 00:07:56,610
Соответственно, по этим признакам
мы можем по графикам выбрать

110
00:07:56,610 --> 00:08:01,570
параметры p и q,
определить: стационарный процесс или нет.

111
00:08:01,570 --> 00:08:09,492
Аналогичный график для ARMA процесса
выглядит следующим образом: мы видим,

112
00:08:09,492 --> 00:08:14,647
опять же, что сам процесс практически
неотличим по графику ни от AR,

113
00:08:14,647 --> 00:08:19,153
ни от MA, ни от белого шума,
однако на графиках частной

114
00:08:19,153 --> 00:08:23,919
автокорреляционной функции и просто
автокорреляционной функции мы

115
00:08:23,919 --> 00:08:27,170
видим довольно быстрое
убывание коэффициентов к нулю.

116
00:08:27,170 --> 00:08:34,643
Итак, подведем мораль сегодняшней лекции:
временные ряды бывают стационарные

117
00:08:34,643 --> 00:08:39,870
или нет; стационарные временные ряды
моделируются с помощью модели класса ARMA,

118
00:08:39,870 --> 00:08:44,540
а нестационарные, как правила,
приводятся преобразованием к стационарным.

