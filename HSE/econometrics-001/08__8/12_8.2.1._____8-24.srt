1
00:00:13,650 --> 00:00:17,965
Запускаем RStudio,

2
00:00:17,965 --> 00:00:23,563
открываем заранее
заготовленный маленький файл.

3
00:00:23,563 --> 00:00:27,330
Open file, и выбираем тут lab_08_before.R.

4
00:00:27,330 --> 00:00:31,880
Соответственно, здесь у нас
сразу сделана загрузка пакетов.

5
00:00:31,880 --> 00:00:33,320
Загружаем пакеты.

6
00:00:33,320 --> 00:00:39,500
И начнём мы с тех рядов,
которые мы сами искусственно создадим,

7
00:00:39,500 --> 00:00:44,352
потому что на искусственно созданных рядах
мы знаем, как устроена истина, и это нам…

8
00:00:44,352 --> 00:00:50,074
знание истины, облегчает нам понимание
графиков соответствующего временного ряда,

9
00:00:50,074 --> 00:00:53,850
автокорреляционной функции и
частной автокорреляционной функции.

10
00:00:53,850 --> 00:00:58,900
Для начала сгенерим простой ряд с помощью

11
00:00:58,900 --> 00:01:03,980
команды arima.sim, то есть это симуляция,
искусственно создаём процесс arima.

12
00:01:03,980 --> 00:01:11,132
Возьмём, скажем, 100 наблюдений и
возьмём AR(1)-процесс с параметром,

13
00:01:11,132 --> 00:01:16,920
скажем, равным 0.7, ar=0.7.

14
00:01:16,920 --> 00:01:20,755
Соответственно, мы сгенерировали наш ряд.

15
00:01:20,755 --> 00:01:25,570
Теперь можно построить его график,
plot(y).

16
00:01:25,570 --> 00:01:32,770
Вот так вот выглядит типичный график
для AR(1)-процесса с параметром 0.7.

17
00:01:32,770 --> 00:01:37,220
Можно посмотреть, как выглядит
его автокорреляционная функция,

18
00:01:37,220 --> 00:01:42,060
Acf(y).

19
00:01:42,060 --> 00:01:46,900
И можно посмотреть, как выглядит его
частная автокорреляционная функция

20
00:01:46,900 --> 00:01:50,361
partial autocorrelation function, Pacf(y).

21
00:01:50,361 --> 00:01:57,210
Ну для удобства мы все три графика
выведем на один экран и посмотрим.

22
00:01:57,210 --> 00:02:02,316
Есть специальная функция tsdisplay,
которая выводит

23
00:02:02,316 --> 00:02:07,700
сразу три этих популярных графика
для одномерного временного ряда.

24
00:02:07,700 --> 00:02:11,587
Мы сделаем увеличение картинки,
нажмем Zoom,

25
00:02:11,587 --> 00:02:19,193
немножко тут потянем и получим
такой замечательный график.

26
00:02:19,193 --> 00:02:24,683
Итак, это AR(1) процесс: yt = 0,7yt ‒

27
00:02:24,683 --> 00:02:29,876
1 + εt, Соответственно, что мы видим?

28
00:02:29,876 --> 00:02:35,044
Если посмотреть на сам график, то видно,
что, в принципе, текущее значение y,

29
00:02:35,044 --> 00:02:40,286
— вот если я возьму какое-то значение, —
оно довольно сильно похоже на предыдущее.

30
00:02:40,286 --> 00:02:44,341
Ну то есть если y был низким,
то и следующий y тоже, скорее всего,

31
00:02:44,341 --> 00:02:45,033
будет низким.

32
00:02:45,033 --> 00:02:48,386
А если вот y был высоким, то и следующий
y, скорее всего, будет высоким.

33
00:02:48,386 --> 00:02:52,310
Ну бывают, конечно, довольно резкие
падения, можно найти на графике: вот был

34
00:02:52,310 --> 00:02:55,494
где-то средненький, около единички,
а тут вот резко упал.

35
00:02:55,494 --> 00:02:59,859
Но, тем не менее, около высоких значений
следуют высокие, и это естественное

36
00:02:59,859 --> 00:03:04,197
свойство AR процесса, потому что yt
по-хорошему равен 0,7 помножить на y

37
00:03:04,197 --> 00:03:09,130
предыдущее плюс случайная составляющая,
что мы видим, соответственно, на графике

38
00:03:09,130 --> 00:03:12,260
обычной автокорреляционной функции и
частной автокорреляционной функции?

39
00:03:12,260 --> 00:03:19,780
На этом графике мы видим корреляцию
между yt и y несколько шагов назад.

40
00:03:19,780 --> 00:03:25,760
То есть если я знаю… если вот предыдущий
y выше среднего уровня на единичку,

41
00:03:25,760 --> 00:03:31,330
то следующий y почти на 0,8 будет выше,
чем свой средний уровень.

42
00:03:31,330 --> 00:03:36,520
А если у меня есть информация о том,
что — раз, два, три, — четыре шага назад,

43
00:03:36,520 --> 00:03:41,318
y четыре шага назад,
четыре периода по времени назад был выше

44
00:03:41,318 --> 00:03:46,125
своего среднего уровня на единичку,
то это приведёт к тому,

45
00:03:46,125 --> 00:03:53,384
что сегодняшний y в среднем будет где-то
на 0,4 выше, чем средний уровень.

46
00:03:53,384 --> 00:03:57,371
То есть мы видим,
что влияние прошлых y ослабляется,

47
00:03:57,371 --> 00:03:59,472
вот если мерить совокупный эффект.

48
00:03:59,472 --> 00:04:03,070
Что мы видим на графике частной
автокорреляционной функции?

49
00:04:03,070 --> 00:04:06,643
На графике частной
автокорреляционной функции мы видим,

50
00:04:06,643 --> 00:04:09,650
что частная автокорреляция
φ1 отлична от нуля,

51
00:04:09,650 --> 00:04:14,480
а остальные частные
автокорреляции ну близки к нулю.

52
00:04:14,480 --> 00:04:18,186
Поскольку мы имеем дело не с настоящими
автокорреляционными функциями,

53
00:04:18,186 --> 00:04:21,078
не с теоретическими, а с выборочной,

54
00:04:21,078 --> 00:04:27,044
то вот здесь R автоматом провёл
границы доверительного интервала,

55
00:04:27,044 --> 00:04:31,682
— соответственно, частная автокорреляция,
начиная со второй, третьей,

56
00:04:31,682 --> 00:04:35,600
четвёртой, пятой и так далее, — гипотеза
о том, что они равны нулю не отвергается.

57
00:04:35,600 --> 00:04:40,238
То есть у нас по-хорошему только одна
частная автокорреляция не равна нулю.

58
00:04:40,238 --> 00:04:41,160
И что мы видим?

59
00:04:41,160 --> 00:04:44,670
Как мы проинтерпретируем этот эффект?

60
00:04:44,670 --> 00:04:48,237
Первая автокорреляция,

61
00:04:48,237 --> 00:04:52,780
она совпадает с первой частной, да, вот
эти два столбика первые одинаковой высоты,

62
00:04:52,780 --> 00:04:56,068
а вторая частная
автокорреляция уже равна нулю.

63
00:04:56,068 --> 00:04:57,321
Что это означает?

64
00:04:57,321 --> 00:05:00,689
Это означает,
что если зафиксировать вчерашний y,

65
00:05:00,689 --> 00:05:05,790
и я знаю что-то про позавчерашний, что
позавчерашний был выше своего среднего,

66
00:05:05,790 --> 00:05:11,910
то это не несёт никакой
информации о сегодняшнем y.

67
00:05:11,910 --> 00:05:17,428
Соответственно, давайте теперь посмотрим,
как выглядят аналогичные

68
00:05:17,428 --> 00:05:22,552
графики для MA-процесса,
для процесса скользящего среднего.

69
00:05:22,552 --> 00:05:25,870
Собственно, замена у нас тут будут одна.

70
00:05:25,870 --> 00:05:31,140
Скажем, мы возьмём MA-процесс
коэффициентом минус 0.8.

71
00:05:31,140 --> 00:05:35,929
Сгенерировали y,
и сразу построим один график,

72
00:05:35,929 --> 00:05:39,520
состоящий из трёх составляющих.

73
00:05:39,520 --> 00:05:45,677
Вот перед нами уже типичный MA-процесс.

74
00:05:45,677 --> 00:05:48,539
Здесь 100 наблюдений за
процессом скользящего среднего.

75
00:05:48,539 --> 00:05:50,430
Здесь ситуация ровно противоположная.

76
00:05:50,430 --> 00:05:56,162
Я вижу, что обычная автокорреляция,
вчерашний y несёт в себе информацию

77
00:05:56,162 --> 00:06:01,100
о сегодняшнем, но позавчерашний y
уже никак не связан с сегодняшним y.

78
00:06:01,100 --> 00:06:05,430
С частной автокорреляцией немножко
по-другому: если я зафиксирую вчерашний y,

79
00:06:05,430 --> 00:06:09,950
то позавчерашний начнёт быть
связанным с сегодняшним.

80
00:06:09,950 --> 00:06:13,322
И, соответственно,

81
00:06:13,322 --> 00:06:17,770
также построим некий
более сложный процесс,

82
00:06:17,770 --> 00:06:22,140
а именно: построим симуляции
для процесса ARMA (1, 1).

83
00:06:22,140 --> 00:06:26,150
Откопируем, соответственно,

84
00:06:26,150 --> 00:06:31,385
эти две строчки и укажем,

85
00:06:31,385 --> 00:06:35,927
что по AR части коэффициент, скажем,

86
00:06:35,927 --> 00:06:43,050
равен 0.5.

87
00:06:43,050 --> 00:06:49,170
И посмотрим на наш ряд.

88
00:06:56,865 --> 00:06:59,302
Ну здесь поведение уже
не такое однозначное.

89
00:06:59,302 --> 00:07:03,925
Видно, что первая автокорреляция и частная
автокорреляция выходят за доверительный

90
00:07:03,925 --> 00:07:06,704
интервал, а дальше все
остальные близки к нулю.

91
00:07:06,704 --> 00:07:10,826
Тут, к сожалению или к счастью,
ARMA-процессы могут демонстрировать

92
00:07:10,826 --> 00:07:14,808
совершенно разное поведение,
но общая суть сохраняется.

93
00:07:14,808 --> 00:07:20,333
Давайте я попробую для
примера взять ARMA-процесс

94
00:07:20,333 --> 00:07:27,185
с одинаковыми знаками: -0.8, -0.5.

95
00:07:27,185 --> 00:07:29,550
И для сравнения посмотрим,
как он выглядит.

96
00:07:29,550 --> 00:07:34,032
Здесь уже совершенно другая структура
частной автокорреляции и автокорреляции,

97
00:07:34,032 --> 00:07:38,635
но, тем не менее, общее свойство
стационарных процессов мы здесь видим: что

98
00:07:38,635 --> 00:07:43,415
и обычная автокорреляция
быстро сходит к нулю,

99
00:07:43,415 --> 00:07:47,155
— то есть вот первое значение отлично
от нуля, слишком сильно отрицательное,

100
00:07:47,155 --> 00:07:50,649
второе слишком сильно положительное,
третье ещё не похоже на ноль,

101
00:07:50,649 --> 00:07:54,786
а дальше уже все похожи на ноль,
— и частная автокорреляция: вот первые

102
00:07:54,786 --> 00:07:57,890
несколько не похожи на ноль,
а дальше все похожи на ноль.

103
00:07:57,890 --> 00:08:01,582
То есть вот она типичная структура
частной автокорреляционной функции и

104
00:08:01,582 --> 00:08:05,965
автокорреляционной функции
для ARMA-процесса: она

105
00:08:05,965 --> 00:08:09,640
быстро должна сходиться к нулю.

106
00:08:09,640 --> 00:08:14,936
И сейчас мы для сравнения посмотрим,

107
00:08:14,936 --> 00:08:24,340
как выглядят аналогичные графики
для нестационарных процессов.

