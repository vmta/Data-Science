Вторая ситуация в перекрёстных выборках,
которая приводит к явлению эндогенности.
Представим себе,
что мы хотим оценить модель в форме
А: yi = β1 + β2xi + β3di + εi.
Ну, скажем, мы хотим понять,
как зарплата зависит от стажа
работы и способостей работника.
И в этой модели мы предполагаем,
что εi никак не связано ни со
стажем работника, ни с его способностями.
То есть мы предполагаем, что Cov(xi,
εi) = 0, Cov(di, εi) = 0.
Ну, конечно,
стаж как-то связан со способностями,
этого мы не исключаем,
поэтому Cov(xi, di) не равна 0.
Но проблема состоит в том, что мы di,
способности, не наблюдаем.
Если стаж, — эти данные мы можем
посмотреть, скажем, в трудовой книжке,
— то величину di мы никак оценить,
ну напрямую она никак явно не оценивается.
Соответственно, в этой ситуации у
нас возникнет не менее правильная,
чем предыдущая форма записи,
другая форма записи Б.
Если я просто в уравнение
модели включу β3di в ошибку,
ну то есть я представлю модель
в виде yi = β1 + β2xi + ui,
и в это ui будет входить
старая ошибка εi и также β3di,
то в этой форме записи модели
у наc будет эндогенность,
а именно: Cov(xi,
ui) = Cov(xi, β3di + εi).
И поскольку есть связь между x и d, то
поэтому эта ковариация не будет равна 0.
Соответственно, если я буду
оценивать эту форму записи с
помощью метода наименьших квадратов,
β2 с крышкой, которое я получу,
оно не будет совпадать с тем β2,
которое я хочу оценить.
И давайте увидим это на простом примере.
Рассмотрим последствия невключения
какого-нибудь регрессора при оценке
модели.
Итак, предположим,
что yi = 2 + 3xi ‒ 2di + εi.
И предположим, что в этой форме записи
модели никакой эндогенности нет.
То есть предполагаем,
что Cov (xi, εi) = 0,
Cov (di, εi) = 0,
ну и также известно про эти
регрессоры x и d, известно,
что дисперсия одного равна
дисперсии другого и пускай,
скажем, равна 9; дисперсия
случайной составляющей
εi равна 1; и Cov(xi,
di) — это регрессора,
между ними корреляция допускается, это
никак не противоречит необходимым условиям
для выполнения хороших статистических
свойств оценок, — минус шести.
Тогда, соответственно,
если я буду применять
метод наименьших квадратов
и оценивать
модель yi равно
β1 с крышкой плюс β2 с крышкой
xi плюс β3 с крышкой di,
то при оценивании такой
модели в силу наших хороших
свойств я получу, что предел по
вероятности β2 с крышкой равен β2.
То есть с увеличением количества
наблюдений, я получу в пределе именно 3.
Однако представим себе теперь,
что оценить такую регрессию я не могу,
потому что di, — по этой переменной
у меня просто нет данных,
— то есть такая идеальная
ситуация невозможна.
Что произойдёт,
если я буду оценивать модель: yi с
крышечкой равняется β1 с
крышечкой плюс β2 с крышечкой xi?
То есть раз просто нет переменной,
ну и, соответственно,
в регрессию её и не включу.
Но в этой ситуации β2 с
крышечкой равно выборочной
ковариации между y и x делить
на выборочную дисперсию x.
И мы уже выясняли,
что по закону больших чисел в пределе,
при n, стремящемся к бесконечности,
мы получаем настоящую ковариацию между
между xi и yi делить на
настоящую дисперсию xi.
Ну давайте подставим.
Ковариация xi,
мы можем подставить вместо
yi выражение для него,
получим: 2 +3xi ‒ 2di + εi,
делённое на дисперсию xi.
xi с
εi не связано,
двойка тоже никак не влияет на ковариацию,
остаётся 3 дисперсии xi
минус 2 помножить на ковариацию
xi и di делить на дисперсию xi.
Или получается: 3
минус 2 помножить на ковариацию xi и di,
деленное на дисперсию xi.
Соответственно, мы получаем,
что даже при большом количестве наблюдений
оценка методом наименьших квадратов
вовсе не стремится к тройке,
вот этому числу перед xi, а стремится
к другому числу, ну в данном случае,
при данной дисперсии и данной ковариации,
у нас получается 3 минус 2
помножить на минус 6, делённое на 9.
И получается 3 плюс 4,
ну сокращаем на 3,
получаем 3 плюс 4/3, получается 4 и 1/3.
То есть мы видим,
что в данном случае при большом количестве
наблюдений метод наименьших квадратов
будет завышать нам значение β2 в
этой форме представления модели.
И снова небольшой итог решения задачи.
Мы хотим оценить модель yi = β1 + β2xi +
β3di + εi, но не наблюдаем регрессор di.
То есть что мы хотим получить?
Мы хотим получить коэффициент β2,
который по смыслу что показывает?
Он по смыслу показывает,
насколько в среднем растёт yi при росте
xi на единичку и при фиксированном di.
Ну то есть если у нас xi — это стаж,
то мы смотрим, насколько растёт
зарплата при росте стажа там на один год и
при фиксированных способностях работника.
Однако если мы просто будем с помощью
метода наименьших квадратов оценивать
модель без пропущенного регрессора,
а пропускать мы его вынужденны,
потому что у нас его просто нет,
то мы получим оценки методом наименьших
квадратов в модели yi с крышкой равно
β1 с крышкой плюс β2 с крышкой на xi.
И вот это β2 с крышкой,
полученное методом наименьших квадратов,
оно не будет похоже на настоящее β2
даже при большом количестве наблюдений,
а именно: по смыслу β2 с крышкой будет
показывать, насколько в среднем растёт yi,
если сравнить двух
работников с разным стажем.
Но у работников с разным
стажем у среднестатистических,
у них в среднем разные способности из-за
того, что стаж связан со способностями.
И получается, что эта оценка методом
наименьших квадратов оказывается
смещённой и несостоятельной,
то есть не совсем то, что нас интересует.

