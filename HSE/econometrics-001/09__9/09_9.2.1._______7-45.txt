Перейдем к компьютерной
части 9-той недели.
Запуская R-studio,
открываем файл с заготовленной загрузкой
пакетов, lab_09_before_R,
выделяем все и запускам, то есть мы
активируем необходимые нам пакеты.
Первое, с чего я хочу начать
— это еще раз подчеркнуть
что эндогенность не имеет никакого
отношения к прогнозированию.
Если мы хотим прогнозировать,
если наша задача прогнозировать,
то нам абсолютно не важна форма
записи моделей с эндогенностью,
и поэтому мы всегда можем предполагать
при прогнозировании что наши
регрессоры не коррелированы
со случайными ошибками.
Ну и давайте покажем, что нам может
быть важно при прогнозировании.
На самом деле при прогнозировании
важно только одно — хорошие прогнозы.
Ни значимость, ни вопросы
эндогенности мы никогда не касаемся.
Давайте для примера загрузим в набор
данных h, да, убедимся, что мы находимся
в нужной папке, установим Set Working
Directory To Source File Location.
Соответственно, загрузим в наши,
в набор данных h данные по
стоимости квартир в Москве,
укажем, что в этих данных есть заголовок,
разделитель между наблюдениями,
табуляция, десятичный разделитель,
точка.
Загрузили данные,
бросили взгляд на данные, чтобы убедиться,
что они корректно загрузились.
И теперь при прогнозировании
надо говорить всегда,
что когда мы оцениваем качество прогнозов,
нам важно честное качество прогнозов,
то есть я должен оценить модель по одной
части выборки, спрогнозировать другую
часть выборки и посмотреть качество
прогнозов на другой части выборки.
Потому что если я оцениваю качество
прогнозов по той части выборки,
по какой я оцениваю модель,
то я могу добиться идеального попадания,
включив достаточное
количество регрессоров.
Поэтому первый шаг при честном
прогнозировании, при оценке честной
качества прогнозов — это разделить выборку
на две части: обучающую и тестовую.
Ну, соответственно,
давайте мы попросим компьютер случайно
поделить наши наблюдения на две
части: обучающую и тестовую.
И, соответственно, номера наблюдений,
давайте их назовем
in_train — это будут номера наблюдений,
которые относятся к обучающей
части выборки, соответственно,
я возьму команду из пакета
carrot createDataPartition,
она длинная, но я нажал Tab,
посмотрел как она называется.
И здесь надо указать зависимую переменную,
зависимая переменная пусть у нас будет из
набора данных мы возьмем цену квартиры.
Надо указать сколько наблюдений
мы относим к обучающей выборке,
то есть по которой мы будем оценивать
модель, ну давайте 75 %, 0.75
отнесем к обучающей части выборки,
а по 25 % выборки будем тестировать.
И тут надо еще указать такую
опцию для удобства list=FALSE.
Соответственно, что такое in_train?
Ну можно посмотреть на этот in_train,
на самом деле это просто номера случайно
отобранных наблюдений,
по которым мы будем оценивать регрессию.
Соответственно, h_train
— то есть это та часть,
по которой мы оценивам модель методом МНК.
Это мы из набора данных возьмем номера,
которые входят в вектор in_train,
ну и, соответственно, все столбики,
а h_test — это будет вторая
часть выборки, по ней мы будем
оценивать качество прогнозов.
Соответственно, те наблюдения, которые
попали в обучающую часть выборки их не
надо брать, остальные надо взять, поэтому
здесь перед индексом стоит значок минус.
Ну, соответственно, если посмотреть
вот количество строк в наборе данных
h — это 2040, количество строк
в наборе данных h_train — это
1533 и остальные отнесены к тестовой части
nrow(h_test) 507,
если сложить, получится 2040.
Соответственно, я могу оценить две модели.
Давайте оценим model_1 —
это линейная модель по
данным из набора данных
h_train вот это важно,
не исходный набор данных, а кусочек его,
и любая формула, например,
логарифм цены как он зависит от логарифма
общей площади, логарифма площади кухни,
логарифма жилой площади.
Оценил одну модель,
пропустил буковку e — livespend,
чуть-чуть подвинем.
Оцениваем model_2,
ну давайте совершенно другую модель-2,
данные мы берем из обучающей
выборки и логарифм цены,
строим регрессию на логарифм общей
площади плюс кирпичность дома.
И теперь я спрогнозирую
на тестовую часть выборки и посмотрю
как эти две модели, то есть я даже не
гляжу на значимость коэффициентов,
если моя задача прогнозировать.
Во-первых, y — это будет
из тестовой части выборки
надо взять price и
взять логарифм,
соответственно, вот можем посмотреть
на наш y какие значения он принимает.
Можем спрогнозировать по первой модели
predict модель
мы используем model_1,
а данные мы используем уже h_test.
Ну давайте посмотрим на
прогнозы по модели-1.
Вот прогнозы по модели-1.
И точно так же можно
спрогнозировать по модели-2,
model_2.
И ну простейший критерий качества —
сумма квадратов ошибок прогнозов,
я возьму сумму квадратов
и здесь внутри надо
посчитать ошибки прогнозов (y – y_hat_1)
— это сумма квадратов ошибок
прогнозов по первой модели,
а сумма квадратов ошибок
прогнозов по второй модели
— она оказывается чуть-чуть меньше.
Соответственно, вот несмотря на то,
что во второй модели меньше переменных,
она вне обучающей выборки
оказывается прогнозирует лучше.
И сейчас мы перейдем к теме интерпретации,
то есть к эндогенности.

