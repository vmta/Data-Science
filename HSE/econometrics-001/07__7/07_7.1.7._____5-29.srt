1
00:00:13,270 --> 00:00:18,272
Как мы уже сказали, логит-

2
00:00:18,272 --> 00:00:22,420
и пробит-модели оцениваются с помощью
метода максимального правдоподобия.

3
00:00:22,420 --> 00:00:28,282
Итак, у нас есть наблюдения, например
y_1 = 1, y_2 = 0, есть логит-модель.

4
00:00:28,282 --> 00:00:30,490
Соответственно, у нас есть
функция правдоподобия,

5
00:00:30,490 --> 00:00:32,320
то есть вероятность получить нашу выборку.

6
00:00:32,320 --> 00:00:36,788
Поскольку мы предполагаем, наблюдения
независимы, то вероятность получения нашей

7
00:00:36,788 --> 00:00:42,720
выборки равна произведению вероятностей:
P(y_1 = 1) * P(y_2 = 0) * ...

8
00:00:42,720 --> 00:00:50,150
К сожалению, в явном виде задача не
решается, то есть несмотря на то,

9
00:00:50,150 --> 00:00:55,831
что можно выписать функцию правдоподобия,
можно взять её производные аналитически,

10
00:00:55,831 --> 00:00:59,223
— решить получающееся уравнение
аналитически не получается.

11
00:00:59,223 --> 00:01:03,844
Поэтому мы будем использовать численные
способы решения этой задачи в R.

12
00:01:03,844 --> 00:01:07,451
Получаемые коэффициенты β₁ с крышкой,
β₂ с крышкой,

13
00:01:07,451 --> 00:01:10,490
к сожалению, плохо интерпретируемы,
потому что они показывают,

14
00:01:10,490 --> 00:01:16,615
насколько меняется скрытая переменная
при изменении x на единичку.

15
00:01:16,615 --> 00:01:23,510
А смысл этой скрытой переменной,
к сожалению, очень редко бывает очевиден.

16
00:01:23,510 --> 00:01:29,800
Поэтому вместо этого в логит- и
пробит-моделях считают предельные эффекты,

17
00:01:29,800 --> 00:01:36,810
то есть на сколько увеличится вероятность
того, что y = 1, с ростом x на единицу.

18
00:01:36,810 --> 00:01:40,193
Соответственно, поскольку
вероятность того, что y = 1,

19
00:01:40,193 --> 00:01:45,187
— это функция распределения, мы берём
производную от функции распределения по x

20
00:01:45,187 --> 00:01:50,620
и получаем β₂ умножить на функцию
плотности в точке (β₁ + β₂x).

21
00:01:50,620 --> 00:01:55,282
Как мы видим,
этот предельные эффект в отличие от

22
00:01:55,282 --> 00:02:00,659
МНК-моделей зависит от x,
то есть вероятность того,

23
00:02:00,659 --> 00:02:05,948
то есть реакция вероятности на
изменение объясняющей переменной,

24
00:02:05,948 --> 00:02:11,479
— она разная для разных наблюдений: для
одного наблюдения она может быть больше,

25
00:02:11,479 --> 00:02:14,535
для другого меньше,
тем не менее знак одинаковый.

26
00:02:14,535 --> 00:02:20,029
Поскольку функция плотности всегда
положительна, то знак предельного эффекта

27
00:02:20,029 --> 00:02:24,940
определяется знаком переменной β₂,
коэффициента β₂.

28
00:02:24,940 --> 00:02:29,462
Существует два популярных
средних предельных эффекта,

29
00:02:29,462 --> 00:02:33,181
которые рассчитывают в разных
статистических пакетах.

30
00:02:33,181 --> 00:02:36,906
Есть средний предельный эффект
по наблюдениям, это означает,

31
00:02:36,906 --> 00:02:41,134
что мы считаем предельный эффект
для каждого наблюдения, смотрим,

32
00:02:41,134 --> 00:02:44,986
на сколько увеличится вероятность для
первого наблюдения быть равным единичке,

33
00:02:44,986 --> 00:02:47,065
если мы увеличим x на единичку, смотрим,

34
00:02:47,065 --> 00:02:51,203
насколько увеличится вероятность для
второго наблюдения быть равным единичке,

35
00:02:51,203 --> 00:02:54,980
если мы x увеличим на единичку,
и потом мы усредняем по всем наблюдениям.

36
00:02:54,980 --> 00:02:59,207
И второй подход: рассмотрим некое
среднестатистическое наблюдение,

37
00:02:59,207 --> 00:03:04,260
то есть рассмотрим x, равный x среднему,
и посчитаем для него предельный эффект.

38
00:03:04,260 --> 00:03:07,970
Эти предельные эффекты,
как правило, чуть-чуть отличаются.

39
00:03:07,970 --> 00:03:11,987
С помощью логит-моделей можно не только
рассчитывать предельные эффекты, то есть

40
00:03:11,987 --> 00:03:17,020
насколько увеличится вероятность того, что
y = 1 при росте x, но и прогнозировать,

41
00:03:17,020 --> 00:03:22,650
собственно, эту самую вероятность того,
что y_i = 1.

42
00:03:22,650 --> 00:03:27,995
Для этого сначала мы спрогнозируем скрытую
переменную, получим y*f с крышкой.

43
00:03:27,995 --> 00:03:31,560
Нижний индекс f обозначает,
что это прогноз.

44
00:03:31,560 --> 00:03:37,070
Получив точечный прогноз y*,

45
00:03:37,070 --> 00:03:42,956
мы можем,
используя логистическую функцию F от y*,

46
00:03:42,956 --> 00:03:45,800
получить прогноз вероятности.

47
00:03:45,800 --> 00:03:51,500
Ну а поскольку мы знаем,
что y* с крышкой — это случайная величина,

48
00:03:51,500 --> 00:03:55,842
потому что случайными величинами
являются β₁ с крышкой и β₂ с крышкой,

49
00:03:55,842 --> 00:04:01,962
— мы можем посчитать для неё доверительный
интервал и, применив функцию F к границам

50
00:04:01,962 --> 00:04:06,680
этого доверительного интервала, получить
доверительный интервал для вероятности.

51
00:04:06,680 --> 00:04:11,125
На практике разница между логит-
и пробит-моделями оказывается

52
00:04:11,125 --> 00:04:12,059
несущественной.

53
00:04:12,059 --> 00:04:15,570
Несмотря на то, что коэффициенты
отличаются примерно в 1.6 раза,

54
00:04:15,570 --> 00:04:19,210
отличие в прогнозах и в
предельных эффектах минимальное.

55
00:04:19,210 --> 00:04:22,090
Разница в 1.6 раза вызвана тем,

56
00:04:22,090 --> 00:04:27,030
что логит можно примерно
представить себе как модель,

57
00:04:27,030 --> 00:04:34,369
где скрытая переменная 
y*i = β₁ + β₂ x_i плюс нормальное распределение

58
00:04:34,369 --> 00:04:39,624
с математическим ожиданием ноль и
дисперсией, равной 1.6 в квадрате.

59
00:04:39,624 --> 00:04:44,250
Поделив уравнение для ненаблюдаемой
скрытой переменной на 1.6,

60
00:04:44,250 --> 00:04:48,795
я получу уравнение: 

61
00:04:48,795 --> 00:04:53,577
y_i*/1.6 = β₁/1.6 + β₂/1.6 x_i плюс

62
00:04:53,577 --> 00:04:57,730
нормальное стандартное распределение,
— что соответствует пробит-модели.

63
00:04:57,730 --> 00:04:59,783
И, действительно, мы видим,

64
00:04:59,783 --> 00:05:04,430
что β₁ в пробит-модели соотносится
с β₁/1.6 из логит-модели.

65
00:05:04,430 --> 00:05:10,480
А поскольку для определения
истинного значения y,

66
00:05:10,480 --> 00:05:15,730
0 или 1, важно только сравнение
скрытой переменной с нулём,

67
00:05:15,730 --> 00:05:19,910
то условие, что y_i*/1.6 > 0

68
00:05:19,910 --> 00:05:25,170
полностью совпадает с условием,
что y_i* > 0.

