Логит и пробит-модели, единственная
проблема от которой они страдают — это то,
что в некоторых случаях оценки метода
максимального правдоподобия не существуют.
Мы рассмотрим простой пример, когда
складывается такая неприятная ситуация.
У нас есть наблюдение: y_1 = 0,
y_2 = 0, и y_3 = 1.
Это наблюдение за нашей
бинарной переменной.
И мы пытаемся ее объяснить с
помощью некоторой объясняющей
переменной x_1 = 1, x_2 = 2, x_3 = 3.
Я напомню, что мы оцениваем логит-модель,
то есть мы предполагаем, что y_i = 1 или 0.
Единичке, если скрытая переменная y со
звездочкой больше, либо равна нулю.
И нулю, если скрытая переменная
y со звездочкой меньше 0.
А это самое y_i* = 
β₁ + β₂ x_i + ε_i,
имеющая логистическое распределение.
Как мы с вами установили,
вероятность того,
что y_i = 1 равна 1,
деленное на 1 + экспонента β₁ + β₂ x_i.
Давайте изобразим
графически нашу ситуацию.
У нас будет два графика.
Верхний — это будет график
функции распределения.
Здесь мы будет откладывать
значения β₁ + β₂ x.
А по вертикали, соответственно,
будет откладываться
от 0 до 1 вероятность того, что y_i = 1.
На нижнем графике, вот здесь нижний
график будет немножко нетрадиционный.
Мы x отложим по вертикали.
По вертикали будет отложено значение x.
А по горизонтали, чтобы графики совпадали,
будет отложено β₁ + β₂, умножить на x.
Соответственно, у нас иксы — это 1,
2 и 3.
Если мы зафиксируем значения β₁ и β₂,
возьмем какие-нибудь
конкретные значения β₁ и β₂,
зависимость β₁ + β₂ x — линейная.
Давайте мы назовем этот параметр а.
Здесь будет а, здесь а и здесь а.
Зависимость а от x линейная,
ее можно изобразить какой-то прямой.
Давайте я нарисую какую-нибудь прямую.
То есть, выбрав β₁ и β₂,
я каждому x могу
соответственно сопоставить β₁
+ β₂ умножить на x_1.
β₁ + β₂ умножить на x_2.
И β₁
+ β₂ умножить на x_3.
Подняв горизонтальные
координаты трех точек
на верхний график,
я получу те же три значения.
Теперь я дополню верхний график, я нарисую
там вот эту функцию распределения.
То есть здесь на графике я нарисую F(а).
Функция распределения,
она имеет следующий вид: 1
делить на 1 + е в степени,
+ экспонента от (-а).
Ой, вот здесь я потерял минус в формуле.
Соответственно, график имеет
следующий вид: функция
является возрастающей от 0
до 1.
И отметим на… мы знаем,
что первый игрек у нас равен 0.
Вероятность того,
что y равен 0 отмеряется сверху.
Вот это у нас — вероятность того,
что y_1 = 0.
Вот это у нас — вероятность того,
что y_2 = 0.
И вот эта вероятность снизу,
это вероятность того, что y_3 = 1.
Соответственно, значения
функции правдоподобия,
а именно вероятность того, что y_1 = 0,
y_2 = 0, и y_3 = 1, в силу независимости
наблюдений, это есть
произведение вероятностей.
Вероятность того, что y_1 = 0,
помножить на вероятность того,
что y_2 = 0, помножить на вероятность того,
что y_3 = 1.
Соответственно, значение
функции правдоподобия — есть
произведение трех длин отрезков.
Вероятность того, что y = 0,
помножить на вероятность того,
что y_2 = 0, помножить на вероятность того,
что y_3 = 1.
Меняя, подбирая β₁ и β₂,
то есть меняя наклон этой прямой,
я меняю значения β₁ + β₂ х_1,
β₁ + β₂ х_2 и β₁ + β₂ х_3.
Меняются расположения трех
точек на горизонтальной оси.
И соответственно меняются длины отрезков.
И меняется результирующее произведение.
Я напомню, что мы хотим
максимизировать это произведение,
подбирая параметры β₁ и β₂.
То есть мы хотим сделать это
произведение максимально возможным.
И на этом графике становится понятно,
что экстремум не существует,
потому что я могу так двигать прямую,
что точка,
соответствующая третьему наблюдению,
уйдет далеко вправо.
И длина отрезка, вероятность того,
что y_3 = 1, будет стремиться к 1.
А точки, которые соответствуют первому
и второму наблюдению, уйдут влево.
И, соответственно, вероятности того,
что y_1 = 0 и y_2 = 0,
тоже будут стремиться к 1.
Этого можно добиться,
выбрав прямую с очень, очень,
очень, очень пологим наклоном.
Вот если я вместо нарисованной
мной в первый раз
прямой возьму прямую с более
пологим наклоном, вот такую вот,
давайте я ее отмечу как-то по-другому,
это альтернативные значения β₁ + β₂.
Соответственно, при таких
альтернативных значениях точки первого,
второго и третьего наблюдения.
Третье наблюдение попадет
существенно правее, третий штрих.
А точки, соответствующие первому
и второму наблюдению — два штрих,
а один штрих даже вылазит за рисунок.
Один штрих.
Точки, соответствующие первому и второму
наблюдению будут лежать существенно левей.
Соответственно, вероятности того,
что y_1 = 0, y_2 = 0,
возрастут, и вероятность того,
что y_3 = 1, тоже возрастет.
Но поскольку никаких ограничений
на наклон прямой у меня нет,
я могу сделать наклон прямой сколь
угодно маленьким, то и, соответственно,
экстремум этого произведения, произведения
длин трех отрезков будет недостижим.
Следовательно, вот в таком простом примере
с тремя наблюдениями и одним регрессором,
случай очень простой — три наблюдения,
один регрессор,
уже оказалось, что бывает такое,
что оценки метода максимального
правдоподобия в
логит-модели не существует.
Заметим, что с существенной,
содержательной точки зрения,
этот случай очень простой.
Это задача, на самом деле,
здесь легко идеально прогнозировать.
Тут можно построить правило гораздо проще,
чем логит-модель,
которая звучит: если х2 > 2.5,
значит y_3 = 1,
и это правило дает нам идеальные прогнозы.
Оказывается, в ситуации,
когда возможно идеальное прогнозирование,
оценки логит- и пробит- модели не
существуют, как показывает этот пример.
Указанная нами проблема логит-
и пробит- моделей, как правило,
она возникает при большом
количестве дамми-переменных,
то есть переменных типа 0 или 1,
используемых в качестве регрессоров.
Признаком является то,
что метод максимального правдоподобия,
задача оптимизации, не сходится.
R, как правило, выводит сообщение: fitted
probabilities numerically 0 or 1 occurred.
Соответственно, решением ее является
либо регуляризация, либо использование
байесовского подхода, которые лежат
за пределами нашего вводного курса.
В сегодняшней лекции мы рассмотрели
метод максимального правдоподобия,
а также применили его к
логит- и пробит-моделям.
Логит- и пробит-модели предназначены
для моделирования зависимой переменной,
которая принимает бинарные значения,
то есть 0 или 1.
В этой ситуации, если использовать метод
наименьших квадратов, то можно получить
прогнозируемые вероятности больше 1 или
меньше 0, что, конечно, не есть хорошо.
В следующий раз мы применим метод
максимального правдоподобия к оценке
модели временных рядов.

