1
00:00:13,540 --> 00:00:18,276
Одним из способов борьбы с
мультиколлинеарностью является

2
00:00:18,276 --> 00:00:21,350
оценка ридж- или LASSO-регрессии.

3
00:00:21,350 --> 00:00:27,260
Перейдем к оценке ридж и LASSO-регрессии.

4
00:00:27,260 --> 00:00:32,160
Ридж и

5
00:00:32,160 --> 00:00:36,150
LASSO.

6
00:00:36,150 --> 00:00:41,830
Для этой регрессии требуется отдельно
получить регрессоры в отдельную

7
00:00:41,830 --> 00:00:46,090
матрицу и в один вектор отдельный
зависимую объясняемую переменную.

8
00:00:46,090 --> 00:00:52,559
Соответственно, y — это будет
объясняемая переменная.

9
00:00:52,559 --> 00:00:58,058
Из набора данных h мы достаем переменную
dist, а матрица х0 у нас уже есть.

10
00:00:58,058 --> 00:01:02,952
Но, давайте я для ясности скопирую ее код.

11
00:01:02,952 --> 00:01:08,952
Это наша матрица объясняющих переменных,

12
00:01:08,952 --> 00:01:11,585
то бишь регрессоров.

13
00:01:11,585 --> 00:01:15,880
И, соответственно, давайте сначала оценим

14
00:01:15,880 --> 00:01:23,160
LASSO.

15
00:01:23,160 --> 00:01:29,322
m_lasso равняется glmnet,
команда, которая оценивает LASSO,

16
00:01:29,322 --> 00:01:33,056
ридж-регрессию и регрессию
эластичной сети.

17
00:01:33,056 --> 00:01:35,803
Регрессоры берутся из матрицы х0.

18
00:01:35,803 --> 00:01:39,380
Зависимая переменная лежит в y.

19
00:01:39,380 --> 00:01:43,292
Alpha — это переменная,
которая определяет, собственно,

20
00:01:43,292 --> 00:01:47,324
какой тип в регуляризации LASSO,
ридж будет использоваться.

21
00:01:47,324 --> 00:01:50,320
LASSO соответствует
alpha равному единичке.

22
00:01:50,320 --> 00:01:54,296
И дальше надо задать вектор
потенциальных лямбд.

23
00:01:54,296 --> 00:01:59,704
Давайте зададим сначала вектор лямбд,
это коэффициенты,

24
00:01:59,704 --> 00:02:08,100
с которыми у нас в RSS входит штраф за
большой размер коэффициента β с крышкой.

25
00:02:08,100 --> 00:02:12,660
То есть введем вектор лямбда,
lambdas, это будут разные лямбды.

26
00:02:12,660 --> 00:02:14,900
Это будет последовательность.

27
00:02:14,900 --> 00:02:17,710
Вот здесь единственный принципиальный
момент, последовательность

28
00:02:17,710 --> 00:02:21,639
надо указывать от большего лямбда к
меньшему, чтобы работала функции glmnet.

29
00:02:21,639 --> 00:02:28,820
Ну, пусть будет, скажем,
lambda от 50 до 1 с шагом в...

30
00:02:28,820 --> 00:02:32,834
давайте даже до 0,1,

31
00:02:32,834 --> 00:02:38,425
и пусть будет там длина 30 разных лямбд.

32
00:02:38,425 --> 00:02:42,881
Соответственно, мы создали
вектор разных лямбд,

33
00:02:42,881 --> 00:02:46,151
которые будут использоваться
в алгоритме LASSO и ридж.

34
00:02:46,151 --> 00:02:49,003
Здесь мы указываем наши lambdas.

35
00:02:49,003 --> 00:02:54,610
Итак, компьютер оценил модель LASSO.

36
00:02:54,610 --> 00:02:58,664
Теперь мы можем построить
ряд интересных графиков,

37
00:02:58,664 --> 00:03:04,520
которые нам позволяют визуализировать
результаты оценивания лассо-регрессии.

38
00:03:04,520 --> 00:03:09,380
Во-первых, plot, модель lasso,

39
00:03:09,380 --> 00:03:15,252
по горизонтали отложим,
собственно, лямбду.

40
00:03:15,252 --> 00:03:19,460
И давайте добавим на график отметки.

41
00:03:19,460 --> 00:03:22,650
Посмотрим, что получится.

42
00:03:22,650 --> 00:03:25,401
Перед нами следующий график.

43
00:03:25,401 --> 00:03:29,064
У нас в модели имеется
коэффициент перед скоростью,

44
00:03:29,064 --> 00:03:32,445
перед скоростью в квадрате,
перед скоростью в кубе.

45
00:03:32,445 --> 00:03:38,320
И, соответственно, по горизонтали здесь
на графике отложим логарифм лямбды,

46
00:03:38,320 --> 00:03:41,440
а по вертикали отложим
размер коэффициента.

47
00:03:41,440 --> 00:03:48,625
Вот единичка… Единичка — это
размер первого коэффициента.

48
00:03:48,625 --> 00:03:52,173
Двоечка и троечка, здесь они сливаются,
коэффициенты практически равны нулю.

49
00:03:52,173 --> 00:03:54,150
Это размер второго и
третьего коэффициента.

50
00:03:54,150 --> 00:03:54,770
Что мы видим?

51
00:03:54,770 --> 00:03:57,836
Соответственно, если
lambda очень маленький,

52
00:03:57,836 --> 00:04:03,058
то есть маленький минус 2 логарифм lambda
— это означает очень маленький lambda.

53
00:04:03,058 --> 00:04:06,538
Это означает,
что практически мы имеем МНК оценки,

54
00:04:06,538 --> 00:04:10,110
то есть никакого штрафа за
размер β c крышкой у нас нет.

55
00:04:10,110 --> 00:04:13,939
Соответственно, здесь у нас первый
коэффициент равен 2 с небольшим,

56
00:04:13,939 --> 00:04:15,330
а остальные два равны 0.

57
00:04:15,330 --> 00:04:20,570
Однако, если мы увеличиваем lambda,
то при большом размере штрафа,

58
00:04:20,570 --> 00:04:24,970
при размере штрафа около,
соответственно, Е.

59
00:04:24,970 --> 00:04:27,503
Ну то есть логарифм около одного,
соответственно,

60
00:04:27,503 --> 00:04:29,370
сам коэффициент штрафа около 2,7.

61
00:04:29,370 --> 00:04:32,539
Резко падает первый коэффициент,

62
00:04:32,539 --> 00:04:38,460
ну и потихоньку при огромном-огромном
размере штрафа все коэффициенты равны 0.

63
00:04:38,460 --> 00:04:43,420
Соответственно, у нас получается некая
содержательная первая интерпретация.

64
00:04:43,420 --> 00:04:47,057
Как зависит от lambda размер
каждого коэффициента,

65
00:04:47,057 --> 00:04:49,410
величина каждого коэффициента.

66
00:04:49,410 --> 00:04:54,841
Вторая картинка,
которую мы можем здесь смотреть.

67
00:04:54,841 --> 00:05:00,304
Чуть-чуть другой график,
по горизонтали можно

68
00:05:00,304 --> 00:05:05,660
отложить долю объясненной

69
00:05:05,660 --> 00:05:12,050
дисперсии.

70
00:05:12,050 --> 00:05:18,440
Соответственно, здесь мы на графике видим,

71
00:05:18,440 --> 00:05:23,460
что чем меньше размер,

72
00:05:23,460 --> 00:05:26,980
чем меньше коэффициент штрафной lambda,

73
00:05:26,980 --> 00:05:33,230
тем больше дисперсий разброса объясняемой
переменной Y мы можем объяснить.

74
00:05:33,230 --> 00:05:37,932
Соответственно, если я хочу объяснить
очень, ну практически максимум,

75
00:05:37,932 --> 00:05:42,143
который может объяснить метод наименьших
квадратов разброса, то мне надо взять

76
00:05:42,143 --> 00:05:46,193
первый коэффициент, равный чуть больше 2,
ну и остальные около 0.

77
00:05:46,193 --> 00:05:50,874
Однако, если я согласен пожертвовать
небольшим количеством...

78
00:05:50,874 --> 00:05:55,120
смотрите, я жертвую совсем небольшим
процентом объясненной дисперсии.

79
00:05:55,120 --> 00:05:58,890
То есть где-то от, ну, наверное, 0,67.

80
00:05:58,890 --> 00:06:04,020
Если я снижу желаемую долю
объясненной дисперсии до 0,63,

81
00:06:04,020 --> 00:06:06,299
то коэффициент резко падает.

82
00:06:06,299 --> 00:06:09,200
Коэффициент резко приближается к 0.

83
00:06:09,200 --> 00:06:11,974
То есть, приблизив резко коэффициент к 0,

84
00:06:11,974 --> 00:06:16,070
вот такое вертикальное падение
в процентах, оно очень большое,

85
00:06:16,070 --> 00:06:22,031
я получу всего лишь небольшую жертву в
виде потери доли объясненной дисперсии.

86
00:06:22,031 --> 00:06:26,926
Соответственно, имеет смысл, если я хочу,
чтобы коэффициенты были небольшие,

87
00:06:26,926 --> 00:06:31,369
с небольшой дисперсией, соответственно,
можно чуть-чуть пожертвовать долей

88
00:06:31,369 --> 00:06:34,962
объясненной дисперсии
зависимой переменной.

89
00:06:34,962 --> 00:06:43,620
И еще один график — можно
разложить штраф на составляющие.

90
00:06:43,620 --> 00:06:48,870
То есть по горизонтали можно
отложить норму вектора.

91
00:06:54,505 --> 00:07:01,102
Здесь по горизонтали отложена,

92
00:07:01,102 --> 00:07:06,737
собственно, величина штрафа,
то есть это сумма модулей β с крышкой.

93
00:07:06,737 --> 00:07:11,500
Модуль β_1 с крышкой + модуль β_2
с крышкой + модуль β_3 с крышкой.

94
00:07:11,500 --> 00:07:16,120
То есть это суммарный вклад в штраф,
который вносят все β.

95
00:07:16,120 --> 00:07:19,556
А здесь он разложен по
вертикали по коэффициентам.

96
00:07:19,556 --> 00:07:23,592
И мы видим, что первый коэффициент,
он, собственно,

97
00:07:23,592 --> 00:07:28,176
практически полностью
определяет нам величину штрафа.

98
00:07:28,176 --> 00:07:34,380
Чем больше совокупная сумма модулей β_1 с
крышкой + β_2 с крышкой + β_3 с крышкой,

99
00:07:34,380 --> 00:07:38,980
тем больше первый коэффициент,
а два остальных колеблются около 0.

100
00:07:38,980 --> 00:07:44,396
Соответственно, можно посмотреть
на сами коэффициенты.

101
00:07:44,396 --> 00:07:47,119
Ну, давайте выберем, например,

102
00:07:47,119 --> 00:07:52,844
коэффициенты модели m_lasso и

103
00:07:52,844 --> 00:07:58,484
укажем конкретное значение lambda,
например,

104
00:07:58,484 --> 00:08:04,450
возьмем lambda равное 0,1

105
00:08:04,450 --> 00:08:11,365
и lambda равное 1.

106
00:08:11,365 --> 00:08:16,066
Соответственно, я показал как выглядят
оценки lasso, коэффициентов в

107
00:08:16,066 --> 00:08:22,154
LASSO-регрессии для двух разных лямбд, для
lambda равного 0,1 и для lambda равного 1.

108
00:08:22,154 --> 00:08:28,376
Вот здесь видно, что коэффициент при
квадрате скорости точно попал в ноль.

109
00:08:28,376 --> 00:08:33,650
А остальные коэффициенты не нули.

