1
00:00:13,250 --> 00:00:19,255
Подведем итог и пополним
список хороших свойств,

2
00:00:19,255 --> 00:00:23,240
большой список хороших свойств,
которыми обладают наши коэффициенты.

3
00:00:23,240 --> 00:00:28,540
Если выполнен ряд предпосылок,
а именно истинная зависимость

4
00:00:28,540 --> 00:00:34,740
имеет линейный вид 
y_i = β₁ + β₂ x_i + β_3 z_i + ε_i.

5
00:00:34,740 --> 00:00:37,796
В матричном виде: y = xβ + ε.

6
00:00:37,796 --> 00:00:42,861
Если мы оцениваем эту же модель с
помощью метода наименьших квадратов,

7
00:00:42,861 --> 00:00:47,408
то есть мы, действительно, строим
регрессию у на константу и те переменных,

8
00:00:47,408 --> 00:00:48,830
от которых он зависит.

9
00:00:48,830 --> 00:00:54,120
В матричном виде это приведет к
оценке β с крышкой = (Х'X)^(-1) X'y.

10
00:00:54,120 --> 00:00:59,410
Если наблюдений больше,
чем оцениваемых коэффициентов,

11
00:00:59,410 --> 00:01:04,383
если имеет место строгая экзогенность,
то есть математическое ожидание от

12
00:01:04,383 --> 00:01:09,020
случайной ошибки ε_i при фиксированных
регрессорах равно нулю.

13
00:01:09,020 --> 00:01:14,089
Если имеет место условная
гомоскедастичность, то есть математическое

14
00:01:14,089 --> 00:01:18,629
ожидание от ε_i в квадрате при
фиксированных регрессорах равно σ квадрат,

15
00:01:18,629 --> 00:01:24,410
или, что тоже самое, что дисперсия ε_i при
фиксированных регрессорах равна σ квадрат.

16
00:01:24,410 --> 00:01:29,275
Если имеет место условная
некоррелированность случайных ошибок,

17
00:01:29,275 --> 00:01:33,055
корреляция ε_i, ε_j при фиксированном X 
равна нулю,

18
00:01:33,055 --> 00:01:37,935
а так же выполнены предпосылки на
регрессоры, а именно отдельные

19
00:01:37,935 --> 00:01:43,420
наблюдения являются случайной выборкой
из некоего большого набора объектов.

20
00:01:43,420 --> 00:01:47,853
То есть регрессоры, относящиеся к
разным наблюдениям, независимы,

21
00:01:47,853 --> 00:01:52,470
и вместе с тем разные наблюдения имеют
одинаковые законы распределения.

22
00:01:52,470 --> 00:01:56,528
И кроме того, последняя предпосылка,

23
00:01:56,528 --> 00:02:01,072
что с вероятностью 1 среди объясняющих
переменных, среди регрессоров,

24
00:02:01,072 --> 00:02:06,810
отсутствует линейная зависимость,
то у нас есть ряд свойств.

25
00:02:06,810 --> 00:02:09,757
Базовые свойства никак не меняются,

26
00:02:09,757 --> 00:02:15,399
а вот теперь мы можем проверять гипотезу
о нескольких линейных ограничения сразу.

27
00:02:15,399 --> 00:02:19,160
То есть у нас в асимптотических
свойствах появляется одно новое.

28
00:02:19,160 --> 00:02:24,665
А именно: χ² – статистика,
рассчитываемая по формуле 

29
00:02:24,665 --> 00:02:30,586
(RSS_R - RSS_UR), деленное на 
RSS_UR, деленное на (n - k),

30
00:02:30,586 --> 00:02:35,204
эта величина стремится к χ² - распределению 
с r степенями свободы.

31
00:02:35,204 --> 00:02:38,880
r — это количество предполагаемых
ограничений верных.

32
00:02:38,880 --> 00:02:42,513
Это свойство добавляется
к старым свойствам.

33
00:02:42,513 --> 00:02:49,300
То, что β_j стремится по вероятности, β_j 
с крышкой стремится по вероятности к β_j,

34
00:02:49,300 --> 00:02:54,544
что дробь (β_j с крышкой минус β_j) делить
на соответствующую стандартную ошибку,

35
00:02:54,544 --> 00:02:57,539
имеет асимптотически
нормальное распределение,

36
00:02:57,539 --> 00:03:01,700
и σ квадрат с крышкой является
состоятельной оценкой для σ квадрат.

37
00:03:01,700 --> 00:03:06,443
И точно также добавляется
соответствующее новое свойство,

38
00:03:06,443 --> 00:03:09,819
тоже хорошее свойство при нормальности ε_i.

39
00:03:09,819 --> 00:03:13,185
При нормальности ε_i мы
имеем новое свойство.

40
00:03:13,185 --> 00:03:17,523
F-статистика равное 
(RSS_R - RSS_UR),

41
00:03:17,523 --> 00:03:21,875
деленное на количество ограничений r,
делить на RSS_UR, делить на (n - k_un),

42
00:03:21,875 --> 00:03:27,444
это случайная
величина имеет F-распределение 

43
00:03:27,444 --> 00:03:31,740
с r,(n - k) степенями свободы.

44
00:03:31,740 --> 00:03:37,200
Давайте в рамках этих предпосылок
отдельно оговорим два особых случая.

45
00:03:37,200 --> 00:03:40,229
А что произойдет,
если я включу лишние переменные.

46
00:03:40,229 --> 00:03:44,872
То есть на самом деле y зависит только от
x, а я этого не знаю же на самом деле.

47
00:03:44,872 --> 00:03:49,901
И я буду строить, оценивать регрессию,
оценивать зависимость y от x и от z.

48
00:03:49,901 --> 00:03:54,050
Что произойдет в этом случае,
когда я включу лишнюю переменную?

49
00:03:54,050 --> 00:03:57,895
И что произойдет в противоположенном
случае, когда я не включу переменную,

50
00:03:57,895 --> 00:04:00,060
от которой на самом деле зависимость есть?

51
00:04:00,060 --> 00:04:04,744
Случай с лишними переменными, он,
к счастью, очень оптимистичный.

52
00:04:04,744 --> 00:04:09,712
Из всей этой армады хороших свойств
потерянным в этом случае окажется только

53
00:04:09,712 --> 00:04:11,460
свойство эффективности.

54
00:04:11,460 --> 00:04:15,125
То есть оценки останутся несмещенными,
останутся состоятельными.

55
00:04:15,125 --> 00:04:19,368
С ростом количества наблюдений они будут
все более и более похожи на настоящее β.

56
00:04:19,368 --> 00:04:23,349
Можно будет проверять гипотезы по
старым формулам, гипотезы об отдельных

57
00:04:23,349 --> 00:04:27,072
коэффициентах, гипотезы о нескольких
линейных ограничениях сразу.

58
00:04:27,072 --> 00:04:29,774
Единственное, что будет
потеряно — оказывается,

59
00:04:29,774 --> 00:04:35,545
что если какие-то коэффициенты на
самом деле, β настоящие, равны нулю,

60
00:04:35,545 --> 00:04:40,455
то при оценки модели с лишними
регрессорами, вы потеряете эффективность.

61
00:04:40,455 --> 00:04:45,160
То есть дисперсия ваших оценок β с
крышкой будет больше, чем могла бы быть,

62
00:04:45,160 --> 00:04:47,917
если бы вы не включили эти коэффициенты.

63
00:04:47,917 --> 00:04:52,947
То есть мораль отсюда, что, как бы,
если у вас есть переменные, от которых

64
00:04:52,947 --> 00:04:58,006
зависимости нет, и вы об этом знаете,
то лучше их в модель не включать, тогда вы

65
00:04:58,006 --> 00:05:02,967
получите более короткие доверительные
интервалы для неизвестных коэффициентов.

66
00:05:02,967 --> 00:05:08,378
Более короткие доверительные интервалы для
прогнозов, то есть вы вернете потерянную

67
00:05:08,378 --> 00:05:13,060
эффективность, если не
включите лишние переменные.

68
00:05:13,060 --> 00:05:16,761
Противоположенный случай,
случай пропущенных переменных,

69
00:05:16,761 --> 00:05:25,270
когда на самом деле истинная зависимость
имеет вид y_i = β₁ + β₂ х_i + β_3 z_i + ε_i,

70
00:05:25,270 --> 00:05:29,900
а оценена регрессия на меньшее
количество переменных,

71
00:05:29,900 --> 00:05:33,350
то, к несчастью, все плохо.

72
00:05:33,350 --> 00:05:36,661
Единственное свойство,
которое осталось у оценок, это то,

73
00:05:36,661 --> 00:05:39,061
что они остались линейными по y.

74
00:05:39,061 --> 00:05:42,220
Все остальные свойства пропали.

75
00:05:42,220 --> 00:05:46,685
Оценки стали смещенными, несостоятельными,
проверять гипотезы нельзя,

76
00:05:46,685 --> 00:05:51,150
строить доверительные интервалы по
формулам, которые у нас есть, нельзя.

77
00:05:51,150 --> 00:05:55,345
И из-за этой вот такой
вот совершенно разной,

78
00:05:55,345 --> 00:06:00,940
разных последствиях неправильных действий,

79
00:06:00,940 --> 00:06:06,870
видно, что лучше включить лишнюю
переменную, чем не включить нужную.

80
00:06:06,870 --> 00:06:10,853
Поэтому, если у нас есть
теоретические основания считать,

81
00:06:10,853 --> 00:06:15,599
что зависимость от переменной z есть,
а вы оцениваете регрессию,

82
00:06:15,599 --> 00:06:18,201
она не значима, лучше ее оставить.

83
00:06:18,201 --> 00:06:21,208
Если есть теоретические основания считать,

84
00:06:21,208 --> 00:06:25,391
что зависимость от z есть,
значит z лучше оставить.

85
00:06:25,391 --> 00:06:29,809
Если переменная, наоборот,
если переменная значима, но теория

86
00:06:29,809 --> 00:06:34,180
говорит: ну не должно быть зависимости
от этой переменной, она вот значима.

87
00:06:34,180 --> 00:06:39,942
Все равно лучше такую переменную оставить,
потому что невключение нужной переменной

88
00:06:39,942 --> 00:06:45,130
— это гораздо страшнее ошибка,
чем включение ненужной переменной.

89
00:06:45,130 --> 00:06:48,749
Конечно, не стоит впадать в крайности
и включать слишком много ненужных

90
00:06:48,749 --> 00:06:52,746
переменных, от этого у вас доверительные
интервалы для коэффициентов станут очень

91
00:06:52,746 --> 00:06:56,498
и очень широкими, и проверять гипотезы
тоже будет как-то бессмысленно,

92
00:06:56,498 --> 00:06:58,810
ни одна гипотеза не будет отвергаться.

93
00:06:58,810 --> 00:07:05,510
Но тем не менее, о важности этих двух
ошибок можно судить по данных выводам.

