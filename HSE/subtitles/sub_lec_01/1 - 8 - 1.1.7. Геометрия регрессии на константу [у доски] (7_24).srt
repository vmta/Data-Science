1
00:00:13,250 --> 00:00:17,917
Как правило,
в моделях в исходных данных у нас

2
00:00:17,917 --> 00:00:22,020
имеется много наблюдений,
n может равняться 100 или 1 000.

3
00:00:22,020 --> 00:00:26,908
Сейчас мы покажем картинку
для линейной модели

4
00:00:26,908 --> 00:00:32,055
регрессии в n-мерном пространстве, то есть
в 100-мерном или 1000-мерном пространстве.

5
00:00:32,055 --> 00:00:35,495
Для того чтобы рисовать в
100-мерном пространстве,

6
00:00:35,495 --> 00:00:39,470
вам потребуется клетчатый шарф,
как у настоящего художника.

7
00:00:46,330 --> 00:00:51,447
Итак, у нас есть исходные данные y_i y_1

8
00:00:51,447 --> 00:00:56,300
и так далее, y_100.

9
00:00:56,300 --> 00:01:00,490
Это вектор,
мы его обозначаем просто буковкой y.

10
00:01:00,490 --> 00:01:03,720
Еще давайте рассмотрим
вектор из одних единичек.

11
00:01:03,720 --> 00:01:09,210
Один, один, один.

12
00:01:09,210 --> 00:01:11,793
Нарисуем эти два вектора.

13
00:01:11,793 --> 00:01:15,280
Тут главное — смелые первые мазки.

14
00:01:15,280 --> 00:01:18,347
На вопрос,

15
00:01:18,347 --> 00:01:24,250
почему именно так мы нарисовали вектор

16
00:01:24,250 --> 00:01:29,697
y 100-мерный и вектор из 1,
можно ответить: «Я так вижу».

17
00:01:29,697 --> 00:01:35,065
Дело в том, что у нас слишком много
свободы в 100-мерном пространстве,

18
00:01:35,065 --> 00:01:39,566
чтобы рисовать векторы, можно посмотреть
на него под разными углами, и векторы,

19
00:01:39,566 --> 00:01:41,696
которые под одним углом перпендикулярны,

20
00:01:41,696 --> 00:01:45,440
могут иметь произвольный
угол под другим углом.

21
00:01:45,440 --> 00:01:49,789
Давайте проиллюстрируем модель, с помощью
этого простого рисунка проиллюстрируем

22
00:01:49,789 --> 00:01:56,728
простую модель y_і = β + ε_i Я напомню,
что мы установили,

23
00:01:56,728 --> 00:02:01,470
что в этой модели бета с крышкой по методу
наименьших квадратов равняется y среднему.

24
00:02:01,470 --> 00:02:06,394
Соответственно, отдельно взятый прогноз
для i наблюдения — это есть просто

25
00:02:06,394 --> 00:02:07,438
игрек среднее.

26
00:02:07,438 --> 00:02:13,925
И если я рассмотрю вектор прогноза для
всех наблюдений, то это y_i с крышкой 1,

27
00:02:13,925 --> 00:02:18,857
y_2 с крышкой и так далее,
игрек n-ное с крышкой, но поскольку

28
00:02:18,857 --> 00:02:23,934
все они одинаковые в такой простой модели,
где нет объясняющей переменной фактически,

29
00:02:23,934 --> 00:02:28,520
то поэтому в этой модели все
эти числа равны y среднему.

30
00:02:28,520 --> 00:02:33,205
y среднее можно вынести за скобки вектора,

31
00:02:33,205 --> 00:02:37,890
и получить, что это y среднее
помножить на вектор из 1.

32
00:02:37,890 --> 00:02:39,987
И это у нас — вектор прогнозов.

33
00:02:39,987 --> 00:02:44,886
Соответственно, вектор прогнозов
пропорционален единичному вектору в

34
00:02:44,886 --> 00:02:46,939
этой модели, то есть?

35
00:02:46,939 --> 00:02:52,080
мы растягиваем вектор
из 1 в y среднее раз,

36
00:02:52,080 --> 00:02:59,150
получаем вектор y среднее
* на вектор из 1.

37
00:02:59,150 --> 00:03:06,533
Давайте заметим,
что ε_i с крышкой равняется y_i-

38
00:03:06,533 --> 00:03:10,450
y_i с крышкой — это ошибка прогноза.

39
00:03:10,450 --> 00:03:18,146
Поэтому y_i = y_i с крышкой + ε_i с крышкой,
прогноз + ошибка.

40
00:03:18,146 --> 00:03:21,704
И если записывать в векторной форме,
то это означает,

41
00:03:21,704 --> 00:03:26,516
что вектор y равен вектору,
по компонентам если складывать вектора,

42
00:03:26,516 --> 00:03:31,022
y с крышкой плюс вектор ε с крышкой,
то получится вектор y.

43
00:03:31,022 --> 00:03:35,600
Это означает на картинке,
это равенство означает,

44
00:03:35,600 --> 00:03:42,725
что если я соединю кончик
вектора y с крышкой до y,

45
00:03:42,725 --> 00:03:48,035
то вот этот вектор — это
будет вектор ε с крышкой.

46
00:03:48,035 --> 00:03:50,876
Действительно, можно пройти вектор y,

47
00:03:50,876 --> 00:03:56,269
а можно пройти вектор y с крышкой,
а потом прибавить к нему ε с крышкой.

48
00:03:56,269 --> 00:03:57,628
Но это еще не всё.

49
00:03:57,628 --> 00:04:03,616
Давайте заметим,
что у нас есть условия первого порядка,

50
00:04:03,616 --> 00:04:09,154
мы находили,
у нас y_i с крышкой равняется y среднее,

51
00:04:09,154 --> 00:04:13,559
ну, то есть, говоря по-другому, мы знаем,

52
00:04:13,559 --> 00:04:20,190
что сумма y_i с крышкой
равняется сумма y среднее,

53
00:04:20,190 --> 00:04:24,562
равняется n умножить на y среднее,
равняется сумма y_i.

54
00:04:24,562 --> 00:04:31,122
То есть, получается, что сумма y_i
с крышкой = сумма y_i среднее, и,

55
00:04:31,122 --> 00:04:36,473
вычитая одно из другого,
получаем, что сумма y_i-

56
00:04:36,473 --> 00:04:41,461
y_i с крышкой = 0, то есть

57
00:04:41,461 --> 00:04:46,550
сумма ε_i с крышкой на 1 равняется 0,

58
00:04:46,550 --> 00:04:50,560
а это условие мы можем
трактовать геометрически.

59
00:04:50,560 --> 00:04:55,570
Вот это условие означает, что вектор

60
00:04:55,570 --> 00:05:03,586
ε с крышкой перпендикулярен
вектору из одних единичек.

61
00:05:03,586 --> 00:05:08,670
Соответственно, мы получили
замечательный результат.

62
00:05:08,670 --> 00:05:13,115
Результат следующий — интерпретация
вот этой простой модели.

63
00:05:13,115 --> 00:05:20,450
Если мне надо с помощью метода наименьших
квадратов оценить модель y_i = β + ε_i,

64
00:05:20,450 --> 00:05:25,550
то для того чтобы найти β с крышкой,

65
00:05:25,550 --> 00:05:29,609
оказывается, это можно сделать
геометрически в n-мерном пространстве,

66
00:05:29,609 --> 00:05:31,885
где n — это количество наблюдений.

67
00:05:31,885 --> 00:05:37,063
А именно, я беру вектор y,
нахожу его проекцию на прямую,

68
00:05:37,063 --> 00:05:43,250
которая задается вектором из одних 1,

69
00:05:43,250 --> 00:05:48,008
и результат проецирования —
это будет вектор y с крышкой.

70
00:05:48,008 --> 00:05:48,823
Еще раз.

71
00:05:48,823 --> 00:05:53,486
Есть у меня вектор y,
есть у меня вектор из одних 1,

72
00:05:53,486 --> 00:05:57,757
я продолжаю этот вектор
до прямой и оказывается,

73
00:05:57,757 --> 00:06:04,168
что в простой модели без регрессоров
спроецировав вектор y на эту прямую,

74
00:06:04,168 --> 00:06:08,270
я получу вектор y с крышкой.

75
00:06:08,270 --> 00:06:12,939
Соответственно, мы получили попутно еще

76
00:06:12,939 --> 00:06:17,484
один факт: если любой вектор
проецировать на вектор из 1,

77
00:06:17,484 --> 00:06:20,930
то получится вектор средних значений.

78
00:06:20,930 --> 00:06:24,682
y среднее и так далее, y среднее.

79
00:06:24,682 --> 00:06:31,733
Ну, например, если у меня есть три вектора
в 100-мерном пространстве — вектор y,

80
00:06:31,733 --> 00:06:38,740
вектор из 1 и вектор х,

81
00:06:38,740 --> 00:06:46,050
если я спроецирую вектор y на вектор из 1,

82
00:06:46,050 --> 00:06:51,788
я получу вот здесь вот вектор y среднее,

83
00:06:51,788 --> 00:06:58,287
y среднее, y среднее, а если я спроецирую

84
00:06:58,287 --> 00:07:03,120
вектор x на тот же самый вектор из 1,

85
00:07:03,120 --> 00:07:07,885
то я, соответственно, получу,

86
00:07:07,885 --> 00:07:12,650
руководствуясь соображениями, что вектор
x ничем не отличается от вектора y,

87
00:07:12,650 --> 00:07:17,000
я получу вектор из x среднее,
x среднее, x среднее и так далее,

88
00:07:17,000 --> 00:07:24,450
x среднее.

