1
00:00:13,210 --> 00:00:18,935
Мы проиллюстрировали метод наименьших
квадратов для множественной регрессии,

2
00:00:18,935 --> 00:00:21,150
когда у нас много регрессоров.

3
00:00:21,150 --> 00:00:28,223
И попутно мы обнаружили следующие факты,
что если в модель включён свободный член,

4
00:00:28,223 --> 00:00:33,815
то есть y_i равняется β₁ плюс объясняющие
регрессоры, то есть существует β₁,

5
00:00:33,815 --> 00:00:39,740
то, соответственно, среди столбцов матрицы
X большое будет слева столбик из единичек,

6
00:00:39,740 --> 00:00:44,021
и в этом случае наши
оценки метода наименьших

7
00:00:44,021 --> 00:00:48,045
квадратов будут обладать
следующими свойствами,

8
00:00:48,045 --> 00:00:53,922
а именно: сумма ошибок прогнозов,
сумма ε_i с крышкой будет равняться нулю,

9
00:00:53,922 --> 00:00:58,841
сумма y будет равняться сумме
прогнозных y, или, другими словами,

10
00:00:58,841 --> 00:01:03,982
среднее значение прогноза будет равняться
среднему значению наблюдаемой переменной,

11
00:01:03,982 --> 00:01:08,003
а также будет присутствовать
разложение TSS = RSS + ESS,

12
00:01:08,003 --> 00:01:11,370
на рисунке мы увидели это
как теорему Пифагора.

13
00:01:11,370 --> 00:01:17,166
Наличие последнего разложения общей
суммы квадратов на две составляющие

14
00:01:17,166 --> 00:01:21,930
RRS плюс ESS позволяет придумать
простой показатель качества модели,

15
00:01:21,930 --> 00:01:27,370
а именно R-квадрат, который умными словами
называется коэффициент детерминации.

16
00:01:27,370 --> 00:01:32,060
Мы знаем, что чем прогнозы точнее

17
00:01:32,060 --> 00:01:37,045
похожи на настоящие Y,
тем меньше будут ошибки прогнозов

18
00:01:37,045 --> 00:01:41,380
ε с крышкой и тем меньше будет сумма
квадратов ошибок прогнозов RSS.

19
00:01:41,380 --> 00:01:47,990
Соответственно, отношение ESS к TSS,
или R-квадрат,

20
00:01:47,990 --> 00:01:54,200
будет примерно равно единичке, если RSS,
сумма квадратов ошибок, будет у нуля.

21
00:01:54,200 --> 00:01:59,750
Соответственно, мы получили коэффициент
R-квадрат, коэффициент детерминации,

22
00:01:59,750 --> 00:02:04,376
который всегда лежит от 0 до 1,
и значения, близкие к 0,

23
00:02:04,376 --> 00:02:09,731
означают, что сумма квадратов ошибок,
сумма квадратов остатков очень большая,

24
00:02:09,731 --> 00:02:13,071
а значения R-квадрат,
близкие к 1, говорят о том,

25
00:02:13,071 --> 00:02:17,660
что сумма квадратов остатков,
сумма квадратов ошибок прогноза маленькая.

26
00:02:17,660 --> 00:02:23,122
Или, другими словами,
R-квадрат — это есть доля объяснённого

27
00:02:23,122 --> 00:02:28,910
разброса y к общему разбросу,
общей сумме квадратов.

28
00:02:28,910 --> 00:02:32,981
Также этот коэффициент R-квадрат
можно интерпретировать по-другому,

29
00:02:32,981 --> 00:02:39,018
не только как объяснённую долю разброса y,
но и как квадрат выборочной корреляции,

30
00:02:39,018 --> 00:02:43,771
а именно: R-квадрат — это есть квадрат
выборочного коэффициента корреляции,

31
00:02:43,771 --> 00:02:48,992
который равен дроби: в числителе сумма y_i
минус y среднее, помножить на y_i с крышкой

32
00:02:48,992 --> 00:02:55,580
минус y среднее, и в знаменателе корни
из TSS помножить на корень из ESS.

33
00:02:55,580 --> 00:02:59,860
Оказывается, доказательство
этого факта очень простое.

34
00:02:59,860 --> 00:03:04,695
Дело в том, что выборочный коэффициент
корреляции — это ни что иное,

35
00:03:04,695 --> 00:03:09,530
как косинус угла между некоторыми двумя
векторами, что мы сейчас и увидим.

36
00:03:09,530 --> 00:03:13,895
А вот теперь как раз нам
потребуется четвёртый факт,

37
00:03:13,895 --> 00:03:19,530
что ESS к TSS — это
косинус квадрат угла φ.

38
00:03:19,530 --> 00:03:22,877
Как мы выяснили, показатель детерминации,

39
00:03:22,877 --> 00:03:28,870
коэффициент — это есть
отношение ESS к TSS.

40
00:03:28,870 --> 00:03:34,400
То есть он несёт тот смысл,
что это есть доля объяснённого

41
00:03:34,400 --> 00:03:39,930
разброса переменной y в
общем разбросе переменной y.

42
00:03:39,930 --> 00:03:45,180
Соответственно, из предыдущих формул
следует, что этот показатель лежит от 0 до

43
00:03:45,180 --> 00:03:51,080
1, и R-квадрат — это
косинус квадрат угла φ.

44
00:03:51,080 --> 00:03:56,030
Но, оказывается,
для косинуса у нас есть и другая формула.

45
00:03:56,030 --> 00:04:00,867
Из-за того, что скалярное произведение

46
00:04:00,867 --> 00:04:05,783
любых двух векторов A и B
— это есть длина вектора

47
00:04:05,783 --> 00:04:11,520
A помножить на длину вектора
B на косинус угла между ними,

48
00:04:11,520 --> 00:04:16,230
то из этого факта следует
выражение для косинуса,

49
00:04:16,230 --> 00:04:21,437
а именно: косинус между
любыми двумя векторами — это

50
00:04:21,437 --> 00:04:26,436
есть скалярное произведение
этих двух векторов делить

51
00:04:26,436 --> 00:04:31,145
на длину одного вектора
на длину другого вектора.

52
00:04:31,145 --> 00:04:36,239
Соответственно, что в нашем случае
будет являться R-квадратом,

53
00:04:36,239 --> 00:04:41,682
или косинусом квадрата между какими
двумя векторами является R-квадрат?

54
00:04:41,682 --> 00:04:44,250
Косинусом какого угла он является?

55
00:04:44,250 --> 00:04:48,560
Угол φ — это угол между AB и BC.

56
00:04:48,560 --> 00:04:53,639
Соответственно, у нас вектор AB с

57
00:04:53,639 --> 00:04:58,697
точностью до направления можно задать

58
00:04:58,697 --> 00:05:03,584
как y минус y

59
00:05:03,584 --> 00:05:08,770
среднее помножить на вектор из единичек.

60
00:05:08,770 --> 00:05:11,165
Соответственно...

61
00:05:11,165 --> 00:05:14,640
Это на самом деле, конечно, BA.

62
00:05:14,640 --> 00:05:20,800
А вектор,

63
00:05:20,800 --> 00:05:25,918
вектор BC можно задать как вектор

64
00:05:25,918 --> 00:05:32,410
y с крышкой минус y среднее
помножить на вектор из единичек.

65
00:05:32,410 --> 00:05:37,090
Это вектор BC.

66
00:05:37,090 --> 00:05:41,770
Соответственно, нам нужен косинус
угла между этими векторами.

67
00:05:41,770 --> 00:05:43,908
Соответственно, что мы получим,

68
00:05:43,908 --> 00:05:47,840
когда посчитаем длину первого
вектора и длину второго вектора?

69
00:05:47,840 --> 00:05:53,540
У нас получается,
что скалярное произведение

70
00:05:53,540 --> 00:06:00,010
BC c BA —

71
00:06:00,010 --> 00:06:06,324
это есть скалярное произведение вектора

72
00:06:06,324 --> 00:06:12,190
y минус y средняя помножить
на вектор из единичек,

73
00:06:12,190 --> 00:06:16,790
y с крышкой минус y средняя
помножить на вектор из единичек.

74
00:06:16,790 --> 00:06:21,413
Соответственно, это есть сумма.

75
00:06:21,413 --> 00:06:29,665
Поскольку с другой стороны скалярное
произведение можно определить как,

76
00:06:29,665 --> 00:06:34,190
скалярное произведение a на b можно
определить как сумму a_i на b_i,

77
00:06:34,190 --> 00:06:39,160
то нам просто нужно попарно
перемножить компоненты этих векторов.

78
00:06:39,160 --> 00:06:43,502
Соответственно, у нас получится: первая
компонента этого вектора — это y_1 минус y79
00:06:43,502 --> 00:06:48,930
средняя, первая компонента второго вектора
— это y с крышкой первая минус y средняя.

80
00:06:48,930 --> 00:06:53,364
Соответственно, я беру
y_i минус y средняя и

81
00:06:53,364 --> 00:06:57,610
перемножаю на y_i с
крышкой минус y средняя.

82
00:06:57,610 --> 00:07:02,250
Это я нашёл числитель.

83
00:07:02,250 --> 00:07:05,749
Соответственно, как выглядит знаменатель?

84
00:07:05,749 --> 00:07:13,350
В знаменателе у нас
находится длина вектора BC,

85
00:07:13,350 --> 00:07:20,550
это корень квадратный из суммы
квадратов его компонент,

86
00:07:20,550 --> 00:07:27,191
то есть это корень квадратный из суммы,
BC это y с крышкой,

87
00:07:27,191 --> 00:07:32,950
соответственно: y_i с крышкой
минус y средняя в квадрате.

88
00:07:32,950 --> 00:07:37,769
Ну, а соответственно,
длина вектора BA — это

89
00:07:37,769 --> 00:07:42,430
есть корень из суммы
квадратов его компонент,

90
00:07:42,430 --> 00:07:49,365
то есть корень из суммы y_i
минус y средняя в квадрате.

91
00:07:49,365 --> 00:07:54,080
Соответственно, мы получили ещё одну
формулу для коэффициента R-квадрат,

92
00:07:54,080 --> 00:07:58,940
а именно: R-квадрат

93
00:07:58,940 --> 00:08:04,163
равняется — в числителе сумма y_i минус

94
00:08:04,163 --> 00:08:09,273
y средняя помножить на y_i
с крышкой минус y средняя,

95
00:08:09,273 --> 00:08:14,500
деленное на корень квадратный

96
00:08:14,500 --> 00:08:19,653
из сумма y_i минус y средняя в

97
00:08:19,653 --> 00:08:25,585
квадрате на сумма y_i с крышкой
минус y средняя в квадрате.

98
00:08:25,585 --> 00:08:29,720
А, с другой стороны,
что это такое по сути?

99
00:08:29,720 --> 00:08:36,844
Здесь можно узнать формулу выборочной
корреляции между двумя векторами,

100
00:08:36,844 --> 00:08:42,326
а именно: это выборочная корреляция,

101
00:08:42,326 --> 00:08:47,716
обозначу её sCorr (sample
correlation — выборочная

102
00:08:47,716 --> 00:08:52,723
корреляция), между
векторами y и y с крышкой.

103
00:08:52,723 --> 00:08:57,770
И всё, конечно, нужно взять в квадрат,

104
00:08:57,770 --> 00:09:00,815
поскольку я считал косинус угла,

105
00:09:00,815 --> 00:09:06,585
а R-квадрат — это косинус квадрат угла.

106
00:09:06,585 --> 00:09:07,747
Таким образом,

107
00:09:07,747 --> 00:09:12,980
мы получили две интерпретации для
показателя в качестве регрессии.

108
00:09:12,980 --> 00:09:18,459
С одной стороны, R-квадрат — это
доля объяснённой дисперсии y, доля

109
00:09:18,459 --> 00:09:23,720
объяснённого разброса y: это объяснённый
разброс y делить на общий разброс y.

110
00:09:23,720 --> 00:09:28,685
А с другой стороны,
R-квадрат — это выборочна корреляция между

111
00:09:28,685 --> 00:09:32,568
прогнозами и настоящим y,
взятое в квадрат.

112
00:09:32,568 --> 00:09:38,214
Чем R-квадрат выше,
тем больше y с крышкой похож на y,

113
00:09:38,214 --> 00:09:42,700
чем чем R-квадрат выше,
тем выше доля объяснённой дисперсии.

